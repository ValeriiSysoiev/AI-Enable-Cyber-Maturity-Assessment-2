#!/bin/bash

# Automated UAT Test Execution Script
# This script runs automated tests that support the UAT checklist validation

set -euo pipefail

# Configuration
STAGING_URL="${STAGING_URL:-https://web-staging.eastus.azurecontainerapps.io}"
API_BASE_URL="${API_BASE_URL:-https://api-staging.eastus.azurecontainerapps.io}"
MCP_GATEWAY_URL="${MCP_GATEWAY_URL:-https://mcp-staging.eastus.azurecontainerapps.io}"
UAT_TEST_MODE="${UAT_TEST_MODE:-true}"

# Test results tracking
TEST_RESULTS_FILE="uat_test_results_$(date +%Y%m%d_%H%M%S).json"
declare -A test_results
total_tests=0
passed_tests=0
failed_tests=0

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
PURPLE='\033[0;35m'
NC='\033[0m' # No Color

# Test credentials (for staging environment)
UAT_ADMIN_EMAIL="uat.admin@staging.local"
UAT_ANALYST_EMAIL="uat.analyst@staging.local"
UAT_VIEWER_EMAIL="uat.viewer@staging.local"
UAT_PASSWORD="UAT_Test_Pass123!"

# Helper functions
log_info() {
    echo -e "${BLUE}[INFO]${NC} $1"
}

log_success() {
    echo -e "${GREEN}[‚úÖ PASS]${NC} $1"
}

log_warning() {
    echo -e "${YELLOW}[‚ö†Ô∏è WARN]${NC} $1"
}

log_error() {
    echo -e "${RED}[‚ùå FAIL]${NC} $1"
}

log_test() {
    echo -e "${PURPLE}[üß™ TEST]${NC} $1"
}

record_test_result() {
    local test_id="$1"\n    local status="$2"\n    local message="$3"\n    local duration="${4:-0}"\n    local details="${5:-}"\n    \n    ((total_tests++))\n    \n    if [[ "$status" == "PASS" ]]; then\n        ((passed_tests++))\n        log_success "$test_id: $message"\n    else\n        ((failed_tests++))\n        log_error "$test_id: $message"\n    fi\n    \n    # Store result in JSON format\n    test_results[\"$test_id\"]=$(jq -n \\\n        --arg id "$test_id" \\\n        --arg status "$status" \\\n        --arg message "$message" \\\n        --arg duration "$duration" \\\n        --arg details "$details" \\\n        --arg timestamp "$(date -u +%Y-%m-%dT%H:%M:%SZ)" \\\n        '{id: $id, status: $status, message: $message, duration: $duration, details: $details, timestamp: $timestamp}')\n}\n\n# Authentication helper\nget_auth_token() {\n    local email="$1"\n    local password="$2"\n    \n    local response\n    response=$(curl -s -X POST "$API_BASE_URL/api/auth/login" \\\n        -H "Content-Type: application/json" \\\n        -d "{\\"email\\":\\"$email\\",\\"password\\":\\"$password\\"}")\n    \n    if echo "$response" | jq -e '.token' >/dev/null 2>&1; then\n        echo "$response" | jq -r '.token'\n        return 0\n    else\n        echo ""\n        return 1\n    fi\n}\n\n# Test execution functions\ntest_authentication() {\n    log_info "üîê Running Authentication Tests"\n    \n    # AC-001: Valid User Login\n    log_test "AC-001: Valid User Login"\n    local start_time=$(date +%s%N)\n    \n    local token\n    if token=$(get_auth_token "$UAT_ANALYST_EMAIL" "$UAT_PASSWORD"); then\n        local end_time=$(date +%s%N)\n        local duration=$(( (end_time - start_time) / 1000000 ))\n        record_test_result "AC-001" "PASS" "User login successful" "$duration" "Token received and valid"\n        echo "$token" > .uat_analyst_token.tmp\n    else\n        local end_time=$(date +%s%N)\n        local duration=$(( (end_time - start_time) / 1000000 ))\n        record_test_result "AC-001" "FAIL" "User login failed" "$duration" "Authentication request failed"\n        return 1\n    fi\n    \n    # AC-002: Invalid Login Attempts\n    log_test "AC-002: Invalid Login Rejection"\n    local start_time=$(date +%s%N)\n    \n    local response\n    response=$(curl -s -X POST "$API_BASE_URL/api/auth/login" \\\n        -H "Content-Type: application/json" \\\n        -d "{\\"email\\":\\"$UAT_ANALYST_EMAIL\\",\\"password\\":\\"WrongPassword\\"}")\n    \n    local end_time=$(date +%s%N)\n    local duration=$(( (end_time - start_time) / 1000000 ))\n    \n    if echo "$response" | jq -e '.error' >/dev/null 2>&1; then\n        record_test_result "AC-002" "PASS" "Invalid login properly rejected" "$duration" "Error response received"\n    else\n        record_test_result "AC-002" "FAIL" "Invalid login not rejected" "$duration" "No error in response"\n    fi\n}\n\ntest_abac_authorization() {\n    log_info "üõ°Ô∏è Running ABAC Authorization Tests"\n    \n    # Get tokens for different users\n    local analyst_token viewer_token\n    if [[ -f ".uat_analyst_token.tmp" ]]; then\n        analyst_token=$(cat .uat_analyst_token.tmp)\n    else\n        log_error "Analyst token not available - skipping ABAC tests"\n        return 1\n    fi\n    \n    if ! viewer_token=$(get_auth_token "$UAT_VIEWER_EMAIL" "$UAT_PASSWORD"); then\n        log_warning "Viewer token not available - limited ABAC testing"\n    fi\n    \n    # AC-006: Engagement Isolation\n    log_test "AC-006: Engagement Isolation"\n    local start_time=$(date +%s%N)\n    \n    # Test analyst access to assigned engagement\n    local response\n    response=$(curl -s -H "Authorization: Bearer $analyst_token" \\\n        "$API_BASE_URL/api/engagements/eng-test-001")\n    \n    local end_time=$(date +%s%N)\n    local duration=$(( (end_time - start_time) / 1000000 ))\n    \n    if echo "$response" | jq -e '.id' >/dev/null 2>&1; then\n        # Test access to non-assigned engagement\n        local forbidden_response\n        forbidden_response=$(curl -s -w "%{http_code}" -H "Authorization: Bearer $analyst_token" \\\n            "$API_BASE_URL/api/engagements/eng-test-002" -o /dev/null)\n        \n        if [[ "$forbidden_response" == "403" ]]; then\n            record_test_result "AC-006" "PASS" "Engagement isolation enforced" "$duration" "Access granted to assigned, denied to non-assigned"\n        else\n            record_test_result "AC-006" "FAIL" "Engagement isolation bypassed" "$duration" "Access granted to non-assigned engagement"\n        fi\n    else\n        record_test_result "AC-006" "FAIL" "Cannot access assigned engagement" "$duration" "Access denied to assigned engagement"\n    fi\n}\n\ntest_mcp_tools() {\n    log_info "üîß Running MCP Tools Integration Tests"\n    \n    # Check MCP Gateway health first\n    local health_response\n    health_response=$(curl -s "$MCP_GATEWAY_URL/health")\n    \n    if ! echo "$health_response" | jq -e '.status' >/dev/null 2>&1; then\n        log_error "MCP Gateway not healthy - skipping MCP tests"\n        record_test_result "MCP-HEALTH" "FAIL" "MCP Gateway health check failed" "0" "Gateway not responding"\n        return 1\n    fi\n    \n    # MCP-001: PDF Processing (mock test)\n    log_test "MCP-001: PDF Tool Availability"\n    local start_time=$(date +%s%N)\n    \n    local tools_response\n    tools_response=$(curl -s "$MCP_GATEWAY_URL/tools")\n    \n    local end_time=$(date +%s%N)\n    local duration=$(( (end_time - start_time) / 1000000 ))\n    \n    if echo "$tools_response" | jq -e '.tools[] | select(.name == "pdf.parse")' >/dev/null 2>&1; then\n        record_test_result "MCP-001" "PASS" "PDF parsing tool available" "$duration" "Tool found in MCP registry"\n    else\n        record_test_result "MCP-001" "FAIL" "PDF parsing tool not available" "$duration" "Tool not found in MCP registry"\n    fi\n    \n    # MCP-006: Audio Transcription Tool\n    log_test "MCP-006: Audio Transcription Tool Availability"\n    local start_time=$(date +%s%N)\n    \n    if echo "$tools_response" | jq -e '.tools[] | select(.name == "transcribe")' >/dev/null 2>&1; then\n        local end_time=$(date +%s%N)\n        local duration=$(( (end_time - start_time) / 1000000 ))\n        record_test_result "MCP-006" "PASS" "Audio transcription tool available" "$duration" "Tool found in MCP registry"\n    else\n        local end_time=$(date +%s%N)\n        local duration=$(( (end_time - start_time) / 1000000 ))\n        record_test_result "MCP-006" "FAIL" "Audio transcription tool not available" "$duration" "Tool not found in MCP registry"\n    fi\n}\n\ntest_api_performance() {\n    log_info "‚ö° Running API Performance Tests"\n    \n    local analyst_token\n    if [[ -f ".uat_analyst_token.tmp" ]]; then\n        analyst_token=$(cat .uat_analyst_token.tmp)\n    else\n        log_error "Analyst token not available - skipping performance tests"\n        return 1\n    fi\n    \n    # PT-001: API Response Time\n    log_test "PT-001: API Response Time"\n    \n    local endpoints=(\n        "/api/health"\n        "/api/engagements"\n        "/api/documents"\n        "/api/search?q=test"\n    )\n    \n    local total_time=0\n    local endpoint_count=0\n    \n    for endpoint in "${endpoints[@]}"; do\n        local start_time=$(date +%s%N)\n        \n        local response_code\n        response_code=$(curl -s -w "%{http_code}" -H "Authorization: Bearer $analyst_token" \\\n            "$API_BASE_URL$endpoint" -o /dev/null)\n        \n        local end_time=$(date +%s%N)\n        local duration=$(( (end_time - start_time) / 1000000 ))\n        total_time=$((total_time + duration))\n        ((endpoint_count++))\n        \n        log_info "  $endpoint: ${duration}ms (HTTP $response_code)"\n    done\n    \n    local avg_time=$((total_time / endpoint_count))\n    \n    # Check against staging threshold (5000ms)\n    if [[ $avg_time -lt 5000 ]]; then\n        record_test_result "PT-001" "PASS" "Average API response time acceptable" "$avg_time" "Average: ${avg_time}ms < 5000ms threshold"\n    else\n        record_test_result "PT-001" "FAIL" "Average API response time too slow" "$avg_time" "Average: ${avg_time}ms >= 5000ms threshold"\n    fi\n}\n\ntest_search_functionality() {\n    log_info "üîç Running Search and RAG Tests"\n    \n    local analyst_token\n    if [[ -f ".uat_analyst_token.tmp" ]]; then\n        analyst_token=$(cat .uat_analyst_token.tmp)\n    else\n        log_error "Analyst token not available - skipping search tests"\n        return 1\n    fi\n    \n    # SR-001: Basic Search\n    log_test "SR-001: Basic Keyword Search"\n    local start_time=$(date +%s%N)\n    \n    local search_response\n    search_response=$(curl -s -H "Authorization: Bearer $analyst_token" \\\n        "$API_BASE_URL/api/search?q=security+policy")\n    \n    local end_time=$(date +%s%N)\n    local duration=$(( (end_time - start_time) / 1000000 ))\n    \n    if echo "$search_response" | jq -e '.results' >/dev/null 2>&1; then\n        local result_count\n        result_count=$(echo "$search_response" | jq '.results | length')\n        record_test_result "SR-001" "PASS" "Search returned results" "$duration" "$result_count results found"\n    else\n        record_test_result "SR-001" "FAIL" "Search failed to return results" "$duration" "No results array in response"\n    fi\n    \n    # RAG-001: Context-Aware Response\n    log_test "RAG-001: RAG Query Processing"\n    local start_time=$(date +%s%N)\n    \n    local rag_response\n    rag_response=$(curl -s -X POST -H "Authorization: Bearer $analyst_token" \\\n        -H "Content-Type: application/json" \\\n        "$API_BASE_URL/api/rag/query" \\\n        -d '{\n            "engagement_id": "eng-test-001",\n            "query": "What are our current password policy requirements?",\n            "include_sources": true\n        }')\n    \n    local end_time=$(date +%s%N)\n    local duration=$(( (end_time - start_time) / 1000000 ))\n    \n    if echo "$rag_response" | jq -e '.response' >/dev/null 2>&1; then\n        local has_sources\n        has_sources=$(echo "$rag_response" | jq -e '.sources')\n        if [[ "$has_sources" != "null" ]]; then\n            record_test_result "RAG-001" "PASS" "RAG query with sources successful" "$duration" "Response and sources provided"\n        else\n            record_test_result "RAG-001" "PASS" "RAG query successful (no sources)" "$duration" "Response provided without sources"\n        fi\n    else\n        record_test_result "RAG-001" "FAIL" "RAG query failed" "$duration" "No response in RAG result"\n    fi\n}\n\ntest_security_endpoints() {\n    log_info "üîí Running Security Tests"\n    \n    # DS-002: HTTPS Enforcement\n    log_test "DS-002: HTTPS Enforcement"\n    local start_time=$(date +%s%N)\n    \n    # Test HTTP to HTTPS redirect\n    local http_url="${API_BASE_URL/https:/http:}"\n    local redirect_response\n    redirect_response=$(curl -s -w "%{http_code}:%{redirect_url}" "$http_url/api/health" -o /dev/null)\n    \n    local end_time=$(date +%s%N)\n    local duration=$(( (end_time - start_time) / 1000000 ))\n    \n    local http_code="${redirect_response%%:*}"\n    local redirect_url="${redirect_response#*:}"\n    \n    if [[ "$http_code" =~ ^30[1-8]$ ]] && [[ "$redirect_url" =~ ^https:// ]]; then\n        record_test_result "DS-002" "PASS" "HTTP to HTTPS redirect working" "$duration" "HTTP $http_code redirect to HTTPS"\n    elif [[ "$http_code" == "000" ]]; then\n        # Connection refused or failed (expected for HTTPS-only)\n        record_test_result "DS-002" "PASS" "HTTP connections blocked" "$duration" "HTTP connection refused"\n    else\n        record_test_result "DS-002" "FAIL" "HTTPS not properly enforced" "$duration" "HTTP $http_code, redirect: $redirect_url"\n    fi\n    \n    # AU-001: Audit Logging (basic check)\n    log_test "AU-001: Audit Logging Endpoint"\n    local start_time=$(date +%s%N)\n    \n    local admin_token\n    if admin_token=$(get_auth_token "$UAT_ADMIN_EMAIL" "$UAT_PASSWORD"); then\n        local audit_response\n        audit_response=$(curl -s -w "%{http_code}" -H "Authorization: Bearer $admin_token" \\\n            "$API_BASE_URL/api/audit/logs?limit=1" -o /dev/null)\n        \n        local end_time=$(date +%s%N)\n        local duration=$(( (end_time - start_time) / 1000000 ))\n        \n        if [[ "$audit_response" == "200" ]]; then\n            record_test_result "AU-001" "PASS" "Audit logs endpoint accessible" "$duration" "HTTP 200 response"\n        else\n            record_test_result "AU-001" "FAIL" "Audit logs endpoint not accessible" "$duration" "HTTP $audit_response response"\n        fi\n    else\n        local end_time=$(date +%s%N)\n        local duration=$(( (end_time - start_time) / 1000000 ))\n        record_test_result "AU-001" "FAIL" "Cannot authenticate admin user for audit test" "$duration" "Admin authentication failed"\n    fi\n}\n\n# Service health check\ncheck_service_health() {\n    log_info "üè• Checking Service Health"\n    \n    local services=(\n        "Web:$STAGING_URL/api/health"\n        "API:$API_BASE_URL/health"\n        "MCP:$MCP_GATEWAY_URL/health"\n    )\n    \n    for service in "${services[@]}"; do\n        local name="${service%%:*}"\n        local url="${service#*:}"\n        \n        log_test "Health Check: $name"\n        local start_time=$(date +%s%N)\n        \n        local response\n        response=$(curl -s -w "%{http_code}" "$url" -o /dev/null)\n        \n        local end_time=$(date +%s%N)\n        local duration=$(( (end_time - start_time) / 1000000 ))\n        \n        if [[ "$response" == "200" ]]; then\n            record_test_result "HEALTH-$name" "PASS" "$name service healthy" "$duration" "HTTP 200 response"\n        else\n            record_test_result "HEALTH-$name" "FAIL" "$name service unhealthy" "$duration" "HTTP $response response"\n        fi\n    done\n}\n\n# Generate test report\ngenerate_test_report() {\n    log_info "üìä Generating UAT Test Report"\n    \n    local pass_percentage=0\n    if [[ $total_tests -gt 0 ]]; then\n        pass_percentage=$((passed_tests * 100 / total_tests))\n    fi\n    \n    # Create JSON report\n    local report_json\n    report_json=$(jq -n \\\n        --arg timestamp "$(date -u +%Y-%m-%dT%H:%M:%SZ)" \\\n        --arg environment "staging" \\\n        --arg total_tests "$total_tests" \\\n        --arg passed_tests "$passed_tests" \\\n        --arg failed_tests "$failed_tests" \\\n        --arg pass_percentage "$pass_percentage" \\\n        --argjson results "$(printf '%s\\n' "${test_results[@]}" | jq -s '.')" \\\n        '{\n            timestamp: $timestamp,\n            environment: $environment,\n            summary: {\n                total_tests: ($total_tests | tonumber),\n                passed_tests: ($passed_tests | tonumber),\n                failed_tests: ($failed_tests | tonumber),\n                pass_percentage: ($pass_percentage | tonumber)\n            },\n            test_results: $results\n        }')\n    \n    echo "$report_json" > "$TEST_RESULTS_FILE"\n    \n    # Generate human-readable summary\n    cat > "uat_summary_$(date +%Y%m%d_%H%M%S).md" << EOF\n# UAT Automated Test Summary\n\n**Execution Time**: $(date -u +"%Y-%m-%d %H:%M:%S UTC")  \n**Environment**: Staging  \n**Total Tests**: $total_tests  \n**Passed**: $passed_tests  \n**Failed**: $failed_tests  \n**Success Rate**: $pass_percentage%  \n\n## Test Categories\n\n### ‚úÖ Passed Tests\n$(echo "$report_json" | jq -r '.test_results[] | select(.status == "PASS") | "- **\\(.id)**: \\(.message) (\\(.duration)ms)"')\n\n### ‚ùå Failed Tests\n$(echo "$report_json" | jq -r '.test_results[] | select(.status == "FAIL") | "- **\\(.id)**: \\(.message) (\\(.duration)ms)"')\n\n## Recommendations\n\n$(\nif [[ $failed_tests -eq 0 ]]; then\n    echo "üéâ All automated tests passed! The staging environment appears ready for manual UAT execution."\nelse\n    echo "‚ö†Ô∏è Some automated tests failed. Please review and resolve the issues before proceeding with manual UAT."\nfi\n)\n\n## Next Steps\n\n1. Review failed tests and resolve underlying issues\n2. Re-run automated tests to verify fixes\n3. Proceed with manual UAT execution using the UAT runbook\n4. Execute comprehensive test scenarios in docs/uat-checklist.md\n\n---\n*Generated by UAT automation script*\nEOF\n    \n    log_info "üìÑ Test results saved to: $TEST_RESULTS_FILE"\n    log_info "üìã Test summary saved to: uat_summary_$(date +%Y%m%d_%H%M%S).md"\n}\n\n# Cleanup function\ncleanup() {\n    # Remove temporary files\n    rm -f .uat_*_token.tmp\n}\n\n# Main execution\nmain() {\n    echo "üß™ UAT Automated Test Execution"\n    echo "================================"\n    echo "Environment: $STAGING_URL"\n    echo "API: $API_BASE_URL"\n    echo "MCP: $MCP_GATEWAY_URL"\n    echo\n    \n    # Check prerequisites\n    if ! command -v curl &> /dev/null; then\n        log_error "curl is required but not installed"\n        exit 1\n    fi\n    \n    if ! command -v jq &> /dev/null; then\n        log_error "jq is required but not installed"\n        exit 1\n    fi\n    \n    # Run test suites\n    check_service_health\n    test_authentication\n    test_abac_authorization\n    test_mcp_tools\n    test_api_performance\n    test_search_functionality\n    test_security_endpoints\n    \n    # Generate report\n    generate_test_report\n    \n    # Print summary\n    echo\n    echo "üìä Test Summary"\n    echo "==============="\n    echo "Total Tests: $total_tests"\n    echo "Passed: $passed_tests"\n    echo "Failed: $failed_tests"\n    echo "Success Rate: $((passed_tests * 100 / total_tests))%"\n    echo\n    \n    if [[ $failed_tests -eq 0 ]]; then\n        log_success "üéâ All automated tests passed!"\n        echo "Ready to proceed with manual UAT execution."\n    else\n        log_error "‚ùå $failed_tests test(s) failed."\n        echo "Please resolve issues before manual UAT execution."\n        exit 1\n    fi\n    \n    cleanup\n}\n\n# Handle script interruption\ntrap cleanup EXIT\n\n# Check if script is being sourced or executed\nif [[ "${BASH_SOURCE[0]}" == "${0}" ]]; then\n    main "$@"\nfi"}]