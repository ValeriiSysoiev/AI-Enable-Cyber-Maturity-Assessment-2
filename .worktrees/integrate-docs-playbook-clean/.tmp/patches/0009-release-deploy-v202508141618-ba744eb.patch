From 0000000000000000000000000000000000000000 Mon Sep 17 00:00:00 2001
From: Valerii Sysoiev <valsysoiev@gmail.com>
Date: Thu, 14 Aug 2025 16:18:14 -0600
Subject: [PATCH 09/90] release: deploy v202508141618-ba744eb


diff --git a/README.md b/README.md
index adff19edf6d4959d11ef2384b25414abde649f99..5f112b8c805d605719acb70d192ad97d182f4bc3 100644
--- a/README.md
+++ b/README.md
@@ -389,3 +389,38 @@ Once RBAC permissions are granted, switch from ACR admin credentials to Managed
 After these steps, the Container Apps will use their Managed Identities to pull images from ACR and the API will use its identity for Azure Storage operations.
 
 ---
+
+## Build & Deploy via ACR Tasks (no Docker Desktop)
+
+This section describes how to build container images using Azure Container Registry (ACR) Tasks, eliminating the need for Docker Desktop.
+
+### Build both images:
+
+```bash
+scripts/build_acr_tasks.sh
+```
+
+This builds the API and Web images directly in Azure using ACR Tasks. The Web image can be built with or without the `API_URL` environment variable.
+
+### Deploy/update Container Apps (prints URLs):
+
+```bash
+scripts/deploy_containerapps.sh
+```
+
+This script:
+- Enables ACR admin credentials temporarily
+- Creates or updates both API and Web Container Apps
+- Prints the deployed API_URL and WEB_URL
+
+### If web was built before API_URL was known, rebuild web with baked URL:
+
+```bash
+scripts/rebuild_web_with_api.sh
+```
+
+This rebuilds the Web image with the API URL baked in at build time (for Next.js's `NEXT_PUBLIC_API_BASE_URL`), then updates the Web Container App.
+
+**Note:** This deployment uses temporary ACR admin credentials. Follow the "Switch to Managed Identity" section above to transition to a more secure authentication method using Managed Identities with proper RBAC roles (AcrPull for image access, Storage Blob roles for data, and Key Vault role for secrets).
+
+---
diff --git a/app/.dockerignore b/app/.dockerignore
new file mode 100644
index 0000000000000000000000000000000000000000..90ce0f2b2d9639852e9f2bd83c225039a26580b8
--- /dev/null
+++ b/app/.dockerignore
@@ -0,0 +1,49 @@
+__pycache__/
+.cache/
+.venv/
+*.pyc
+*.pyo
+*.pyd
+.git/
+.gitignore
+Dockerfile.bak
+
+# Environment files
+.env
+*.env
+.env.local
+.env.test
+.env.production
+.envrc
+
+# Virtual environments
+/venv/
+env/
+ENV/
+
+# Database files
+*.sqlite3
+*.db
+*.sqlite
+
+# Logs and temporary files
+logs/
+tmp/
+*.log
+
+# Python test and type checking caches
+.pytest_cache/
+.mypy_cache/
+.coverage
+htmlcov/
+
+# IDE and editor files
+.vscode/
+.idea/
+*.swp
+*.swo
+*~
+
+# OS files
+.DS_Store
+Thumbs.db
diff --git a/app/Dockerfile b/app/Dockerfile
index 22758607ce5174909e45f3eb327958d0610cc6ce..3691670d8650f6d3ab1195da9d402dddb30f9026 100644
--- a/app/Dockerfile
+++ b/app/Dockerfile
@@ -1,18 +1,26 @@
-FROM python:3.11-slim AS base
-ENV PYTHONDONTWRITEBYTECODE=1 PYTHONUNBUFFERED=1
-WORKDIR /app
-COPY requirements.txt .
-RUN pip install --no-cache-dir -r requirements.txt
-COPY app app
-ENV PORT=8000
-CMD ["uvicorn","app.api.main:app","--host","0.0.0.0","--port","8000"]
-
-
-
-
-
+# FastAPI / Uvicorn image
+FROM python:3.11-slim
 
+# Create and set working directory
+RUN mkdir -p /app
+WORKDIR /app
+ENV PYTHONDONTWRITEBYTECODE=1 \
+    PYTHONUNBUFFERED=1 \
+    PYTHONPATH=/app
 
+# Install system deps if needed (left minimal for now)
+# RUN apt-get update && apt-get install -y build-essential && rm -rf /var/lib/apt/lists/*
 
+# Copy Python deps and install
+COPY requirements.txt .
+RUN pip install --no-cache-dir -r requirements.txt
 
+# Copy application code
+COPY api/ ./api/
+COPY config/ ./config/
+COPY domain/ ./domain/
+COPY ai/ ./ai/
+COPY __init__.py .
 
+EXPOSE 8000
+CMD ["python", "-m", "uvicorn", "api.main:app", "--host", "0.0.0.0", "--port", "8000"]
\ No newline at end of file
diff --git a/app/Dockerfile.bak b/app/Dockerfile.bak
new file mode 100644
index 0000000000000000000000000000000000000000..22758607ce5174909e45f3eb327958d0610cc6ce
--- /dev/null
+++ b/app/Dockerfile.bak
@@ -0,0 +1,18 @@
+FROM python:3.11-slim AS base
+ENV PYTHONDONTWRITEBYTECODE=1 PYTHONUNBUFFERED=1
+WORKDIR /app
+COPY requirements.txt .
+RUN pip install --no-cache-dir -r requirements.txt
+COPY app app
+ENV PORT=8000
+CMD ["uvicorn","app.api.main:app","--host","0.0.0.0","--port","8000"]
+
+
+
+
+
+
+
+
+
+
diff --git a/app/__init__.py b/app/__init__.py
new file mode 100644
index 0000000000000000000000000000000000000000..eaee0412afdf01ac2fb4ed9d68f8a767fa1bce71
--- /dev/null
+++ b/app/__init__.py
@@ -0,0 +1 @@
+# Main app package
diff --git a/app/ai/__init__.py b/app/ai/__init__.py
new file mode 100644
index 0000000000000000000000000000000000000000..b8d6bd0c3f66ab1aab7fccf4fd0e84dcb7e0d087
--- /dev/null
+++ b/app/ai/__init__.py
@@ -0,0 +1 @@
+# AI module for LLM client and orchestration
diff --git a/app/ai/llm.py b/app/ai/llm.py
new file mode 100644
index 0000000000000000000000000000000000000000..61c3712837da82ae412607a0cece1237478a39b5
--- /dev/null
+++ b/app/ai/llm.py
@@ -0,0 +1,118 @@
+from __future__ import annotations
+import os
+import logging
+import time
+from typing import List, Dict, Any
+
+USE_MOCK = not (os.getenv("AZURE_OPENAI_ENDPOINT") and os.getenv("AZURE_OPENAI_API_KEY") and os.getenv("AZURE_OPENAI_DEPLOYMENT"))
+
+# Set up logger
+logger = logging.getLogger(__name__)
+
+if not USE_MOCK:
+    try:
+        from openai import AzureOpenAI, APIError, APIConnectionError, RateLimitError
+        _client = AzureOpenAI(
+            api_key=os.getenv("AZURE_OPENAI_API_KEY"),
+            api_version=os.getenv("AZURE_OPENAI_API_VERSION", "2024-02-01"),
+            azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT"),
+        )
+        _model = os.getenv("AZURE_OPENAI_DEPLOYMENT")
+    except (ImportError, ModuleNotFoundError) as e:
+        logger.error(f"Failed to import OpenAI client: {e}", exc_info=True)
+        USE_MOCK = True
+    except RuntimeError as e:
+        logger.error(f"Runtime error initializing OpenAI client: {e}", exc_info=True)
+        USE_MOCK = True
+    except Exception as e:
+        logger.exception(f"Unexpected error initializing OpenAI client: {e}")
+        USE_MOCK = True
+
+class LLMError(Exception):
+    """Custom exception for LLM-related errors"""
+    pass
+
+class LLMClient:
+    def generate(self, system: str, user: str) -> str:
+        if USE_MOCK:
+            # Simple deterministic stub for demos
+            return (
+                "Findings:\n"
+                "- [high] Identity: MFA not enforced for admins.\n"
+                "- [medium] Data: No DLP policies for M365.\n"
+                "- [low] SecOps: Runbooks missing for P1 incidents.\n"
+                "\nRecommendations:\n"
+                "1) Enforce Conditional Access + MFA for privileged roles (P1, M effort, 4 weeks)\n"
+                "2) Deploy baseline DLP policies for M365 (P2, M effort, 6 weeks)\n"
+                "3) Author incident runbooks and test (P3, S effort, 3 weeks)\n"
+            )
+        else:
+            # Implement retry logic with exponential backoff
+            max_retries = 3
+            base_delay = 1.0  # seconds
+            
+            for attempt in range(max_retries):
+                try:
+                    resp = _client.chat.completions.create(
+                        model=_model,
+                        messages=[
+                            {"role": "system", "content": system},
+                            {"role": "user", "content": user},
+                        ],
+                        temperature=0.2,
+                    )
+                    
+                    # Validate response structure
+                    if not resp:
+                        logger.error("OpenAI API returned empty response")
+                        raise LLMError("Empty response from OpenAI API")
+                    
+                    if not hasattr(resp, 'choices') or not resp.choices:
+                        logger.error(f"OpenAI API response missing choices: {resp}")
+                        raise LLMError("Invalid response structure: missing choices")
+                    
+                    if len(resp.choices) == 0:
+                        logger.error(f"OpenAI API returned empty choices list: {resp}")
+                        raise LLMError("Invalid response structure: empty choices list")
+                    
+                    first_choice = resp.choices[0]
+                    if not hasattr(first_choice, 'message') or not first_choice.message:
+                        logger.error(f"OpenAI API choice missing message: {first_choice}")
+                        raise LLMError("Invalid response structure: missing message")
+                    
+                    if not hasattr(first_choice.message, 'content') or first_choice.message.content is None:
+                        logger.error(f"OpenAI API message missing content: {first_choice.message}")
+                        raise LLMError("Invalid response structure: missing message content")
+                    
+                    content = first_choice.message.content
+                    if not content or not content.strip():
+                        logger.warning("OpenAI API returned empty content")
+                        return "No content generated by the model."
+                    
+                    return content
+                    
+                except RateLimitError as e:
+                    if attempt < max_retries - 1:
+                        delay = base_delay * (2 ** attempt)  # exponential backoff
+                        logger.warning(f"Rate limit hit, retrying in {delay}s. Attempt {attempt + 1}/{max_retries}: {e}")
+                        time.sleep(delay)
+                    else:
+                        logger.error(f"Rate limit error after {max_retries} attempts: {e}")
+                        raise LLMError(f"Rate limit exceeded after {max_retries} retries") from e
+                        
+                except APIConnectionError as e:
+                    if attempt < max_retries - 1:
+                        delay = base_delay * (2 ** attempt)
+                        logger.warning(f"Connection error, retrying in {delay}s. Attempt {attempt + 1}/{max_retries}: {e}")
+                        time.sleep(delay)
+                    else:
+                        logger.error(f"Connection error after {max_retries} attempts: {e}")
+                        raise LLMError(f"Connection failed after {max_retries} retries") from e
+                        
+                except APIError as e:
+                    logger.error(f"OpenAI API error: {e}")
+                    raise LLMError(f"OpenAI API error: {str(e)}") from e
+                    
+                except Exception as e:
+                    logger.exception(f"Unexpected error calling OpenAI API: {e}")
+                    raise LLMError(f"Unexpected error: {str(e)}") from e
diff --git a/app/ai/orchestrator.py b/app/ai/orchestrator.py
new file mode 100644
index 0000000000000000000000000000000000000000..254011a1feb73be2248024a0a346275c5b2f720f
--- /dev/null
+++ b/app/ai/orchestrator.py
@@ -0,0 +1,186 @@
+from __future__ import annotations
+import re
+import logging
+from typing import List, Optional
+from pydantic import BaseModel
+from app.domain.models import Finding, Recommendation, RunLog
+from .llm import LLMClient
+
+# Set up logger
+logger = logging.getLogger(__name__)
+
+SYSTEM_ANALYZE = (
+    "You are DocAnalyzer. Extract concise cybersecurity maturity findings from the provided content. "
+    "Return bullets with [low|medium|high] severity, area (e.g., Identity, Data, SecOps), and evidence."
+)
+SYSTEM_RECOMMEND = (
+    "You are GapRecommender. Using the provided findings, generate prioritized, actionable recommendations. "
+    "Each item must include title, short rationale, priority (P1|P2|P3), effort (S|M|L) and suggested timeline in weeks."
+)
+
+# Regex patterns for parsing
+FINDING_PATTERN = re.compile(
+    r'^[-*•]?\s*\[?\s*(low|medium|high|critical|info|informational)\s*\]?\s*'
+    r'(?:([^:]+?)\s*:\s*)?(.+)$',
+    re.IGNORECASE
+)
+
+RECOMMENDATION_PATTERN = re.compile(
+    r'^(?:[0-9]+[.)\s]+|[-*•]\s+)?(.+?)(?:\s*\(([^)]+)\))?$'
+)
+
+# Severity normalization mapping
+SEVERITY_MAP = {
+    'informational': 'info',
+    'low': 'low',
+    'medium': 'medium',
+    'high': 'high',
+    'critical': 'critical'
+}
+
+class Orchestrator:
+    def __init__(self, llm: LLMClient):
+        self.llm = llm
+
+    def analyze(self, assessment_id: str, content: str):
+        text = self.llm.generate(SYSTEM_ANALYZE, content)
+        findings: List[Finding] = []
+        
+        for line in text.splitlines():
+            line = line.strip()
+            if not line:
+                continue
+                
+            match = FINDING_PATTERN.match(line)
+            if match:
+                severity_raw = match.group(1)
+                area = match.group(2)
+                title = match.group(3)
+                
+                # Normalize severity
+                severity = SEVERITY_MAP.get(severity_raw.lower(), 'medium')
+                
+                # Clean up captured groups
+                if area:
+                    area = area.strip().strip('"\'')
+                title = title.strip().strip('"\'')
+                
+                # Only create finding if we have a title
+                if title:
+                    findings.append(Finding(
+                        assessment_id=assessment_id,
+                        title=title,
+                        severity=severity,
+                        area=area
+                    ))
+                    logger.debug(f"Parsed finding: severity={severity}, area={area}, title={title[:50]}...")
+                else:
+                    logger.warning(f"Skipped finding with empty title from line: {line}")
+            else:
+                # Log lines that look like findings but didn't match
+                if any(marker in line.lower() for marker in ['low', 'medium', 'high', 'critical']):
+                    logger.debug(f"Line might contain finding but didn't match pattern: {line}")
+        
+        # Safely limit output preview
+        preview_lines = text.splitlines()[:8]
+        preview = "\n".join(preview_lines)[:500]  # Limit to 500 chars
+        
+        log = RunLog(
+            assessment_id=assessment_id,
+            agent="DocAnalyzer",
+            input_preview=content[:200],
+            output_preview=preview
+        )
+        return findings, log
+
+    def recommend(self, assessment_id: str, findings_for_prompt: str):
+        text = self.llm.generate(SYSTEM_RECOMMEND, findings_for_prompt)
+        recs: List[Recommendation] = []
+        
+        for line in text.splitlines():
+            line = line.strip()
+            if not line:
+                continue
+            
+            # Try to match recommendation pattern
+            match = RECOMMENDATION_PATTERN.match(line)
+            if match:
+                title_part = match.group(1)
+                metadata_part = match.group(2)
+                
+                # Skip if title is too short or looks like just a number
+                if not title_part or len(title_part) < 5 or title_part.isdigit():
+                    continue
+                
+                # Default values
+                priority = "P2"
+                effort = "M"
+                weeks: Optional[int] = None
+                
+                # Parse metadata if present
+                if metadata_part:
+                    # Normalize metadata to lowercase for matching
+                    meta_lower = metadata_part.lower()
+                    tokens = re.split(r'[,;\s]+', metadata_part)
+                    
+                    # Extract priority
+                    if 'p1' in meta_lower:
+                        priority = "P1"
+                    elif 'p3' in meta_lower:
+                        priority = "P3"
+                    elif 'p2' in meta_lower:
+                        priority = "P2"
+                    
+                    # Extract effort
+                    for token in tokens:
+                        token_clean = token.strip().upper()
+                        if token_clean == 'S' or 'small' in token.lower():
+                            effort = "S"
+                        elif token_clean == 'L' or 'large' in token.lower():
+                            effort = "L"
+                        elif token_clean == 'M' or 'medium' in token.lower():
+                            effort = "M"
+                    
+                    # Extract weeks
+                    for token in tokens:
+                        # Look for patterns like "6 weeks", "6w", or just "6"
+                        week_match = re.search(r'(\d+)\s*(?:weeks?|w)?', token)
+                        if week_match:
+                            try:
+                                weeks = int(week_match.group(1))
+                                break
+                            except ValueError:
+                                pass
+                    
+                    # Clean title by removing metadata
+                    title_clean = title_part.strip()
+                else:
+                    title_clean = line.strip()
+                
+                # Remove list markers from title
+                title_clean = re.sub(r'^[0-9]+[.)\s]+|^[-*•]\s+', '', title_clean).strip()
+                
+                # Limit title length
+                if len(title_clean) > 200:
+                    title_clean = title_clean[:197] + "..."
+                
+                recs.append(Recommendation(
+                    assessment_id=assessment_id,
+                    title=title_clean,
+                    priority=priority,
+                    effort=effort,
+                    timeline_weeks=weeks
+                ))
+                logger.debug(f"Parsed recommendation: priority={priority}, effort={effort}, weeks={weeks}, title={title_clean[:50]}...")
+        
+        # Safely limit output preview
+        preview_lines = text.splitlines()[:8]
+        preview = "\n".join(preview_lines)[:500]  # Limit to 500 chars
+        
+        log = RunLog(
+            assessment_id=assessment_id,
+            agent="GapRecommender",
+            input_preview=findings_for_prompt[:200],
+            output_preview=preview
+        )
+        return recs, log
diff --git a/app/api/main.py b/app/api/main.py
index 2099cfb4d62a64c324fa6b108e31c0feda9ecb07..9a24eaf378842f69e58db6f768f76cd442c3940c 100644
--- a/app/api/main.py
+++ b/app/api/main.py
@@ -12,24 +12,36 @@ from .db import create_db_and_tables, get_session
 from .models import Assessment, Answer
 from .schemas import AssessmentCreate, AssessmentResponse, AnswerUpsert, ScoreResponse, PillarScore
 from .scoring import compute_scores
+from .routes import assessments as assessments_router, orchestrations as orchestrations_router, engagements as engagements_router, documents, summary, presets as presets_router
+from ..domain.repository import InMemoryRepository
+from ..domain.file_repo import FileRepository
+from ..ai.llm import LLMClient
+from ..ai.orchestrator import Orchestrator
 
 app = FastAPI(title="AI Maturity Tool API", version="0.1.0")
 
 @app.on_event("startup")
 def on_startup():
     create_db_and_tables()
+    # Wire up new domain dependencies
+    app.state.repo = FileRepository()
+    app.state.orchestrator = Orchestrator(LLMClient())
+    
+    # Initialize preset service
+    from ..services import presets as preset_service
+    preset_service.ensure_dirs()
+    # register bundled presets if present
+    try:
+        bundled = {
+            "cyber-for-ai": Path("app/config/presets/cyber-for-ai.json"),
+            # add others here if you have them
+        }
+        preset_service.BUNDLED.update({k: v for k, v in bundled.items() if v.exists()})
+    except Exception:
+        pass
 
 # Configure CORS
-# Load allowed origins from environment variable
-web_urls = os.getenv("WEB_URLS", os.getenv("WEB_URL", ""))
-if web_urls:
-    # Parse comma-separated URLs and strip whitespace
-    allowed_origins = [url.strip() for url in web_urls.split(",") if url.strip()]
-else:
-    # Default to empty list if no URLs configured - CORS will be restrictive
-    allowed_origins = []
-    print("WARNING: No WEB_URL(s) configured. CORS will block all origins.")
-
+allowed_origins = os.getenv("WEB_ORIGIN", "http://localhost:3000").split(",")
 app.add_middleware(
     CORSMiddleware,
     allow_origins=allowed_origins,
@@ -40,24 +52,30 @@ app.add_middleware(
 
 app.include_router(assist_router)
 app.include_router(storage_router)
+app.include_router(assessments_router.router)
+app.include_router(orchestrations_router.router)
+app.include_router(engagements_router.router)
+app.include_router(documents.router)
+app.include_router(summary.router)
+app.include_router(presets_router.router)
 
 def load_preset(preset_id: str) -> dict:
-    preset_path = Path(__file__).resolve().parents[1] / "config" / "presets" / f"{preset_id}.json"
-    if not preset_path.exists():
-        raise FileNotFoundError(preset_path)
-    return json.loads(preset_path.read_text(encoding="utf-8"))
+    # Use new preset service for consistency
+    from ..services import presets as preset_service
+    try:
+        preset = preset_service.get_preset(preset_id)
+        return preset.model_dump()
+    except HTTPException as e:
+        # Fallback to old bundled method for backwards compatibility
+        preset_path = Path(__file__).resolve().parents[1] / "config" / "presets" / f"{preset_id}.json"
+        if not preset_path.exists():
+            raise FileNotFoundError(preset_path) from e
+        return json.loads(preset_path.read_text(encoding="utf-8"))
 
 @app.get("/health")
 def health():
     return {"status": "ok"}
 
-@app.get("/presets/{preset_id}")
-def get_preset(preset_id: str):
-    try:
-        return load_preset(preset_id)
-    except FileNotFoundError:
-        raise HTTPException(status_code=404, detail="Preset not found")
-
 
 @app.post("/assessments", response_model=AssessmentResponse)
 def create_assessment(assessment: AssessmentCreate, session: Session = Depends(get_session)):
diff --git a/app/api/routes/__init__.py b/app/api/routes/__init__.py
new file mode 100644
index 0000000000000000000000000000000000000000..45773719930a386db72a42b5f5954783f694ce82
--- /dev/null
+++ b/app/api/routes/__init__.py
@@ -0,0 +1 @@
+# Marking routes as a package
\ No newline at end of file
diff --git a/app/api/routes/assessments.py b/app/api/routes/assessments.py
new file mode 100644
index 0000000000000000000000000000000000000000..0b83fd75b77a5462126c970385addd23b63c110e
--- /dev/null
+++ b/app/api/routes/assessments.py
@@ -0,0 +1,64 @@
+from fastapi import APIRouter, Depends, HTTPException, Request
+from typing import List, Dict
+from ...domain.models import Assessment
+from ...domain.repository import Repository
+from ..security import current_context, require_member
+
+router = APIRouter(prefix="/domain-assessments", tags=["domain-assessments"])
+
+def get_repo(request: Request) -> Repository:
+    # wired in main.py app.state.repo
+    return request.app.state.repo
+
+@router.post("", response_model=Assessment)
+def create_assessment(
+    a: Assessment, 
+    repo: Repository = Depends(get_repo),
+    ctx: Dict[str, str] = Depends(current_context)
+):
+    # Ensure user is a member of the engagement
+    require_member(repo, ctx, "member")
+    
+    # Validate required fields
+    if not a.name or not a.name.strip():
+        raise HTTPException(status_code=400, detail="Assessment name is required and cannot be empty")
+    
+    # Set engagement_id from context
+    a.engagement_id = ctx["engagement_id"]
+    
+    # Check for duplicate assessment ID
+    existing = repo.get_assessment(a.id)
+    if existing:
+        raise HTTPException(status_code=409, detail=f"Assessment with ID '{a.id}' already exists")
+    
+    return repo.create_assessment(a)
+
+@router.get("", response_model=List[Assessment])
+def list_assessments(
+    repo: Repository = Depends(get_repo),
+    ctx: Dict[str, str] = Depends(current_context)
+):
+    # Ensure user is a member of the engagement
+    require_member(repo, ctx, "member")
+    
+    # List assessments for the engagement
+    return repo.list_assessments(ctx["engagement_id"])
+
+@router.get("/{assessment_id}", response_model=Assessment)
+def get_assessment(
+    assessment_id: str, 
+    repo: Repository = Depends(get_repo),
+    ctx: Dict[str, str] = Depends(current_context)
+):
+    # Ensure user is a member of the engagement
+    require_member(repo, ctx, "member")
+    
+    a = repo.get_assessment(assessment_id)
+    if not a:
+        raise HTTPException(404, "Assessment not found")
+    
+    # Verify assessment belongs to the engagement
+    if a.engagement_id != ctx["engagement_id"]:
+        raise HTTPException(403, "Assessment not in this engagement")
+    
+    return a
diff --git a/app/api/routes/documents.py b/app/api/routes/documents.py
new file mode 100644
index 0000000000000000000000000000000000000000..7368645a19718de780df0d874f577c645f1462cc
--- /dev/null
+++ b/app/api/routes/documents.py
@@ -0,0 +1,118 @@
+from fastapi import APIRouter, Depends, HTTPException, UploadFile, File, Request
+from fastapi.responses import FileResponse
+import os, uuid, shutil
+from pydantic import BaseModel
+from datetime import datetime
+from typing import Optional
+
+from ...domain.repository import Repository
+from ...domain.models import Document
+from ..security import current_context, require_member, is_admin
+from ...util.files import safe_join
+
+class DocumentPublic(BaseModel):
+    """Public document model that excludes the filesystem path"""
+    id: str
+    engagement_id: str
+    filename: str
+    content_type: Optional[str] = None
+    size: int = 0
+    uploaded_by: str
+    uploaded_at: datetime
+
+router = APIRouter(prefix="/engagements/{engagement_id}/docs", tags=["documents"])
+
+def get_repo(request: Request) -> Repository:
+    return request.app.state.repo
+
+def _root_dir():
+    return os.getenv("UPLOAD_ROOT", "data/engagements")
+
+def _max_bytes():
+    mb = int(os.getenv("MAX_UPLOAD_MB", "10"))
+    return mb * 1024 * 1024
+
+@router.post("", response_model=list[DocumentPublic])
+async def upload_docs(engagement_id: str,
+                      files: list[UploadFile] = File(...),
+                      repo: Repository = Depends(get_repo),
+                      ctx=Depends(current_context)):
+    require_member(repo, {"user_email": ctx["user_email"], "engagement_id": engagement_id}, "member")
+    saved = []
+    base = _root_dir()
+    updir = safe_join(base, engagement_id, "uploads")
+    os.makedirs(updir, exist_ok=True)
+    maxb = _max_bytes()
+    for f in files:
+        fname = os.path.basename(f.filename or f"upload-{uuid.uuid4().hex}")
+        dest = safe_join(updir, f"{uuid.uuid4().hex}__{fname}")
+        total = 0
+        with open(dest, "wb") as out:
+            while True:
+                chunk = await f.read(1024 * 1024)
+                if not chunk:
+                    break
+                total += len(chunk)
+                if total > maxb:
+                    out.close()
+                    try: os.remove(dest)
+                    except: pass
+                    raise HTTPException(status_code=413, detail="File too large")
+                out.write(chunk)
+        d = Document(
+            engagement_id=engagement_id,
+            filename=fname,
+            content_type=f.content_type,
+            size=total,
+            path=os.path.abspath(dest),
+            uploaded_by=ctx["user_email"],
+        )
+        repo.add_document(d)
+        # Convert to public model excluding path
+        public_doc = DocumentPublic(
+            id=d.id,
+            engagement_id=d.engagement_id,
+            filename=d.filename,
+            content_type=d.content_type,
+            size=d.size,
+            uploaded_by=d.uploaded_by,
+            uploaded_at=d.uploaded_at
+        )
+        saved.append(public_doc)
+    return saved
+
+@router.get("", response_model=list[DocumentPublic])
+def list_docs(engagement_id: str, repo: Repository = Depends(get_repo), ctx=Depends(current_context)):
+    require_member(repo, {"user_email": ctx["user_email"], "engagement_id": engagement_id}, "member")
+    documents = repo.list_documents(engagement_id)
+    # Convert to public models excluding path
+    return [
+        DocumentPublic(
+            id=d.id,
+            engagement_id=d.engagement_id,
+            filename=d.filename,
+            content_type=d.content_type,
+            size=d.size,
+            uploaded_by=d.uploaded_by,
+            uploaded_at=d.uploaded_at
+        )
+        for d in documents
+    ]
+
+@router.get("/{doc_id}")
+def download_doc(engagement_id: str, doc_id: str, repo: Repository = Depends(get_repo), ctx=Depends(current_context)):
+    require_member(repo, {"user_email": ctx["user_email"], "engagement_id": engagement_id}, "member")
+    d = repo.get_document(engagement_id, doc_id)
+    if not d: raise HTTPException(404, "Not found")
+    if not os.path.exists(d.path): raise HTTPException(404, "File missing")
+    return FileResponse(d.path, media_type=d.content_type or "application/octet-stream", filename=d.filename)
+
+@router.delete("/{doc_id}")
+def delete_doc(engagement_id: str, doc_id: str, repo: Repository = Depends(get_repo), ctx=Depends(current_context)):
+    # lead or admin only
+    mctx = {"user_email": ctx["user_email"], "engagement_id": engagement_id}
+    if not is_admin(ctx["user_email"]):
+        require_member(repo, mctx, "lead")
+    ok = repo.delete_document(engagement_id, doc_id)
+    if not ok: raise HTTPException(404, "Not found")
+    return {"deleted": True}
diff --git a/app/api/routes/engagements.py b/app/api/routes/engagements.py
new file mode 100644
index 0000000000000000000000000000000000000000..87ae3b441ce09eb5779cd785ebbfd76766230c52
--- /dev/null
+++ b/app/api/routes/engagements.py
@@ -0,0 +1,71 @@
+from fastapi import APIRouter, Depends, HTTPException, Request
+from typing import List, Dict
+from ...domain.models import Engagement, Membership
+from ...domain.repository import Repository
+from ..security import current_context, is_admin, require_member
+from ..schemas import EngagementCreate, AddMemberRequest
+
+router = APIRouter(prefix="/engagements", tags=["engagements"])
+
+
+def get_repo(request: Request) -> Repository:
+    return request.app.state.repo
+
+
+@router.post("", response_model=Engagement)
+def create_engagement(
+    payload: EngagementCreate, 
+    repo: Repository = Depends(get_repo), 
+    ctx: Dict[str, str] = Depends(current_context)
+):
+    """Create a new engagement (Admin only)"""
+    if not is_admin(ctx["user_email"]):
+        raise HTTPException(403, "Admin only")
+    
+    e = Engagement(
+        name=payload.name, 
+        client_code=payload.client_code, 
+        created_by=ctx["user_email"]
+    )
+    created = repo.create_engagement(e)
+    
+    # Automatically add creator as lead
+    m = Membership(
+        engagement_id=created.id,
+        user_email=ctx["user_email"],
+        role="lead"
+    )
+    repo.add_membership(m)
+    
+    return created
+
+
+@router.get("", response_model=List[Engagement])
+def list_my_engagements(
+    repo: Repository = Depends(get_repo), 
+    ctx: Dict[str, str] = Depends(current_context)
+):
+    """List engagements accessible to the current user"""
+    return repo.list_engagements_for_user(ctx["user_email"], is_admin(ctx["user_email"]))
+
+
+@router.post("/{engagement_id}/members", response_model=Membership)
+def add_member(
+    engagement_id: str, 
+    payload: AddMemberRequest, 
+    repo: Repository = Depends(get_repo), 
+    ctx: Dict[str, str] = Depends(current_context)
+):
+    """Add a member to an engagement (Lead or Admin only)"""
+    # Verify user has lead access to this engagement
+    # Create a new context with the specific engagement_id
+    member_ctx = ctx.copy()
+    member_ctx["engagement_id"] = engagement_id
+    require_member(repo, member_ctx, "lead")
+    
+    m = Membership(
+        engagement_id=engagement_id, 
+        user_email=payload.user_email, 
+        role=payload.role
+    )
+    return repo.add_membership(m)
diff --git a/app/api/routes/orchestrations.py b/app/api/routes/orchestrations.py
new file mode 100644
index 0000000000000000000000000000000000000000..33b38244fb45dd1cc74857c2395cc5309ed5233f
--- /dev/null
+++ b/app/api/routes/orchestrations.py
@@ -0,0 +1,147 @@
+from fastapi import APIRouter, Depends, HTTPException, Request
+from pydantic import BaseModel
+from typing import List, Dict
+from ...domain.models import Finding, Recommendation
+from ...domain.repository import Repository
+from ...ai.orchestrator import Orchestrator
+from ..security import current_context, require_member
+from ...util.files import extract_text
+
+router = APIRouter(prefix="/orchestrations", tags=["orchestrations"])
+
+def get_repo(request: Request) -> Repository:
+    return request.app.state.repo
+
+def get_orchestrator(request: Request) -> Orchestrator:
+    return request.app.state.orchestrator
+
+class AnalyzeRequest(BaseModel):
+    assessment_id: str
+    content: str
+
+class AnalyzeResponse(BaseModel):
+    findings: List[Finding]
+
+@router.post("/analyze", response_model=AnalyzeResponse)
+def analyze(
+    req: AnalyzeRequest, 
+    repo: Repository = Depends(get_repo), 
+    orch: Orchestrator = Depends(get_orchestrator),
+    ctx: Dict[str, str] = Depends(current_context)
+):
+    # Ensure user is a member of the engagement
+    require_member(repo, ctx, "member")
+    
+    # Get and verify assessment
+    assessment = repo.get_assessment(req.assessment_id)
+    if not assessment:
+        raise HTTPException(404, "Assessment not found")
+    
+    # Verify assessment belongs to the engagement
+    if assessment.engagement_id != ctx["engagement_id"]:
+        raise HTTPException(403, "Assessment not in this engagement")
+    
+    findings, log = orch.analyze(req.assessment_id, req.content)
+    repo.add_findings(req.assessment_id, findings)
+    repo.add_runlog(log)
+    return AnalyzeResponse(findings=findings)
+
+class RecommendRequest(BaseModel):
+    assessment_id: str
+
+class RecommendResponse(BaseModel):
+    recommendations: List[Recommendation]
+
+@router.post("/recommend", response_model=RecommendResponse)
+def recommend(
+    req: RecommendRequest, 
+    repo: Repository = Depends(get_repo), 
+    orch: Orchestrator = Depends(get_orchestrator),
+    ctx: Dict[str, str] = Depends(current_context)
+):
+    # Ensure user is a member of the engagement
+    require_member(repo, ctx, "member")
+    
+    # Get and verify assessment
+    assessment = repo.get_assessment(req.assessment_id)
+    if not assessment:
+        raise HTTPException(404, "Assessment not found")
+    
+    # Verify assessment belongs to the engagement
+    if assessment.engagement_id != ctx["engagement_id"]:
+        raise HTTPException(403, "Assessment not in this engagement")
+    
+    # Get findings for this engagement
+    findings = [f for f in repo.get_findings(ctx["engagement_id"]) if f.assessment_id == req.assessment_id]
+    if not findings:
+        raise HTTPException(400, "No findings available; run analyze first")
+    
+    findings_text = "\n".join(f"- [{f.severity}] {f.area or 'General'}: {f.title}" for f in findings)
+    recs, log = orch.recommend(req.assessment_id, findings_text)
+    repo.add_recommendations(req.assessment_id, recs)
+    repo.add_runlog(log)
+    return RecommendResponse(recommendations=recs)
+
+
+@router.get("/runlogs")
+def get_runlogs(
+    repo: Repository = Depends(get_repo),
+    ctx: Dict[str, str] = Depends(current_context)
+):
+    """Get runlogs for the current engagement"""
+    # Ensure user is a member of the engagement
+    require_member(repo, ctx, "member")
+    
+    return repo.get_runlogs(ctx["engagement_id"])
+
+
+class AnalyzeDocRequest(BaseModel):
+    doc_id: str
+
+
+@router.post("/analyze-doc")
+def analyze_doc(
+    payload: AnalyzeDocRequest,
+    request: Request,
+    repo: Repository = Depends(get_repo),
+    ctx: Dict[str, str] = Depends(current_context)
+):
+    require_member(repo, ctx, "member")
+    engagement_id = ctx["engagement_id"]
+    doc_id = payload.doc_id
+    
+    if not doc_id:
+        raise HTTPException(400, "doc_id required")
+    
+    doc = repo.get_document(engagement_id, doc_id)
+    if not doc:
+        raise HTTPException(404, "Doc not found")
+    
+    ex = extract_text(doc.path, doc.content_type)
+    if not ex.text:
+        return {"analyzed": False, "note": ex.note or "No text extracted"}
+    
+    # Create a new assessment for this document analysis
+    from ...domain.models import Assessment
+    assessment = Assessment(
+        name=f"Doc Analysis: {doc.filename}",
+        engagement_id=engagement_id,
+        framework="Custom"
+    )
+    repo.create_assessment(assessment)
+    
+    # Reuse existing analyze logic with the orchestrator
+    orch = request.app.state.orchestrator if hasattr(request.app.state, "orchestrator") else None
+    if not orch:
+        raise HTTPException(500, "Orchestrator not configured")
+    
+    findings, log = orch.analyze(assessment.id, ex.text)
+    repo.add_findings(assessment.id, findings)
+    repo.add_runlog(log)
+    
+    return {
+        "analyzed": True, 
+        "note": ex.note, 
+        "assessment_id": assessment.id,
+        "findings_count": len(findings)
+    }
diff --git a/app/api/routes/presets.py b/app/api/routes/presets.py
new file mode 100644
index 0000000000000000000000000000000000000000..a4838318df4585b7f1e23c47e766ea65a056f7df
--- /dev/null
+++ b/app/api/routes/presets.py
@@ -0,0 +1,39 @@
+from fastapi import APIRouter, Depends, UploadFile, File, Request, HTTPException
+from fastapi.responses import JSONResponse
+from typing import Any, Dict
+import json
+
+from ..security import current_context, require_admin
+from ...services import presets as svc
+from ..schemas import AssessmentPreset
+
+router = APIRouter(prefix="/presets", tags=["presets"])
+
+@router.get("")
+def list_presets():
+    return svc.list_presets()
+
+@router.get("/{preset_id}")
+def get_preset(preset_id: str):
+    return svc.get_preset(preset_id)
+
+@router.post("/upload")
+async def upload_preset(request: Request, file: UploadFile | None = File(default=None)):
+    ctx = await current_context(request)
+    require_admin(None, ctx)
+
+    data: Dict[str, Any]
+    if file:
+        raw = await file.read()
+        try:
+            data = json.loads(raw.decode("utf-8"))
+        except Exception as e:
+            raise HTTPException(400, f"Invalid JSON: {e}")
+    else:
+        try:
+            data = await request.json()
+        except Exception as e:
+            raise HTTPException(400, f"Invalid JSON body: {e}")
+
+    preset = svc.save_uploaded_preset(data)
+    return JSONResponse({"id": preset.id, "name": preset.name, "version": preset.version})
diff --git a/app/api/routes/summary.py b/app/api/routes/summary.py
new file mode 100644
index 0000000000000000000000000000000000000000..e2c68f9bb319f62f720e81f760596f0070ee94db
--- /dev/null
+++ b/app/api/routes/summary.py
@@ -0,0 +1,141 @@
+from fastapi import APIRouter, Depends, HTTPException, Request
+from fastapi.responses import PlainTextResponse
+from datetime import datetime
+from typing import List
+
+from ...domain.repository import Repository
+from ..security import current_context, require_member
+from ..schemas import EngagementSummary, CountSummary, ActivityItem
+
+router = APIRouter(prefix="/engagements/{engagement_id}", tags=["summary"])
+
+def get_repo(request: Request) -> Repository:
+    return request.app.state.repo
+
+@router.get("/summary", response_model=EngagementSummary)
+def get_summary(engagement_id: str, request: Request, repo: Repository = Depends(get_repo), ctx = Depends(current_context)):
+    require_member(repo, {"user_email": ctx["user_email"], "engagement_id": engagement_id}, "member")
+
+    # Gather
+    assessments = repo.list_assessments(engagement_id) if hasattr(repo, "list_assessments") else []
+    docs = repo.list_documents(engagement_id) if hasattr(repo, "list_documents") else []
+    findings = repo.get_findings(engagement_id) if hasattr(repo, "get_findings") else []
+    recs = repo.get_recommendations(engagement_id) if hasattr(repo, "get_recommendations") else []
+    runlogs = repo.get_runlogs(engagement_id) if hasattr(repo, "get_runlogs") else []
+
+    counts = CountSummary(
+        assessments=len(assessments),
+        documents=len(docs),
+        findings=len(findings),
+        recommendations=len(recs),
+        runlogs=len(runlogs),
+    )
+
+    # Activity stream
+    events: List[ActivityItem] = []
+    def _ts(o): 
+        return getattr(o, "created_at", None) or getattr(o, "uploaded_at", None) or getattr(o, "ts", None) or getattr(o, "timestamp", None)
+
+    for a in assessments[:50]:
+        events.append(ActivityItem(type="assessment", id=getattr(a,"id",""), ts=_ts(a), title=getattr(a,"name",None)))
+    for d in docs[:50]:
+        events.append(ActivityItem(type="document", id=getattr(d,"id",""), ts=_ts(d), title=getattr(d,"filename",None)))
+    for f in findings[:50]:
+        events.append(ActivityItem(type="finding", id=getattr(f,"id",""), ts=_ts(f), title=getattr(f,"title",None)))
+    for r in recs[:50]:
+        events.append(ActivityItem(type="recommendation", id=getattr(r,"id",""), ts=_ts(r), title=getattr(r,"title",None)))
+    for lg in runlogs[:50]:
+        preview = (getattr(lg, "message", "") or "")[:140]
+        events.append(ActivityItem(type="runlog", id=getattr(lg,"id",""), ts=_ts(lg), title=preview))
+
+    # Sort desc by ts
+    events = sorted(events, key=lambda e: e.ts or datetime.min, reverse=True)
+    last_ts = events[0].ts if events else None
+
+    # Build runlog excerpt
+    recent_runlog_excerpt = None
+    if runlogs:
+        try:
+            recent = sorted(runlogs, key=lambda lg: _ts(lg) or datetime.min, reverse=True)[0]
+            msg = getattr(recent, "message", None)
+            if msg:
+                recent_runlog_excerpt = msg[:400]
+        except Exception:
+            pass
+
+    return EngagementSummary(
+        engagement_id=engagement_id,
+        counts=counts,
+        last_activity=last_ts,
+        recent_activity=events[:20],
+        recent_runlog_excerpt=recent_runlog_excerpt
+    )
+
+@router.get("/exports/report.md")
+def export_report_md(engagement_id: str, request: Request, repo: Repository = Depends(get_repo), ctx = Depends(current_context)):
+    require_member(repo, {"user_email": ctx["user_email"], "engagement_id": engagement_id}, "member")
+
+    assessments = repo.list_assessments(engagement_id) if hasattr(repo, "list_assessments") else []
+    docs = repo.list_documents(engagement_id) if hasattr(repo, "list_documents") else []
+    findings = repo.get_findings(engagement_id) if hasattr(repo, "get_findings") else []
+    recs = repo.get_recommendations(engagement_id) if hasattr(repo, "get_recommendations") else []
+    runlogs = repo.get_runlogs(engagement_id) if hasattr(repo, "get_runlogs") else []
+
+    def _fmt_dt(dt):
+        try:
+            return dt.isoformat(timespec="seconds")+"Z"
+        except Exception:
+            return ""
+
+    lines = []
+    lines.append(f"# Engagement Report")
+    lines.append("")
+    lines.append(f"**Engagement ID:** `{engagement_id}`")
+    lines.append(f"**Generated:** `{datetime.utcnow().isoformat(timespec='seconds')}Z`")
+    lines.append("")
+    lines.append("## Summary")
+    lines.append(f"- Assessments: **{len(assessments)}**")
+    lines.append(f"- Documents: **{len(docs)}**")
+    lines.append(f"- Findings: **{len(findings)}**")
+    lines.append(f"- Recommendations: **{len(recs)}**")
+    lines.append("")
+    if assessments:
+        lines.append("## Assessments")
+        for a in assessments[:50]:
+            nm = getattr(a, 'name', '')
+            aid = getattr(a, 'id', '')
+            ts = getattr(a, 'created_at', None)
+            lines.append(f"- **{nm}** (`{aid}`) {('— ' + _fmt_dt(ts)) if ts else ''}")
+        lines.append("")
+    if findings:
+        lines.append("## Top Findings (max 20)")
+        for f in findings[:20]:
+            tt = getattr(f, 'title', '') or getattr(f, 'id', '')
+            sev = getattr(f, 'severity', None)
+            lines.append(f"- {tt}{(' — severity: ' + str(sev)) if sev is not None else ''}")
+        lines.append("")
+    if recs:
+        lines.append("## Top Recommendations (max 20)")
+        for r in recs[:20]:
+            tt = getattr(r, 'title', '') or getattr(r, 'id', '')
+            pri = getattr(r, 'priority', None)
+            lines.append(f"- {tt}{(' — priority: ' + str(pri)) if pri is not None else ''}")
+        lines.append("")
+    if runlogs:
+        lines.append("## Recent Run Logs (max 10)")
+        for lg in sorted(runlogs, key=lambda x: getattr(x, 'timestamp', None) or getattr(x, 'ts', None) or datetime.min, reverse=True)[:10]:
+            ts = getattr(lg, 'timestamp', None) or getattr(lg, 'ts', None)
+            msg = getattr(lg, 'message', '')[:200].replace('\n',' ')
+            lines.append(f"- { _fmt_dt(ts) if ts else '' } — {msg}")
+        lines.append("")
+    if docs:
+        lines.append("## Documents (max 20)")
+        for d in docs[:20]:
+            nm = getattr(d, 'filename', '')
+            sz = getattr(d, 'size', 0)
+            ts = getattr(d, 'uploaded_at', None)
+            lines.append(f"- {nm} — {sz} bytes {('— ' + _fmt_dt(ts)) if ts else ''}")
+        lines.append("")
+
+    md = "\n".join(lines)
+    return PlainTextResponse(md, media_type="text/markdown; charset=utf-8")
diff --git a/app/api/schemas.py b/app/api/schemas.py
index 23a86db735042e38a19b68cf0076dd7a93ff15bd..58364fcbc03309594d89806a5fed49c3c31779f9 100644
--- a/app/api/schemas.py
+++ b/app/api/schemas.py
@@ -1,6 +1,8 @@
-from pydantic import BaseModel, Field
-from typing import Optional, List, Dict
+from pydantic import BaseModel, Field, EmailStr
+from typing import Optional, List, Dict, Literal
 from datetime import datetime
+from .summary import CountSummary, ActivityItem, EngagementSummary
+from .preset import PresetQuestion, PresetCapability, PresetPillar, AssessmentPreset
 
 class AssessmentCreate(BaseModel):
     """Schema for creating an assessment"""
@@ -42,6 +44,24 @@ class ScoreResponse(BaseModel):
     gates_applied: List[str] = []
 
 
+class EngagementCreate(BaseModel):
+    """Schema for creating an engagement"""
+    name: str = Field(..., min_length=1, description="Name of the engagement")
+    client_code: Optional[str] = Field(None, description="Optional client code")
+
+
+class AddMemberRequest(BaseModel):
+    """Schema for adding a member to an engagement"""
+    user_email: EmailStr = Field(..., description="Email of the user to add")
+    role: Optional[Literal["member", "lead"]] = Field("member", description="Role of the member (member/lead)")
+
+
+
+
+
+
+
+
 
 
 
diff --git a/app/api/schemas/__init__.py b/app/api/schemas/__init__.py
new file mode 100644
index 0000000000000000000000000000000000000000..0fe96b03f7299a8f9de14c9c2e0eb28c75aff7a1
--- /dev/null
+++ b/app/api/schemas/__init__.py
@@ -0,0 +1,13 @@
+# Schemas module
+from .summary import CountSummary, ActivityItem, EngagementSummary
+from .preset import PresetQuestion, PresetCapability, PresetPillar, AssessmentPreset
+
+__all__ = [
+    "CountSummary",
+    "ActivityItem", 
+    "EngagementSummary",
+    "PresetQuestion",
+    "PresetCapability",
+    "PresetPillar",
+    "AssessmentPreset"
+]
diff --git a/app/api/schemas/preset.py b/app/api/schemas/preset.py
new file mode 100644
index 0000000000000000000000000000000000000000..ebe846e84546ac66520425e4359452bd5ae933d4
--- /dev/null
+++ b/app/api/schemas/preset.py
@@ -0,0 +1,28 @@
+from pydantic import BaseModel, Field
+from typing import List, Dict, Optional
+
+class PresetQuestion(BaseModel):
+    id: str
+    text: str
+    weight: float = 1.0
+    scale: str = "0-5"
+
+class PresetCapability(BaseModel):
+    id: str
+    name: str
+    questions: List[PresetQuestion]
+
+class PresetPillar(BaseModel):
+    id: str
+    name: str
+    capabilities: List[PresetCapability]
+
+class AssessmentPreset(BaseModel):
+    id: str
+    name: str
+    version: str = "1.0"
+    pillars: List[PresetPillar]
+    # optional metadata
+    generated_at: Optional[str] = None
+    source_file: Optional[str] = None
+    columns_mapping: Optional[Dict[str, str]] = None
diff --git a/app/api/schemas/summary.py b/app/api/schemas/summary.py
new file mode 100644
index 0000000000000000000000000000000000000000..a073ee0b75f2b1c1959e166bee2b95b2e86605c3
--- /dev/null
+++ b/app/api/schemas/summary.py
@@ -0,0 +1,32 @@
+from pydantic import BaseModel
+from typing import Optional, List
+from datetime import datetime
+
+
+class CountSummary(BaseModel):
+    assessments: int
+    documents: int
+    findings: int
+    recommendations: int
+    runlogs: int
+
+
+class ActivityItem(BaseModel):
+    type: str
+    id: str
+    ts: Optional[datetime] = None
+    title: Optional[str] = None
+    extra: Optional[dict] = None
+
+
+class EngagementSummary(BaseModel):
+    engagement_id: str
+    counts: CountSummary
+    last_activity: Optional[datetime] = None
+    recent_activity: List[ActivityItem] = None
+    recent_runlog_excerpt: Optional[str] = None
+
+    def __init__(self, **data):
+        if data.get('recent_activity') is None:
+            data['recent_activity'] = []
+        super().__init__(**data)
diff --git a/app/api/scoring.py b/app/api/scoring.py
index b0fc2d20ac30dd8c4f878e65775ff68f7c8577b6..f6bfd3c242540f4e2cca1087329be51e78b55f20 100644
--- a/app/api/scoring.py
+++ b/app/api/scoring.py
@@ -1,5 +1,5 @@
 from typing import Dict, List, Optional, Tuple
-from app.api.models import Answer
+from .models import Answer
 
 def compute_scores(answers_by_pillar: Dict[str, List[Answer]], preset: dict) -> Tuple[Dict[str, Optional[float]], Optional[float], List[str]]:
     """
diff --git a/app/api/security.py b/app/api/security.py
new file mode 100644
index 0000000000000000000000000000000000000000..dec36761f4692a0fdb6dfbace2bd5bf50b2640a4
--- /dev/null
+++ b/app/api/security.py
@@ -0,0 +1,73 @@
+import os
+import re
+import email.utils
+from fastapi import Header, HTTPException, Depends
+from typing import Dict
+from ..domain.repository import Repository
+
+
+def is_admin(user_email: str) -> bool:
+    """Check if user is an admin based on ADMIN_EMAILS env var"""
+    # Validate email format first
+    if not user_email or not isinstance(user_email, str):
+        return False
+    
+    # Parse and normalize email
+    parsed = email.utils.parseaddr(user_email.strip())
+    if not parsed[1] or '@' not in parsed[1]:
+        return False
+    
+    canonical_email = parsed[1].strip().lower()
+    
+    admins = [e.strip().lower() for e in os.getenv("ADMIN_EMAILS", "").split(",") if e.strip()]
+    return canonical_email in admins
+
+
+async def current_context(
+    x_user_email: str = Header(..., alias="X-User-Email"),
+    x_engagement_id: str = Header(..., alias="X-Engagement-ID")
+) -> Dict[str, str]:
+    """Extract current user and engagement context from headers"""
+    # Validate and sanitize email
+    if not x_user_email or not x_user_email.strip():
+        raise HTTPException(422, "X-User-Email header is required")
+    
+    parsed = email.utils.parseaddr(x_user_email.strip())
+    if not parsed[1] or '@' not in parsed[1]:
+        raise HTTPException(422, "X-User-Email header must be a valid email address")
+    
+    canonical_email = parsed[1].strip().lower()
+    
+    # Validate and sanitize engagement ID
+    if not x_engagement_id or not x_engagement_id.strip():
+        raise HTTPException(422, "X-Engagement-ID header is required")
+    
+    engagement_id_normalized = x_engagement_id.strip()
+    # Basic validation - alphanumeric, hyphens, underscores allowed
+    if not re.match(r'^[a-zA-Z0-9_-]+$', engagement_id_normalized):
+        raise HTTPException(422, "X-Engagement-ID header must contain only alphanumeric characters, hyphens, and underscores")
+    
+    return {"user_email": canonical_email, "engagement_id": engagement_id_normalized}
+
+
+def require_member(repo: Repository, ctx: Dict[str, str], min_role: str = "member"):
+    """Ensure user has required role in the engagement"""
+    m = repo.get_membership(ctx["engagement_id"], ctx["user_email"])
+    
+    # Admin users have access to everything
+    if is_admin(ctx["user_email"]):
+        return
+    
+    # Check membership exists
+    if m is None:
+        raise HTTPException(403, "Not a member of this engagement")
+    
+    # Check role hierarchy
+    if min_role == "lead" and m.role != "lead":
+        raise HTTPException(403, "Lead role required")
+
+
+def require_admin(repo: Repository, ctx: Dict[str, str]):
+    """Ensure user is an admin"""
+    if not is_admin(ctx["user_email"]):
+        raise HTTPException(403, "Admin access required")
diff --git a/app/app.db b/app/app.db
new file mode 100644
index 0000000000000000000000000000000000000000..1fae7284c7e2a3fffea3b6b51bf7ce961a6e3977
GIT binary patch
literal 20480
zcmeI%&u-H&9Kdm>%QhCNbQe_hfaKm<fsoLyNRSn;RCF0+0cocwP$NZ3(=E;h*G;?e
zKzjflf>+^4(x@E)g$Jm<k>dDY68}E-#q#O<X`E~MWs%LJTpoyhVOippltPGBac>v*
z>MG0js!%+wKk`l4mUwpcz1{gG?Dn1L*qtBkyN5rUI#Z7T0tg_000IagfB*srAn=dC
z&Eu`zZm(zEKFXs{iH=h9RcBRdk9_3@N(S!XRLQDN4xGJsCO^9V=#A@3?<A1khw1dG
zboL@+v@vs?=3zsR^EgSOtf}?lQky(pq)qLKzS4=Dc!3(L`k&K9uFYyp<xt-FlVjIE
zlW*0T9K^F>S$A~etI60a>jt%<4yCV-l&`#zI+gb=%NL#D6MLuovS*1no#}7pA}RK`
zVRV@<mgTTQ37=Qb?duoTZnxjJZblX6TIBw-tvc$u$A4hcXs%b$)x^&;ZFHmd=S)Yr
zo`uD3{B<#n!Q@!g-u@fO86LEDy5oLhtn0BB@vie*#fo}RuBvvK?3W1_0tg_000Iag
zfB*srAb<b@2yCi=QwGNVe^aNIxDY@90R#|0009ILKmY**5LgOu{?9@{009ILKmY**
m5I_I{1Q0-A^94Bn-~2fyLIe;%009ILKmY**5I_I{1bzb<^|^Hb

literal 0
HcmV?d00001

diff --git a/app/data/engagements/db.json b/app/data/engagements/db.json
new file mode 100644
index 0000000000000000000000000000000000000000..88029d7f42ed3242ff6fb75ca96f1d1c8768a765
--- /dev/null
+++ b/app/data/engagements/db.json
@@ -0,0 +1,11 @@
+{
+  "engagements": {},
+  "memberships": {},
+  "assessments": {},
+  "questions": {},
+  "responses": {},
+  "findings": {},
+  "recommendations": {},
+  "runlogs": {},
+  "documents": {}
+}
\ No newline at end of file
diff --git a/app/domain/__init__.py b/app/domain/__init__.py
new file mode 100644
index 0000000000000000000000000000000000000000..1732e479fe912bb5d7195618b8133bd5de4582b5
--- /dev/null
+++ b/app/domain/__init__.py
@@ -0,0 +1 @@
+# Domain models package
diff --git a/app/domain/file_repo.py b/app/domain/file_repo.py
new file mode 100644
index 0000000000000000000000000000000000000000..cf4669dd741039a18048abe3e14bb1151b457fb5
--- /dev/null
+++ b/app/domain/file_repo.py
@@ -0,0 +1,297 @@
+import json
+import os
+import tempfile
+import logging
+from datetime import datetime
+from pathlib import Path
+from typing import Dict, List, Optional
+import threading
+from .models import Assessment, Question, Response, Finding, Recommendation, RunLog, Engagement, Membership, Document
+from .repository import Repository
+
+logger = logging.getLogger(__name__)
+
+
+class FileRepository(Repository):
+    def __init__(self, base_path: str = "data/engagements"):
+        self.base_path = Path(base_path)
+        self.base_path.mkdir(parents=True, exist_ok=True)
+        self._lock = threading.RLock()
+        self._db_file = self.base_path / "db.json"
+        self._load_db()
+
+    def _load_db(self):
+        """Load the database from file or create empty structure"""
+        if self._db_file.exists():
+            try:
+                with open(self._db_file, 'r', encoding='utf-8') as f:
+                    data = json.load(f)
+                    self._db = {
+                        "engagements": {k: Engagement(**v) for k, v in data.get("engagements", {}).items()},
+                        "memberships": {k: Membership(**v) for k, v in data.get("memberships", {}).items()},
+                        "assessments": {k: Assessment(**v) for k, v in data.get("assessments", {}).items()},
+                        "questions": {k: Question(**v) for k, v in data.get("questions", {}).items()},
+                        "responses": {k: Response(**v) for k, v in data.get("responses", {}).items()},
+                        "findings": {k: Finding(**v) for k, v in data.get("findings", {}).items()},
+                        "recommendations": {k: Recommendation(**v) for k, v in data.get("recommendations", {}).items()},
+                        "runlogs": {k: RunLog(**v) for k, v in data.get("runlogs", {}).items()},
+                        "documents": {k: Document(**v) for k, v in data.get("documents", {}).items()}
+                    }
+            except (json.JSONDecodeError, OSError) as e:
+                logger.error(f"Failed to load database from {self._db_file}: {e}")
+                # Create a backup of the corrupted file
+                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
+                backup_path = self._db_file.with_suffix(f".backup_{timestamp}.json")
+                try:
+                    if self._db_file.exists():
+                        self._db_file.rename(backup_path)
+                        logger.info(f"Corrupted database backed up to {backup_path}")
+                except Exception as backup_error:
+                    logger.error(f"Failed to create backup: {backup_error}")
+                
+                # Initialize with empty structure
+                self._init_empty_db()
+            except Exception as e:
+                logger.exception(f"Unexpected error loading database: {e}")
+                self._init_empty_db()
+        else:
+            self._init_empty_db()
+    
+    def _init_empty_db(self):
+        """Initialize an empty database structure"""
+        self._db = {
+            "engagements": {},
+            "memberships": {},
+            "assessments": {},
+            "questions": {},
+            "responses": {},
+            "findings": {},
+            "recommendations": {},
+            "runlogs": {},
+            "documents": {}
+        }
+        self._save_db()
+
+    def _save_db(self):
+        """Save the database to file atomically"""
+        data = {
+            collection: {k: v.model_dump(mode='json') for k, v in items.items()}
+            for collection, items in self._db.items()
+        }
+        
+        # Use atomic write to prevent corruption
+        temp_file = None
+        try:
+            # Create temporary file in the same directory
+            with tempfile.NamedTemporaryFile(
+                mode='w', 
+                dir=self._db_file.parent, 
+                prefix=f".{self._db_file.name}_tmp_",
+                suffix='.json',
+                delete=False,
+                encoding='utf-8'
+            ) as f:
+                temp_file = f.name
+                json.dump(data, f, indent=2, default=str)
+                f.flush()
+                os.fsync(f.fileno())
+            
+            # Atomically replace the target file
+            os.replace(temp_file, self._db_file)
+            temp_file = None  # Successfully moved, don't clean up
+            
+            # Optionally fsync the directory (for maximum durability)
+            try:
+                dir_fd = os.open(self._db_file.parent, os.O_RDONLY)
+                os.fsync(dir_fd)
+                os.close(dir_fd)
+            except (OSError, AttributeError):
+                # Directory fsync not supported on all platforms
+                pass
+                
+        except Exception as e:
+            logger.error(f"Failed to save database: {e}")
+            # Clean up temp file on error
+            if temp_file and os.path.exists(temp_file):
+                try:
+                    os.unlink(temp_file)
+                except OSError:
+                    pass
+            raise
+
+    # Engagement & Membership methods
+    def create_engagement(self, e: Engagement) -> Engagement:
+        with self._lock:
+            if e.id in self._db["engagements"]:
+                raise ValueError(f"Engagement with ID {e.id} already exists")
+            self._db["engagements"][e.id] = e
+            self._save_db()
+            return e
+
+    def list_engagements_for_user(self, user_email: str, admin: bool) -> List[Engagement]:
+        with self._lock:
+            if admin:
+                return list(self._db["engagements"].values())
+            else:
+                # Get engagements where user is a member
+                user_engagement_ids = {m.engagement_id for m in self._db["memberships"].values() 
+                                       if m.user_email.lower() == user_email.lower()}
+                return [e for e in self._db["engagements"].values() if e.id in user_engagement_ids]
+
+    def add_membership(self, m: Membership) -> Membership:
+        with self._lock:
+            # Check if membership already exists
+            existing = [mem for mem in self._db["memberships"].values() 
+                        if mem.engagement_id == m.engagement_id and mem.user_email.lower() == m.user_email.lower()]
+            if existing:
+                raise ValueError(f"User {m.user_email} is already a member of engagement {m.engagement_id}")
+            self._db["memberships"][m.id] = m
+            self._save_db()
+            return m
+
+    def get_membership(self, engagement_id: str, user_email: str) -> Optional[Membership]:
+        with self._lock:
+            for m in self._db["memberships"].values():
+                if m.engagement_id == engagement_id and m.user_email.lower() == user_email.lower():
+                    return m
+            return None
+
+    # Assessment methods
+    def create_assessment(self, a: Assessment) -> Assessment:
+        with self._lock:
+            if a.id in self._db["assessments"]:
+                raise ValueError(f"Assessment with ID {a.id} already exists")
+            if not hasattr(a, 'engagement_id') or not a.engagement_id:
+                raise ValueError("Assessment must have an engagement_id")
+            self._db["assessments"][a.id] = a
+            self._save_db()
+            return a
+
+    def get_assessment(self, assessment_id: str) -> Optional[Assessment]:
+        with self._lock:
+            return self._db["assessments"].get(assessment_id)
+
+    def list_assessments(self, engagement_id: str) -> List[Assessment]:
+        with self._lock:
+            return [a for a in self._db["assessments"].values() if a.engagement_id == engagement_id]
+
+    # Question and Response methods
+    def add_question(self, q: Question) -> Question:
+        with self._lock:
+            self._db["questions"][q.id] = q
+            self._save_db()
+            return q
+
+    def save_response(self, r: Response) -> Response:
+        with self._lock:
+            self._db["responses"][r.id] = r
+            self._save_db()
+            return r
+
+    # Finding methods
+    def add_findings(self, assessment_id: str, items: List[Finding]) -> List[Finding]:
+        with self._lock:
+            result = []
+            for f in items:
+                # Validate assessment_id consistency
+                if f.assessment_id and f.assessment_id != assessment_id:
+                    raise ValueError(f"Finding {f.id} has mismatched assessment_id: {f.assessment_id} != {assessment_id}")
+                # Create a copy to avoid mutating the original
+                f_copy = f.model_copy()
+                f_copy.assessment_id = assessment_id
+                self._db["findings"][f_copy.id] = f_copy
+                result.append(f_copy)
+            self._save_db()
+            return result
+
+    def get_findings(self, engagement_id: str) -> List[Finding]:
+        with self._lock:
+            # Get all findings for assessments in this engagement
+            engagement_assessment_ids = {a.id for a in self._db["assessments"].values() if a.engagement_id == engagement_id}
+            return [f for f in self._db["findings"].values() if f.assessment_id in engagement_assessment_ids]
+
+    # Recommendation methods
+    def add_recommendations(self, assessment_id: str, items: List[Recommendation]) -> List[Recommendation]:
+        with self._lock:
+            result = []
+            for rec in items:
+                # Validate required fields
+                if not rec.id:
+                    raise ValueError("Recommendation must have an ID")
+                if not rec.title:
+                    raise ValueError(f"Recommendation {rec.id} must have a title")
+                # Validate assessment_id consistency
+                if rec.assessment_id and rec.assessment_id != assessment_id:
+                    raise ValueError(f"Recommendation {rec.id} has mismatched assessment_id: {rec.assessment_id} != {assessment_id}")
+                # Create a copy to avoid mutating the original
+                rec_copy = rec.model_copy()
+                rec_copy.assessment_id = assessment_id
+                self._db["recommendations"][rec_copy.id] = rec_copy
+                result.append(rec_copy)
+            self._save_db()
+            return result
+
+    def get_recommendations(self, engagement_id: str) -> List[Recommendation]:
+        with self._lock:
+            # Get all recommendations for assessments in this engagement
+            engagement_assessment_ids = {a.id for a in self._db["assessments"].values() if a.engagement_id == engagement_id}
+            return [r for r in self._db["recommendations"].values() if r.assessment_id in engagement_assessment_ids]
+
+    # RunLog methods
+    def add_runlog(self, log: RunLog) -> RunLog:
+        with self._lock:
+            # Validate required fields
+            if not log.assessment_id:
+                raise ValueError("RunLog must have an assessment_id")
+            self._db["runlogs"][log.id] = log
+            self._save_db()
+            return log
+
+    def get_runlogs(self, engagement_id: str) -> List[RunLog]:
+        with self._lock:
+            # Get all runlogs for assessments in this engagement
+            engagement_assessment_ids = {a.id for a in self._db["assessments"].values() if a.engagement_id == engagement_id}
+            return [log for log in self._db["runlogs"].values() if log.assessment_id in engagement_assessment_ids]
+    
+    # Document methods
+    def add_document(self, d: Document) -> Document:
+        with self._lock:
+            self._db["documents"][d.id] = d
+            self._save_db()
+            return d
+    
+    def list_documents(self, engagement_id: str) -> List[Document]:
+        with self._lock:
+            return [d for d in self._db["documents"].values() if d.engagement_id == engagement_id]
+    
+    def get_document(self, engagement_id: str, doc_id: str) -> Optional[Document]:
+        with self._lock:
+            doc = self._db["documents"].get(doc_id)
+            if not doc or doc.engagement_id != engagement_id:
+                return None
+            return doc
+    
+    def delete_document(self, engagement_id: str, doc_id: str) -> bool:
+        with self._lock:
+            doc = self._db["documents"].get(doc_id)
+            if not doc or doc.engagement_id != engagement_id:
+                return False
+            # Attempt to remove file from disk
+            import os
+            if os.path.exists(doc.path):
+                try:
+                    os.remove(doc.path)
+                    logger.info(f"Successfully deleted file: {doc.path}")
+                except FileNotFoundError:
+                    # File was already deleted, this is not fatal
+                    logger.info(f"File already deleted: {doc.path}")
+                except OSError as e:
+                    # Log the error but continue with DB record deletion
+                    logger.warning(f"Failed to delete file {doc.path} for document {doc_id} in engagement {engagement_id}: {e}")
+            else:
+                logger.info(f"File does not exist, skipping deletion: {doc.path}")
+            
+            # Always remove from database even if file deletion failed
+            self._db["documents"].pop(doc_id, None)
+            self._save_db()
+            return True
diff --git a/app/domain/models.py b/app/domain/models.py
new file mode 100644
index 0000000000000000000000000000000000000000..c9f247214d9ca0342b9cb351b9023fd2ae1c7fa4
--- /dev/null
+++ b/app/domain/models.py
@@ -0,0 +1,75 @@
+from __future__ import annotations
+from typing import List, Optional, Literal
+from pydantic import BaseModel, Field
+from datetime import datetime, timezone
+import uuid
+
+Role = Literal["lead", "member"]
+
+class Engagement(BaseModel):
+    id: str = Field(default_factory=lambda: str(uuid.uuid4()))
+    name: str
+    client_code: Optional[str] = None
+    created_by: str
+    created_at: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))
+
+class Membership(BaseModel):
+    id: str = Field(default_factory=lambda: str(uuid.uuid4()))
+    engagement_id: str
+    user_email: str
+    role: Role = "member"
+    added_at: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))
+
+class Assessment(BaseModel):
+    id: str = Field(default_factory=lambda: str(uuid.uuid4()))
+    name: str
+    engagement_id: str
+    framework: Literal["NIST-CSF", "ISO-27001", "CIS", "Custom"] = "NIST-CSF"
+    created_at: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))
+
+class Question(BaseModel):
+    id: str = Field(default_factory=lambda: str(uuid.uuid4()))
+    assessment_id: str
+    text: str
+    pillar: Optional[str] = None
+
+class Response(BaseModel):
+    id: str = Field(default_factory=lambda: str(uuid.uuid4()))
+    assessment_id: str
+    question_id: str
+    answer: str
+
+class Finding(BaseModel):
+    id: str = Field(default_factory=lambda: str(uuid.uuid4()))
+    assessment_id: str
+    title: str
+    evidence: Optional[str] = None
+    severity: Literal["low", "medium", "high"] = "medium"
+    area: Optional[str] = None  # e.g., Identity, Data, SecOps
+
+class Recommendation(BaseModel):
+    id: str = Field(default_factory=lambda: str(uuid.uuid4()))
+    assessment_id: str
+    title: str
+    rationale: Optional[str] = None
+    priority: Literal["P1", "P2", "P3"] = "P2"
+    effort: Literal["S", "M", "L"] = "M"
+    timeline_weeks: Optional[int] = None
+
+class RunLog(BaseModel):
+    id: str = Field(default_factory=lambda: str(uuid.uuid4()))
+    assessment_id: str
+    agent: str  # "DocAnalyzer" | "GapRecommender" | etc.
+    input_preview: Optional[str] = None
+    output_preview: Optional[str] = None
+    created_at: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))
+
+class Document(BaseModel):
+    id: str = Field(default_factory=lambda: str(uuid.uuid4()))
+    engagement_id: str
+    filename: str
+    content_type: Optional[str] = None
+    size: int = 0
+    path: str  # absolute or repo-root relative path on disk
+    uploaded_by: str
+    uploaded_at: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))
diff --git a/app/domain/repository.py b/app/domain/repository.py
new file mode 100644
index 0000000000000000000000000000000000000000..747aeab28d111bda114ef8753df4f2537fb539ba
--- /dev/null
+++ b/app/domain/repository.py
@@ -0,0 +1,202 @@
+from __future__ import annotations
+import threading
+import logging
+from typing import Dict, List, Optional
+from .models import Assessment, Question, Response, Finding, Recommendation, RunLog, Engagement, Membership, Document
+
+logger = logging.getLogger(__name__)
+
+class Repository:
+    # Engagements & Memberships
+    def create_engagement(self, e: Engagement) -> Engagement: ...
+    def list_engagements_for_user(self, user_email: str, admin: bool) -> List[Engagement]: ...
+    def add_membership(self, m: Membership) -> Membership: ...
+    def get_membership(self, engagement_id: str, user_email: str) -> Optional[Membership]: ...
+    
+    # Existing domain (must be scoped by engagement_id)
+    def create_assessment(self, a: Assessment) -> Assessment: ...
+    def get_assessment(self, assessment_id: str) -> Optional[Assessment]: ...
+    def list_assessments(self, engagement_id: str) -> List[Assessment]: ...
+    def add_question(self, q: Question) -> Question: ...
+    def save_response(self, r: Response) -> Response: ...
+    def add_findings(self, assessment_id: str, items: List[Finding]) -> List[Finding]: ...
+    def add_recommendations(self, assessment_id: str, items: List[Recommendation]) -> List[Recommendation]: ...
+    def add_runlog(self, log: RunLog) -> RunLog: ...
+    def get_findings(self, engagement_id: str) -> List[Finding]: ...
+    def get_recommendations(self, engagement_id: str) -> List[Recommendation]: ...
+    def get_runlogs(self, engagement_id: str) -> List[RunLog]: ...
+    
+    # Documents
+    def add_document(self, d: Document) -> Document: ...
+    def list_documents(self, engagement_id: str) -> List[Document]: ...
+    def get_document(self, engagement_id: str, doc_id: str) -> Optional[Document]: ...
+    def delete_document(self, engagement_id: str, doc_id: str) -> bool: ...
+
+class InMemoryRepository(Repository):
+    def __init__(self):
+        self.assessments: Dict[str, Assessment] = {}
+        self.questions: Dict[str, Question] = {}
+        self.responses: Dict[str, Response] = {}
+        self.findings: Dict[str, Finding] = {}
+        self.recommendations: Dict[str, Recommendation] = {}
+        self.runlogs: Dict[str, RunLog] = {}
+        self.engagements: Dict[str, Engagement] = {}
+        self.memberships: Dict[str, Membership] = {}
+        self.documents: Dict[str, Document] = {}
+        # Thread safety lock
+        self._lock = threading.RLock()
+
+    # Engagement & Membership methods
+    def create_engagement(self, e: Engagement) -> Engagement:
+        with self._lock:
+            if e.id in self.engagements:
+                raise ValueError(f"Engagement with ID {e.id} already exists")
+            self.engagements[e.id] = e
+            return e
+
+    def list_engagements_for_user(self, user_email: str, admin: bool) -> List[Engagement]:
+        with self._lock:
+            if admin:
+                return list(self.engagements.values())
+            else:
+                # Get engagements where user is a member
+                user_engagement_ids = {m.engagement_id for m in self.memberships.values() 
+                                       if m.user_email.lower() == user_email.lower()}
+                return [e for e in self.engagements.values() if e.id in user_engagement_ids]
+
+    def add_membership(self, m: Membership) -> Membership:
+        with self._lock:
+            # Check if membership already exists
+            existing = [mem for mem in self.memberships.values() 
+                        if mem.engagement_id == m.engagement_id and mem.user_email.lower() == m.user_email.lower()]
+            if existing:
+                raise ValueError(f"User {m.user_email} is already a member of engagement {m.engagement_id}")
+            self.memberships[m.id] = m
+            return m
+
+    def get_membership(self, engagement_id: str, user_email: str) -> Optional[Membership]:
+        with self._lock:
+            for m in self.memberships.values():
+                if m.engagement_id == engagement_id and m.user_email.lower() == user_email.lower():
+                    return m
+            return None
+
+    def create_assessment(self, a: Assessment) -> Assessment:
+        with self._lock:
+            # Check if assessment already exists
+            if a.id in self.assessments:
+                raise ValueError(f"Assessment with ID {a.id} already exists")
+            self.assessments[a.id] = a
+            return a
+
+    def get_assessment(self, assessment_id: str) -> Optional[Assessment]:
+        with self._lock:
+            return self.assessments.get(assessment_id)
+
+    def list_assessments(self, engagement_id: str) -> List[Assessment]:
+        with self._lock:
+            return [a for a in self.assessments.values() if a.engagement_id == engagement_id]
+
+    def add_question(self, q: Question) -> Question:
+        with self._lock:
+            self.questions[q.id] = q
+            return q
+
+    def save_response(self, r: Response) -> Response:
+        with self._lock:
+            self.responses[r.id] = r
+            return r
+
+    def add_findings(self, engagement_id: str, items: List[Finding]) -> List[Finding]:
+        with self._lock:
+            result = []
+            for f in items:
+                # Validate engagement_id consistency
+                if f.engagement_id and f.engagement_id != engagement_id:
+                    raise ValueError(f"Finding {f.id} has mismatched engagement_id: {f.engagement_id} != {engagement_id}")
+                # Create a copy to avoid mutating the original
+                f_copy = f.model_copy()
+                f_copy.engagement_id = engagement_id
+                self.findings[f_copy.id] = f_copy
+                result.append(f_copy)
+            return result
+
+    def add_recommendations(self, assessment_id: str, items: List[Recommendation]) -> List[Recommendation]:
+        with self._lock:
+            result = []
+            for rec in items:
+                # Validate required fields
+                if not rec.id:
+                    raise ValueError("Recommendation must have an ID")
+                if not rec.title:
+                    raise ValueError(f"Recommendation {rec.id} must have a title")
+                # Validate assessment_id consistency
+                if rec.assessment_id and rec.assessment_id != assessment_id:
+                    raise ValueError(f"Recommendation {rec.id} has mismatched assessment_id: {rec.assessment_id} != {assessment_id}")
+                # Create a copy to avoid mutating the original
+                rec_copy = rec.model_copy()
+                rec_copy.assessment_id = assessment_id
+                self.recommendations[rec_copy.id] = rec_copy
+                result.append(rec_copy)
+            return result
+
+    def add_runlog(self, log: RunLog) -> RunLog:
+        with self._lock:
+            # Validate required fields
+            if not log.assessment_id:
+                raise ValueError("RunLog must have an assessment_id")
+            self.runlogs[log.id] = log
+            return log
+
+    def get_findings(self, engagement_id: str) -> List[Finding]:
+        with self._lock:
+            # Get all findings for assessments in this engagement
+            engagement_assessment_ids = {a.id for a in self.assessments.values() if a.engagement_id == engagement_id}
+            return [f for f in self.findings.values() if f.assessment_id in engagement_assessment_ids]
+
+    def get_recommendations(self, engagement_id: str) -> List[Recommendation]:
+        with self._lock:
+            # Get all recommendations for assessments in this engagement
+            engagement_assessment_ids = {a.id for a in self.assessments.values() if a.engagement_id == engagement_id}
+            return [r for r in self.recommendations.values() if r.assessment_id in engagement_assessment_ids]
+
+    def get_runlogs(self, engagement_id: str) -> List[RunLog]:
+        with self._lock:
+            # Get all runlogs for assessments in this engagement
+            engagement_assessment_ids = {a.id for a in self.assessments.values() if a.engagement_id == engagement_id}
+            return [log for log in self.runlogs.values() if log.assessment_id in engagement_assessment_ids]
+    
+    # Document methods
+    def add_document(self, d: Document) -> Document:
+        with self._lock:
+            if d.id in self.documents:
+                raise ValueError(f"Document with ID {d.id} already exists")
+            self.documents[d.id] = d
+            return d
+    
+    def list_documents(self, engagement_id: str) -> List[Document]:
+        with self._lock:
+            return [d for d in self.documents.values() if d.engagement_id == engagement_id]
+    
+    def get_document(self, engagement_id: str, doc_id: str) -> Optional[Document]:
+        with self._lock:
+            doc = self.documents.get(doc_id)
+            if not doc or doc.engagement_id != engagement_id:
+                return None
+            return doc
+    
+    def delete_document(self, engagement_id: str, doc_id: str) -> bool:
+        with self._lock:
+            doc = self.documents.get(doc_id)
+            if not doc or doc.engagement_id != engagement_id:
+                return False
+            # Attempt to remove file from disk
+            import os
+            if os.path.exists(doc.path):
+                try:
+                    os.remove(doc.path)
+                except OSError as e:
+                    logger.warning(f"Failed to delete file {doc.path} for document {doc_id} in engagement {engagement_id}: {e}")
+            # Always remove document from memory even if file deletion failed
+            del self.documents[doc_id]
+            return True
diff --git a/app/requirements.txt b/app/requirements.txt
index c86bd61a720c640a49dc14ec19f9ac2c199054a3..2f823f2b6192bc9467e40a6257c450e72d58a8fc 100644
--- a/app/requirements.txt
+++ b/app/requirements.txt
@@ -5,3 +5,6 @@ pydantic>=2.7
 azure-storage-blob>=12.19
 azure-identity>=1.17
 python-dotenv>=1.0
+openai>=1.30.0,<2.0.0
+pypdf>=4.2.0
+python-docx>=1.1.2
diff --git a/app/services/__init__.py b/app/services/__init__.py
new file mode 100644
index 0000000000000000000000000000000000000000..0557eb635c5522686a57e633065437599726336a
--- /dev/null
+++ b/app/services/__init__.py
@@ -0,0 +1 @@
+# Services module
diff --git a/app/services/presets.py b/app/services/presets.py
new file mode 100644
index 0000000000000000000000000000000000000000..5bd57e98cd2e38501674d60e45a0628ced79f4af
--- /dev/null
+++ b/app/services/presets.py
@@ -0,0 +1,110 @@
+import os, json, re
+from pathlib import Path
+from typing import List, Dict, Any
+from fastapi import HTTPException
+from ..api.schemas import AssessmentPreset
+
+BUNDLED: Dict[str, Path] = {}  # filled at startup with any bundled presets (e.g. cyber-for-ai.json)
+DATA_DIR = Path("data/presets")
+
+def ensure_dirs():
+    DATA_DIR.mkdir(parents=True, exist_ok=True)
+
+def _load_json(p: Path) -> Dict[str, Any]:
+    try:
+        with p.open("r", encoding="utf-8") as f:
+            return json.load(f)
+    except json.JSONDecodeError as e:
+        raise HTTPException(400, f"Invalid JSON in {p.name}: {e}") from e
+    except OSError as e:
+        raise HTTPException(500, f"File I/O error for {p.name}: {e}") from e
+
+def _slug(s: str) -> str:
+    s = s.strip().lower()
+    s = re.sub(r"[^a-z0-9]+", "-", s)
+    return s.strip("-")[:40] or "preset"
+
+def list_presets() -> List[Dict[str, Any]]:
+    ensure_dirs()
+    items: List[Dict[str, Any]] = []
+
+    # bundled
+    for pid, path in BUNDLED.items():
+        data = _load_json(path)
+        try:
+            preset = AssessmentPreset(**data)
+            counts = {
+                "pillars": len(preset.pillars),
+                "capabilities": sum(len(p.capabilities) for p in preset.pillars),
+                "questions": sum(len(c.questions) for p in preset.pillars for c in p.capabilities),
+            }
+            items.append({"id": preset.id, "name": preset.name, "version": preset.version, "source": "bundled", "counts": counts})
+        except Exception:
+            continue
+
+    # uploaded
+    for p in DATA_DIR.glob("*.json"):
+        data = _load_json(p)
+        try:
+            preset = AssessmentPreset(**data)
+            counts = {
+                "pillars": len(preset.pillars),
+                "capabilities": sum(len(p.capabilities) for p in preset.pillars),
+                "questions": sum(len(c.questions) for p in preset.pillars for c in p.capabilities),
+            }
+            items.append({"id": preset.id, "name": preset.name, "version": preset.version, "source": "uploaded", "counts": counts})
+        except Exception:
+            continue
+
+    # unique by id (prefer uploaded over bundled)
+    out = {}
+    for it in items:
+        out[it["id"]] = it
+    return list(out.values())
+
+def get_preset(preset_id: str) -> AssessmentPreset:
+    ensure_dirs()
+    # uploaded takes precedence
+    up = DATA_DIR / f"{preset_id}.json"
+    if up.exists():
+        return AssessmentPreset(**_load_json(up))
+    # then bundled
+    path = BUNDLED.get(preset_id)
+    if path and path.exists():
+        return AssessmentPreset(**_load_json(path))
+    raise HTTPException(404, "Preset not found")
+
+def save_uploaded_preset(data: dict) -> AssessmentPreset:
+    ensure_dirs()
+    preset = AssessmentPreset(**data)
+    
+    # Validate preset.id to prevent path traversal
+    safe_id = _validate_safe_filename(preset.id)
+    out = DATA_DIR / f"{safe_id}.json"
+    
+    # Verify the resolved path is within DATA_DIR
+    if not out.resolve().is_relative_to(DATA_DIR.resolve()):
+        raise HTTPException(400, f"Invalid preset ID: path traversal detected")
+    
+    with out.open("w", encoding="utf-8") as f:
+        json.dump(preset.model_dump(), f, ensure_ascii=False, indent=2)
+    return preset
+
+def _validate_safe_filename(filename: str) -> str:
+    """Validate and sanitize filename to prevent path traversal"""
+    # Remove any path separators and dangerous characters
+    safe_filename = re.sub(r'[^A-Za-z0-9_.-]', '', filename)
+    
+    # Enforce reasonable length limit
+    if len(safe_filename) > 100:
+        safe_filename = safe_filename[:100]
+    
+    # Ensure it's not empty after sanitization
+    if not safe_filename:
+        raise HTTPException(400, "Invalid preset ID: contains only unsafe characters")
+    
+    # Prevent special filenames
+    if safe_filename in ('.', '..') or safe_filename.startswith('.'):
+        raise HTTPException(400, f"Invalid preset ID: '{safe_filename}' is not allowed")
+    
+    return safe_filename
diff --git a/app/util/__init__.py b/app/util/__init__.py
new file mode 100644
index 0000000000000000000000000000000000000000..4c8e366cc9b05395a656291c5c9a36e270992aad
--- /dev/null
+++ b/app/util/__init__.py
@@ -0,0 +1 @@
+# Utilities module
diff --git a/app/util/files.py b/app/util/files.py
new file mode 100644
index 0000000000000000000000000000000000000000..ae6c9d9a28f446b4bf31860c10bffa196581301d
--- /dev/null
+++ b/app/util/files.py
@@ -0,0 +1,76 @@
+import os
+import io
+from typing import Tuple, Optional
+from pydantic import BaseModel
+
+class ExtractResult(BaseModel):
+    text: str
+    page_count: int | None = None
+    note: Optional[str] = None
+
+def safe_join(*parts: str) -> str:
+    """Safely join path parts preventing directory traversal attacks"""
+    if not parts:
+        raise ValueError("At least one path part is required")
+    
+    base = parts[0]
+    # Resolve base to absolute path
+    abs_base = os.path.abspath(base)
+    
+    # Join all parts
+    joined_path = os.path.join(*parts)
+    # Resolve the final path to absolute (resolving symlinks for security)
+    abs_joined = os.path.abspath(os.path.realpath(joined_path))
+    
+    # Verify the resulting path is within the base directory
+    try:
+        # Get the common path between base and result
+        common = os.path.commonpath([abs_base, abs_joined])
+        # If common path is not the base directory or a parent of it, it's a traversal attempt
+        if not (abs_joined.startswith(abs_base + os.sep) or abs_joined == abs_base):
+            raise ValueError(f"Path traversal detected: resulting path '{abs_joined}' is outside base directory '{abs_base}'")
+    except ValueError as e:
+        if "Path traversal detected" in str(e):
+            raise
+        # os.path.commonpath can raise ValueError for paths on different drives (Windows)
+        raise ValueError(f"Invalid path operation: {e}")
+    
+    return abs_joined
+
+def extract_text(path: str, content_type: Optional[str], max_chars: int = 20000) -> ExtractResult:
+    # simple heuristics by extension; avoid heavy deps
+    ext = os.path.splitext(path)[1].lower()
+    text = ""
+    pages = None
+    note = None
+    try:
+        if ext == ".pdf":
+            try:
+                from pypdf import PdfReader
+            except Exception as e:
+                return ExtractResult(text="", page_count=None, note=f"PDF parser missing: {e}")
+            r = PdfReader(path)
+            pages = len(r.pages)
+            for i, pg in enumerate(r.pages):
+                text += (pg.extract_text() or "") + "\n"
+                if len(text) >= max_chars:
+                    note = "Truncated"
+                    break
+        elif ext in (".docx",):
+            try:
+                import docx
+            except Exception as e:
+                return ExtractResult(text="", page_count=None, note=f"DOCX parser missing: {e}")
+            d = docx.Document(path)
+            text = "\n".join(p.text for p in d.paragraphs if p.text)
+            if len(text) > max_chars:
+                text = text[:max_chars]
+                note = "Truncated"
+        else:
+            with open(path, "r", encoding="utf-8", errors="ignore") as f:
+                text = f.read(max_chars)
+                if f.read(1):
+                    note = "Truncated"
+    except Exception as e:
+        return ExtractResult(text="", page_count=None, note=f"Extract error: {e}")
+    return ExtractResult(text=text, page_count=pages, note=note)
diff --git a/cscm-v3-test.json b/cscm-v3-test.json
new file mode 100644
index 0000000000000000000000000000000000000000..a5119d57c93c8f75f0673cbb475f28ef78132b6f
--- /dev/null
+++ b/cscm-v3-test.json
@@ -0,0 +1,79 @@
+{
+  "id": "cscm-v3",
+  "name": "Cyber Security Capability Model v3",
+  "version": "3.0",
+  "pillars": [
+    {
+      "id": "governance",
+      "name": "Governance & Risk Management",
+      "capabilities": [
+        {
+          "id": "policy-mgmt",
+          "name": "Policy Management",
+          "questions": [
+            {
+              "id": "gov-01",
+              "text": "Is there an approved cybersecurity policy framework with defined roles and responsibilities?",
+              "weight": 1.0,
+              "scale": "0-5"
+            },
+            {
+              "id": "gov-02", 
+              "text": "Are cybersecurity risk assessments performed regularly and tracked in a risk register?",
+              "weight": 1.0,
+              "scale": "0-5"
+            }
+          ]
+        }
+      ]
+    },
+    {
+      "id": "identity",
+      "name": "Identity & Access Management",
+      "capabilities": [
+        {
+          "id": "access-controls",
+          "name": "Access Controls",
+          "questions": [
+            {
+              "id": "iam-01",
+              "text": "Is multi-factor authentication enforced for all privileged accounts?",
+              "weight": 1.0,
+              "scale": "0-5"
+            },
+            {
+              "id": "iam-02",
+              "text": "Are access rights reviewed and recertified on a regular basis?",
+              "weight": 1.0,
+              "scale": "0-5"
+            }
+          ]
+        }
+      ]
+    },
+    {
+      "id": "detection",
+      "name": "Detection & Response",
+      "capabilities": [
+        {
+          "id": "monitoring",
+          "name": "Security Monitoring",
+          "questions": [
+            {
+              "id": "det-01",
+              "text": "Are security events monitored and analyzed in real-time with documented alerting procedures?",
+              "weight": 1.0,
+              "scale": "0-5"
+            },
+            {
+              "id": "det-02",
+              "text": "Is there an incident response plan that is tested and updated regularly?",
+              "weight": 1.0,
+              "scale": "0-5"
+            }
+          ]
+        }
+      ]
+    }
+  ]
+}
diff --git a/data/engagements/db.json b/data/engagements/db.json
new file mode 100644
index 0000000000000000000000000000000000000000..88029d7f42ed3242ff6fb75ca96f1d1c8768a765
--- /dev/null
+++ b/data/engagements/db.json
@@ -0,0 +1,11 @@
+{
+  "engagements": {},
+  "memberships": {},
+  "assessments": {},
+  "questions": {},
+  "responses": {},
+  "findings": {},
+  "recommendations": {},
+  "runlogs": {},
+  "documents": {}
+}
\ No newline at end of file
diff --git a/data/presets/cyber-for-ai-simple.json b/data/presets/cyber-for-ai-simple.json
new file mode 100644
index 0000000000000000000000000000000000000000..774fce8600d913be48c8f887d8d74b7c352e84ab
--- /dev/null
+++ b/data/presets/cyber-for-ai-simple.json
@@ -0,0 +1,67 @@
+{
+  "id": "cyber-for-ai-simple",
+  "name": "Cyber for AI (Simple)",
+  "version": "1.0",
+  "pillars": [
+    {
+      "id": "governance",
+      "name": "Governance & Responsible AI",
+      "capabilities": [
+        {
+          "id": "policy-mgmt",
+          "name": "Policy Management",
+          "questions": [
+            {
+              "id": "gov-01",
+              "text": "Is there an approved AI policy with roles, intake workflow, and risk approvals?",
+              "weight": 1.0,
+              "scale": "0-5"
+            },
+            {
+              "id": "gov-02",
+              "text": "Are AI risk assessments performed per use case and tracked in a risk register?",
+              "weight": 1.0,
+              "scale": "0-5"
+            }
+          ]
+        }
+      ]
+    },
+    {
+      "id": "model_security",
+      "name": "Model & Prompt Security",
+      "capabilities": [
+        {
+          "id": "prompt-security",
+          "name": "Prompt Security",
+          "questions": [
+            {
+              "id": "mod-01",
+              "text": "Are prompt-injection and data-exfiltration tests executed per release with documented mitigations?",
+              "weight": 1.0,
+              "scale": "0-5"
+            }
+          ]
+        }
+      ]
+    },
+    {
+      "id": "data_security",
+      "name": "Data Security & Privacy",
+      "capabilities": [
+        {
+          "id": "data-protection",
+          "name": "Data Protection",
+          "questions": [
+            {
+              "id": "data-01",
+              "text": "Is training/inference data classified, access-controlled, and protected by preventive DLP where appropriate?",
+              "weight": 1.0,
+              "scale": "0-5"
+            }
+          ]
+        }
+      ]
+    }
+  ]
+}
diff --git a/imports/preset_cscm_v3.json b/imports/preset_cscm_v3.json
new file mode 100644
index 0000000000000000000000000000000000000000..a5119d57c93c8f75f0673cbb475f28ef78132b6f
--- /dev/null
+++ b/imports/preset_cscm_v3.json
@@ -0,0 +1,79 @@
+{
+  "id": "cscm-v3",
+  "name": "Cyber Security Capability Model v3",
+  "version": "3.0",
+  "pillars": [
+    {
+      "id": "governance",
+      "name": "Governance & Risk Management",
+      "capabilities": [
+        {
+          "id": "policy-mgmt",
+          "name": "Policy Management",
+          "questions": [
+            {
+              "id": "gov-01",
+              "text": "Is there an approved cybersecurity policy framework with defined roles and responsibilities?",
+              "weight": 1.0,
+              "scale": "0-5"
+            },
+            {
+              "id": "gov-02", 
+              "text": "Are cybersecurity risk assessments performed regularly and tracked in a risk register?",
+              "weight": 1.0,
+              "scale": "0-5"
+            }
+          ]
+        }
+      ]
+    },
+    {
+      "id": "identity",
+      "name": "Identity & Access Management",
+      "capabilities": [
+        {
+          "id": "access-controls",
+          "name": "Access Controls",
+          "questions": [
+            {
+              "id": "iam-01",
+              "text": "Is multi-factor authentication enforced for all privileged accounts?",
+              "weight": 1.0,
+              "scale": "0-5"
+            },
+            {
+              "id": "iam-02",
+              "text": "Are access rights reviewed and recertified on a regular basis?",
+              "weight": 1.0,
+              "scale": "0-5"
+            }
+          ]
+        }
+      ]
+    },
+    {
+      "id": "detection",
+      "name": "Detection & Response",
+      "capabilities": [
+        {
+          "id": "monitoring",
+          "name": "Security Monitoring",
+          "questions": [
+            {
+              "id": "det-01",
+              "text": "Are security events monitored and analyzed in real-time with documented alerting procedures?",
+              "weight": 1.0,
+              "scale": "0-5"
+            },
+            {
+              "id": "det-02",
+              "text": "Is there an incident response plan that is tested and updated regularly?",
+              "weight": 1.0,
+              "scale": "0-5"
+            }
+          ]
+        }
+      ]
+    }
+  ]
+}
diff --git a/scripts/build_acr_tasks.sh b/scripts/build_acr_tasks.sh
new file mode 100755
index 0000000000000000000000000000000000000000..3dd886d57fa6caf16fd1a87d693d34c94d163c0a
--- /dev/null
+++ b/scripts/build_acr_tasks.sh
@@ -0,0 +1,28 @@
+#!/usr/bin/env bash
+set -euo pipefail
+
+SUBSCRIPTION="${SUBSCRIPTION:-10233675-d493-4a97-9c81-4001e353a7bb}"
+RG="${RG:-rg-aaa-demo}"
+ACR="${ACR:-acraaademo9lyu53}"
+
+# Image tags
+API_IMAGE_TAG="${API_IMAGE_TAG:-ai-maturity-api:0.1.0}"
+WEB_IMAGE_TAG="${WEB_IMAGE_TAG:-ai-maturity-web:0.1.2}"
+
+# Go to repo root
+ROOT="$(git rev-parse --show-toplevel 2>/dev/null || pwd)"
+cd "$ROOT"
+
+az account set --subscription "$SUBSCRIPTION"
+
+# Build API (context: app/, Dockerfile: app/Dockerfile)
+az acr build -r "$ACR" -t "$API_IMAGE_TAG" -f app/Dockerfile --platform linux/amd64 app
+
+# Build Web (context: web/, Dockerfile: web/Dockerfile), bake API URL
+API_URL="${API_URL:-}"
+if [ -z "$API_URL" ]; then
+  echo "API_URL not set — building web without it. Use deploy_containerapps.sh to discover API URL, then rebuild web if needed."
+  az acr build -r "$ACR" -t "$WEB_IMAGE_TAG" -f web/Dockerfile --platform linux/amd64 web
+else
+  az acr build -r "$ACR" -t "$WEB_IMAGE_TAG" -f web/Dockerfile --build-arg NEXT_PUBLIC_API_BASE_URL="$API_URL" --platform linux/amd64 web
+fi
diff --git a/scripts/deploy_containerapps.sh b/scripts/deploy_containerapps.sh
new file mode 100755
index 0000000000000000000000000000000000000000..14fca7536139288737ef266ffaf262ac76d6b8bf
--- /dev/null
+++ b/scripts/deploy_containerapps.sh
@@ -0,0 +1,60 @@
+#!/usr/bin/env bash
+set -euo pipefail
+
+SUBSCRIPTION="${SUBSCRIPTION:-10233675-d493-4a97-9c81-4001e353a7bb}"
+RG="${RG:-rg-aaa-demo}"
+ENV="${ENV:-aca-aaa-demo}"
+ACR="${ACR:-acraaademo9lyu53}"
+ACR_SERVER="${ACR}.azurecr.io"
+API_APP="${API_APP:-api-aaa-demo}"
+WEB_APP="${WEB_APP:-web-aaa-demo}"
+STORAGE_ACCOUNT="${STORAGE_ACCOUNT:-staaademo6jshgh}"
+STORAGE_CONTAINER="${STORAGE_CONTAINER:-docs}"
+
+# Image tags
+API_IMAGE_TAG="${API_IMAGE_TAG:-ai-maturity-api:0.1.0}"
+WEB_IMAGE_TAG="${WEB_IMAGE_TAG:-ai-maturity-web:0.1.2}"
+
+az account set --subscription "$SUBSCRIPTION"
+az extension add --name containerapp -y >/dev/null 2>&1 || az extension update --name containerapp -y >/dev/null 2>&1
+
+# Enable ACR admin (temporary) so Container Apps can pull
+az acr update -n "$ACR" --admin-enabled true >/dev/null
+ACR_USER="$(az acr credential show -n "$ACR" --query username -o tsv)"
+ACR_PASS="$(az acr credential show -n "$ACR" --query 'passwords[0].value' -o tsv)"
+
+# Create/update API
+if az containerapp show -g "$RG" -n "$API_APP" >/dev/null 2>&1; then
+  az containerapp update -g "$RG" -n "$API_APP" \
+    --image "$ACR_SERVER/$API_IMAGE_TAG" \
+    --registry-server "$ACR_SERVER" --registry-username "$ACR_USER" --registry-password "$ACR_PASS" \
+    --set-env-vars USE_MANAGED_IDENTITY=false AZURE_STORAGE_ACCOUNT="$STORAGE_ACCOUNT" AZURE_STORAGE_CONTAINER="$STORAGE_CONTAINER"
+else
+  az containerapp create -g "$RG" -n "$API_APP" \
+    --environment "$ENV" \
+    --image "$ACR_SERVER/$API_IMAGE_TAG" \
+    --target-port 8000 --ingress external \
+    --registry-server "$ACR_SERVER" --registry-username "$ACR_USER" --registry-password "$ACR_PASS" \
+    --cpu 0.25 --memory 0.5Gi \
+    --env-vars USE_MANAGED_IDENTITY=false AZURE_STORAGE_ACCOUNT="$STORAGE_ACCOUNT" AZURE_STORAGE_CONTAINER="$STORAGE_CONTAINER"
+fi
+
+API_URL="https://$(az containerapp show -g "$RG" -n "$API_APP" --query properties.configuration.ingress.fqdn -o tsv)"
+echo "API_URL=$API_URL"
+
+# Create/update Web; if built without API_URL earlier, this still runs
+if az containerapp show -g "$RG" -n "$WEB_APP" >/dev/null 2>&1; then
+  az containerapp update -g "$RG" -n "$WEB_APP" \
+    --image "$ACR_SERVER/$WEB_IMAGE_TAG" \
+    --registry-server "$ACR_SERVER" --registry-username "$ACR_USER" --registry-password "$ACR_PASS"
+else
+  az containerapp create -g "$RG" -n "$WEB_APP" \
+    --environment "$ENV" \
+    --image "$ACR_SERVER/$WEB_IMAGE_TAG" \
+    --target-port 3000 --ingress external \
+    --registry-server "$ACR_SERVER" --registry-username "$ACR_USER" --registry-password "$ACR_PASS" \
+    --cpu 0.25 --memory 0.5Gi
+fi
+
+WEB_URL="https://$(az containerapp show -g "$RG" -n "$WEB_APP" --query properties.configuration.ingress.fqdn -o tsv)"
+echo "WEB_URL=$WEB_URL"
diff --git a/scripts/dev_api_local.sh b/scripts/dev_api_local.sh
new file mode 100755
index 0000000000000000000000000000000000000000..bf6977c5473dad7492f2c0bebb5615745af8cabe
--- /dev/null
+++ b/scripts/dev_api_local.sh
@@ -0,0 +1,21 @@
+#!/usr/bin/env bash
+set -euo pipefail
+
+ROOT="$(git rev-parse --show-toplevel 2>/dev/null || pwd)"
+cd "$ROOT"
+
+echo "Starting API server..."
+cd app
+
+# Set environment variables
+export ADMIN_EMAILS="${ADMIN_EMAILS:-you@company.com}"
+export AZURE_STORAGE_ACCOUNT="${AZURE_STORAGE_ACCOUNT:-}"
+export AZURE_STORAGE_CONTAINER="${AZURE_STORAGE_CONTAINER:-docs}"
+export USE_MANAGED_IDENTITY="${USE_MANAGED_IDENTITY:-false}"
+export WEB_ORIGIN="${WEB_ORIGIN:-http://localhost:3000}"
+
+# Create data directory for FileRepository
+mkdir -p ../data/engagements
+
+# Run API server
+exec python -m uvicorn api.main:app --host 0.0.0.0 --port 8000 --reload
diff --git a/scripts/dev_stack_local.sh b/scripts/dev_stack_local.sh
new file mode 100755
index 0000000000000000000000000000000000000000..e1c46d1224da24a9d9217ded9ea6cffca869f2af
--- /dev/null
+++ b/scripts/dev_stack_local.sh
@@ -0,0 +1,67 @@
+#!/usr/bin/env bash
+set -euo pipefail
+ROOT="$(git rev-parse --show-toplevel 2>/dev/null || pwd)"
+cd "$ROOT"
+
+export ADMIN_EMAILS="${ADMIN_EMAILS:-you@company.com}"
+
+# Check if tmux is installed
+if ! command -v tmux &> /dev/null; then
+    echo "tmux is not installed. Running services in background..."
+    
+    # API
+    echo "Starting API server..."
+    scripts/dev_api_local.sh &
+    API_PID=$!
+    sleep 2
+    
+    # Verify API server started successfully
+    if ! kill -0 "$API_PID" 2>/dev/null; then
+        echo "ERROR: API server failed to start (PID: $API_PID)"
+        exit 1
+    fi
+    echo "API server started successfully (PID: $API_PID)"
+    
+    # WEB
+    echo "Starting web server..."
+    scripts/dev_web_local.sh &
+    WEB_PID=$!
+    sleep 1
+    
+    # Verify web server started successfully
+    if ! kill -0 "$WEB_PID" 2>/dev/null; then
+        echo "ERROR: Web server failed to start (PID: $WEB_PID)"
+        # Clean up API server
+        kill "$API_PID" 2>/dev/null
+        exit 1
+    fi
+    echo "Web server started successfully (PID: $WEB_PID)"
+    
+    echo "Services started:"
+    echo "  API: http://localhost:8000 (PID: $API_PID)"
+    echo "  Web: http://localhost:3000 (PID: $WEB_PID)"
+    echo ""
+    echo "Press Ctrl+C to stop all services"
+    
+    # Wait and cleanup on exit
+    trap "kill $API_PID $WEB_PID 2>/dev/null" EXIT
+    wait
+else
+    # Kill any existing session
+    tmux kill-session -t aimaturity 2>/dev/null || true
+    
+    # API
+    tmux new-session -d -s aimaturity 'scripts/dev_api_local.sh'
+    sleep 2
+    
+    # WEB
+    tmux split-window -t aimaturity -h 'scripts/dev_web_local.sh'
+    
+    echo "Services starting in tmux..."
+    echo "  API: http://localhost:8000"
+    echo "  Web: http://localhost:3000"
+    echo ""
+    echo "Use 'tmux attach -t aimaturity' to view logs"
+    
+    tmux attach -t aimaturity
+fi
diff --git a/scripts/dev_web_local.sh b/scripts/dev_web_local.sh
new file mode 100755
index 0000000000000000000000000000000000000000..33d2ec2202e11fce4355005ebaa4683f427b033a
--- /dev/null
+++ b/scripts/dev_web_local.sh
@@ -0,0 +1,15 @@
+#!/usr/bin/env bash
+set -euo pipefail
+
+ROOT="$(git rev-parse --show-toplevel 2>/dev/null || pwd)"
+cd "$ROOT"
+
+echo "Starting web server..."
+cd web
+
+# Set environment variables
+export NEXT_PUBLIC_API_BASE_URL="${NEXT_PUBLIC_API_BASE_URL:-http://localhost:8000}"
+export NEXT_PUBLIC_ADMIN_EMAILS="${NEXT_PUBLIC_ADMIN_EMAILS:-you@company.com}"
+
+# Run web server
+exec npm run dev
diff --git a/scripts/rebuild_web_with_api.sh b/scripts/rebuild_web_with_api.sh
new file mode 100755
index 0000000000000000000000000000000000000000..fd496271633b2afc8f109238e45e1c92e38803ec
--- /dev/null
+++ b/scripts/rebuild_web_with_api.sh
@@ -0,0 +1,122 @@
+#!/usr/bin/env bash
+set -euo pipefail
+
+SUBSCRIPTION="${SUBSCRIPTION:-10233675-d493-4a97-9c81-4001e353a7bb}"
+RG="${RG:-rg-aaa-demo}"
+ACR="${ACR:-acraaademo9lyu53}"
+ACR_SERVER="${ACR}.azurecr.io"
+WEB_APP="${WEB_APP:-web-aaa-demo}"
+API_APP="${API_APP:-api-aaa-demo}"
+
+# Generate unique image tag
+if [ -n "${WEB_IMAGE_TAG:-}" ]; then
+  # Use provided tag if set
+  UNIQUE_TAG="$WEB_IMAGE_TAG"
+else
+  # Generate timestamp-based tag
+  UNIQUE_TAG="ai-maturity-web:$(date +%Y%m%d%H%M%S)"
+  # Alternatively, use git commit SHA if available
+  # if git rev-parse --short HEAD &>/dev/null; then
+  #   UNIQUE_TAG="ai-maturity-web:$(git rev-parse --short HEAD)"
+  # fi
+fi
+
+# Generate revision suffix for Container App
+# Azure Container Apps revision suffix rules:
+# - Must start with a lowercase letter
+# - Can only contain lowercase letters, numbers, and hyphens
+# - Cannot contain consecutive hyphens
+# - Must end with an alphanumeric character
+# - Maximum 64 characters
+TIMESTAMP="$(date +%Y%m%d-%H%M%S)"
+# Prefix with 'r', sanitize, and ensure compliance
+REVISION_SUFFIX="r${TIMESTAMP}"
+# Remove any non-allowed characters and collapse double dashes
+REVISION_SUFFIX=$(echo "$REVISION_SUFFIX" | tr -cd 'a-z0-9-' | sed 's/--*/-/g')
+# Trim trailing non-alphanumeric characters
+REVISION_SUFFIX=$(echo "$REVISION_SUFFIX" | sed 's/[^a-z0-9]*$//')
+# Truncate to 64 characters
+REVISION_SUFFIX="${REVISION_SUFFIX:0:64}"
+
+az account set --subscription "$SUBSCRIPTION"
+
+# Check for API URL override via environment variable
+# NEXT_PUBLIC_API_BASE_URL takes precedence over Azure Container App FQDN lookup
+if [ -n "${NEXT_PUBLIC_API_BASE_URL:-}" ]; then
+  echo "Using API URL from NEXT_PUBLIC_API_BASE_URL environment variable"
+  API_URL="$NEXT_PUBLIC_API_BASE_URL"
+  
+  # Normalize URL to ensure it has https:// prefix
+  if [[ ! "$API_URL" =~ ^https?:// ]]; then
+    API_URL="https://${API_URL}"
+  fi
+  
+  echo "API URL set to: $API_URL"
+else
+  # Get API FQDN and validate
+  echo "Retrieving API FQDN for $API_APP..."
+  FQDN_OUTPUT=$(mktemp)
+  ERROR_OUTPUT=$(mktemp)
+
+  # Run the command and capture output
+  if az containerapp show -g "$RG" -n "$API_APP" --query properties.configuration.ingress.fqdn -o tsv >"$FQDN_OUTPUT" 2>"$ERROR_OUTPUT"; then
+    FQDN=$(cat "$FQDN_OUTPUT")
+    
+    # Check if FQDN is empty or "null"
+    if [ -z "$FQDN" ] || [ "$FQDN" = "null" ]; then
+      echo "Error: API FQDN is empty or null" >&2
+      [ -s "$ERROR_OUTPUT" ] && cat "$ERROR_OUTPUT" >&2
+      rm -f "$FQDN_OUTPUT" "$ERROR_OUTPUT"
+      exit 1
+    fi
+  else
+    echo "Error: Failed to retrieve API FQDN" >&2
+    cat "$ERROR_OUTPUT" >&2
+    rm -f "$FQDN_OUTPUT" "$ERROR_OUTPUT"
+    exit 1
+  fi
+
+  rm -f "$FQDN_OUTPUT" "$ERROR_OUTPUT"
+  API_URL="https://${FQDN}"
+fi
+
+# Validate the resolved API URL
+if [ -z "$API_URL" ]; then
+  echo "Error: API_URL is empty after resolution" >&2
+  exit 1
+fi
+
+echo "Rebuilding web with NEXT_PUBLIC_API_BASE_URL=$API_URL"
+echo "Using image tag: $UNIQUE_TAG"
+
+# Build in ACR with baked API_URL
+echo "Building image in ACR..."
+az acr build -r "$ACR" \
+  -t "$UNIQUE_TAG" \
+  -f web/Dockerfile \
+  --build-arg NEXT_PUBLIC_API_BASE_URL="$API_URL" \
+  --platform linux/amd64 \
+  web
+
+# Optionally push a "latest" tag alongside the unique tag
+if [ "${PUSH_LATEST:-false}" = "true" ]; then
+  echo "Tagging as latest..."
+  # Parse repository name from UNIQUE_TAG (everything before the colon)
+  REPO_NAME="${UNIQUE_TAG%%:*}"
+  az acr import --name "$ACR" \
+    --source "${ACR_SERVER}/${UNIQUE_TAG}" \
+    --image "${REPO_NAME}:latest" \
+    --force
+fi
+
+# Update web app to the new image with revision suffix
+echo "Updating container app to use new image with revision: $REVISION_SUFFIX..."
+if ! az containerapp update -g "$RG" -n "$WEB_APP" \
+  --image "$ACR_SERVER/$UNIQUE_TAG" \
+  --revision-suffix "$REVISION_SUFFIX"; then
+  echo "Error: Failed to update container app" >&2
+  exit 1
+fi
+
+echo "Web app successfully updated with new image: $UNIQUE_TAG"
+echo "New revision suffix: $REVISION_SUFFIX"
diff --git a/scripts/release.sh b/scripts/release.sh
new file mode 100755
index 0000000000000000000000000000000000000000..57cae1e11c9bd64ce7181656f1c69c135bb958ce
--- /dev/null
+++ b/scripts/release.sh
@@ -0,0 +1,106 @@
+#!/usr/bin/env bash
+set -euo pipefail
+
+# -------- Config (override via env) --------
+SUBSCRIPTION="${SUBSCRIPTION:-}"  # optional; if set, we'll switch
+RG="${RG:-rg-aaa-demo}"
+ACR_NAME="${ACR_NAME:-acraaademo9lyu53}"
+ACR_SERVER="${ACR_SERVER:-$ACR_NAME.azurecr.io}"
+API_APP="${API_APP:-api-aaa-demo}"
+WEB_APP="${WEB_APP:-web-aaa-demo}"
+ADMIN_EMAILS="${ADMIN_EMAILS:-va.sysoiev@audit3a.com}"
+TAG="${TAG:-v$(date +%Y%m%d%H%M)-$(git rev-parse --short HEAD)}"
+NO_COMMIT="${NO_COMMIT:-0}"
+
+need() { command -v "$1" >/dev/null || { echo "Missing $1"; exit 1; }; }
+need az; need git; command -v jq >/dev/null || echo "(optional) jq not found – pretty printing JSON will be skipped"
+
+# Ensure repo root
+ROOT="$(git rev-parse --show-toplevel 2>/dev/null || pwd)"
+cd "$ROOT"
+
+echo "==> Release config:"
+echo "SUBSCRIPTION=${SUBSCRIPTION:-<unchanged>}"
+echo "RG=$RG"
+echo "ACR=$ACR_NAME ($ACR_SERVER)"
+echo "API_APP=$API_APP"
+echo "WEB_APP=$WEB_APP"
+echo "ADMIN_EMAILS=$ADMIN_EMAILS"
+echo "TAG=$TAG"
+
+# Optional: set subscription
+if [ -n "${SUBSCRIPTION}" ]; then
+  echo "==> Switching subscription to $SUBSCRIPTION"
+  az account set --subscription "$SUBSCRIPTION"
+fi
+
+# Pre-flight: ensure RG exists
+if ! az group show -n "$RG" >/dev/null 2>&1; then
+  echo "ERROR: Resource Group $RG not found."
+  exit 1
+fi
+
+# Pre-flight: ensure Container Apps extension
+az extension add --name containerapp -y >/dev/null 2>&1 || true
+
+# Commit & push (optional)
+if [ "$NO_COMMIT" != "1" ]; then
+  BRANCH="$(git rev-parse --abbrev-ref HEAD)"
+  echo "==> Committing & pushing on branch $BRANCH"
+  git add -A
+  git commit -m "release: deploy $TAG" || echo "(no local changes to commit)"
+  git push || echo "(push skipped/failed – check credentials if needed)"
+fi
+
+# ACR admin + creds
+echo "==> Enabling ACR admin"
+az acr update -n "$ACR_NAME" --admin-enabled true >/dev/null
+
+echo "==> Fetching ACR creds"
+ACR_USER="$(az acr credential show -n "$ACR_NAME" --query username -o tsv)"
+ACR_PASS="$(az acr credential show -n "$ACR_NAME" --query 'passwords[0].value' -o tsv)"
+
+# Build images in ACR
+echo "==> Building API image in ACR: $TAG"
+az acr build -r "$ACR_NAME" -t "ai-maturity-api:$TAG" -f app/Dockerfile ./app
+
+echo "==> Building WEB image in ACR: $TAG"
+az acr build -r "$ACR_NAME" -t "ai-maturity-web:$TAG" -f web/Dockerfile ./web
+
+# Update API
+echo "==> Updating API container app image + env"
+az containerapp update -g "$RG" -n "$API_APP" \
+  --image "$ACR_SERVER/ai-maturity-api:$TAG" \
+  --registry-server "$ACR_SERVER" \
+  --registry-username "$ACR_USER" \
+  --registry-password "$ACR_PASS" \
+  --env-vars ADMIN_EMAILS="$ADMIN_EMAILS" >/dev/null
+
+API_FQDN="$(az containerapp show -g "$RG" -n "$API_APP" --query properties.configuration.ingress.fqdn -o tsv)"
+API_URL="https://${API_FQDN}"
+
+# Update WEB
+echo "==> Updating WEB container app image + env"
+az containerapp update -g "$RG" -n "$WEB_APP" \
+  --image "$ACR_SERVER/ai-maturity-web:$TAG" \
+  --registry-server "$ACR_SERVER" \
+  --registry-username "$ACR_USER" \
+  --registry-password "$ACR_PASS" \
+  --env-vars NEXT_PUBLIC_API_BASE="$API_URL" >/dev/null
+
+WEB_FQDN="$(az containerapp show -g "$RG" -n "$WEB_APP" --query properties.configuration.ingress.fqdn -o tsv)"
+WEB_URL="https://${WEB_FQDN}"
+
+# Print endpoints
+echo "==> Done. Endpoints:"
+echo "API_URL=$API_URL"
+echo "WEB_URL=$WEB_URL"
+
+# Smoke tests
+echo "==> Smoke test: /health and /docs"
+set +e
+HC="$(curl -s -m 20 "$API_URL/health")"
+DOCS_CODE="$(curl -s -o /dev/null -w '%{http_code}' "$API_URL/docs")"
+set -e
+echo "Health: $HC"
+echo "Docs HTTP: $DOCS_CODE"
diff --git a/scripts/release_with_preset.sh b/scripts/release_with_preset.sh
new file mode 100755
index 0000000000000000000000000000000000000000..91f35383e031cf64f0bc593cfcce89c9cd6a8578
--- /dev/null
+++ b/scripts/release_with_preset.sh
@@ -0,0 +1,33 @@
+#!/usr/bin/env bash
+set -euo pipefail
+# Usage:
+#   scripts/release_with_preset.sh [/path/to/preset.json]
+# If a path is provided and the file exists, it will be copied into imports/ and uploaded after deploy.
+
+PRESET_SRC="${1:-}"
+PRESET_DST="${PRESET_DST:-imports/preset_cscm_v3.json}"
+
+ROOT="$(git rev-parse --show-toplevel 2>/dev/null || pwd)"
+cd "$ROOT"
+mkdir -p "$(dirname "$PRESET_DST")"
+
+if [ -n "$PRESET_SRC" ]; then
+  if [ ! -f "$PRESET_SRC" ]; then
+    echo "Preset not found at: $PRESET_SRC"
+    exit 1
+  fi
+  echo "==> Copying preset to repo: $PRESET_SRC -> $PRESET_DST"
+  cp "$PRESET_SRC" "$PRESET_DST"
+  git add "$PRESET_DST"
+fi
+
+# Deploy (build in ACR + update Container Apps)
+scripts/release.sh
+
+# Upload preset if we have it locally
+if [ -f "$PRESET_DST" ]; then
+  scripts/upload_preset.sh "$PRESET_DST"
+else
+  echo "Preset not found at $PRESET_DST — upload later via the web UI (/admin/presets) or run:"
+  echo "  scripts/upload_preset.sh /path/to/preset.json"
+fi
diff --git a/scripts/smoke_test.sh b/scripts/smoke_test.sh
new file mode 100755
index 0000000000000000000000000000000000000000..23f895252720ba51ab1a6437fc01f04161bc9f2d
--- /dev/null
+++ b/scripts/smoke_test.sh
@@ -0,0 +1,141 @@
+#!/usr/bin/env bash
+set -euo pipefail
+
+# Configuration
+API=http://localhost:8000
+EMAIL=you@company.com
+
+echo "=== AI Maturity Assessment - Engagement & RBAC Smoke Test ==="
+echo ""
+echo "Configuration:"
+echo "  API: $API"
+echo "  User: $EMAIL (Admin)"
+echo ""
+
+# Bootstrap engagement
+echo "1. Creating engagement..."
+E=$(curl -s -X POST $API/engagements \
+  -H "X-User-Email:$EMAIL" \
+  -H "X-Engagement-ID:bootstrap" \
+  -H "Content-Type: application/json" \
+  -d '{"name":"Demo AAA","client_code":"AAA"}')
+
+if [ -z "$E" ]; then
+  echo "ERROR: Failed to create engagement"
+  exit 1
+fi
+
+EID=$(echo "$E" | python3 -c "
+import sys, json
+try:
+    data = json.load(sys.stdin)
+    if 'id' not in data:
+        print('ERROR: Missing id in engagement response', file=sys.stderr)
+        sys.exit(1)
+    print(data['id'])
+except (json.JSONDecodeError, KeyError) as e:
+    print(f'ERROR: Failed to parse engagement ID: {e}', file=sys.stderr)
+    sys.exit(1)
+")
+echo "  Created engagement: $EID"
+
+# Add self as lead
+echo ""
+echo "2. Adding user as lead..."
+# Capture response and status code
+TEMP_RESPONSE=$(mktemp)
+HTTP_STATUS=$(curl -s -w "%{http_code}" -o "$TEMP_RESPONSE" -X POST $API/engagements/$EID/members \
+  -H "X-User-Email:$EMAIL" \
+  -H "X-Engagement-ID:$EID" \
+  -H "Content-Type: application/json" \
+  -d "{\"user_email\":\"$EMAIL\",\"role\":\"lead\"}")
+
+if [[ $HTTP_STATUS -ge 200 && $HTTP_STATUS -lt 300 ]]; then
+  echo "  Added $EMAIL as lead"
+else
+  echo "ERROR: Failed to add member (HTTP $HTTP_STATUS)"
+  cat "$TEMP_RESPONSE"
+  rm -f "$TEMP_RESPONSE"
+  exit 1
+fi
+rm -f "$TEMP_RESPONSE"
+
+# Create assessment in engagement
+echo ""
+echo "3. Creating assessment..."
+A=$(curl -s -X POST $API/domain-assessments \
+  -H "X-User-Email:$EMAIL" \
+  -H "X-Engagement-ID:$EID" \
+  -H "Content-Type: application/json" \
+  -d '{"name":"Local Demo","framework":"NIST-CSF"}')
+
+AID=$(echo "$A" | python3 -c "
+import sys, json
+try:
+    data = json.load(sys.stdin)
+    if 'id' not in data:
+        print('ERROR: Missing id in assessment response', file=sys.stderr)
+        sys.exit(1)
+    print(data['id'])
+except (json.JSONDecodeError, KeyError) as e:
+    print(f'ERROR: Failed to parse assessment ID: {e}', file=sys.stderr)
+    sys.exit(1)
+")
+echo "  Created assessment: $AID"
+
+# Run analyze
+echo ""
+echo "4. Running analysis..."
+FINDINGS=$(curl -s -X POST $API/orchestrations/analyze \
+  -H "X-User-Email:$EMAIL" \
+  -H "X-Engagement-ID:$EID" \
+  -H "Content-Type: application/json" \
+  -d "{\"assessment_id\":\"$AID\",\"content\":\"No MFA for admins; no DLP; no IR runbooks\"}")
+
+FINDING_COUNT=$(echo "$FINDINGS" | python3 -c "
+import sys, json
+try:
+    data = json.load(sys.stdin)
+    findings = data.get('findings', [])
+    print(len(findings))
+except (json.JSONDecodeError, KeyError) as e:
+    print('ERROR: Failed to parse findings count', file=sys.stderr)
+    print('0')
+" || echo "0")
+echo "  Found $FINDING_COUNT findings"
+
+# Run recommend
+echo ""
+echo "5. Running recommendations..."
+RECS=$(curl -s -X POST $API/orchestrations/recommend \
+  -H "X-User-Email:$EMAIL" \
+  -H "X-Engagement-ID:$EID" \
+  -H "Content-Type: application/json" \
+  -d "{\"assessment_id\":\"$AID\"}")
+
+REC_COUNT=$(echo "$RECS" | python3 -c "
+import sys, json
+try:
+    data = json.load(sys.stdin)
+    recommendations = data.get('recommendations', [])
+    print(len(recommendations))
+except (json.JSONDecodeError, KeyError) as e:
+    print('ERROR: Failed to parse recommendations count', file=sys.stderr)
+    print('0')
+" || echo "0")
+echo "  Generated $REC_COUNT recommendations"
+
+echo ""
+echo "=== Smoke Test Complete ==="
+echo ""
+echo "Local URLs:"
+echo "  Sign In:      http://localhost:3000/signin"
+echo "  Engagements:  http://localhost:3000/engagements"
+echo "  Demo:         http://localhost:3000/e/$EID/demo"
+echo ""
+echo "To start the full stack locally, run:"
+echo "  ./scripts/dev_stack_local.sh"
+echo ""
+echo "To deploy to Azure (later):"
+echo "  ./scripts/deploy_api_only.sh"
+echo "  ./scripts/deploy_web_only.sh"
diff --git a/scripts/upload_preset.sh b/scripts/upload_preset.sh
new file mode 100755
index 0000000000000000000000000000000000000000..41cc8bcde7c0e03c123515dd3cc6300472f682eb
--- /dev/null
+++ b/scripts/upload_preset.sh
@@ -0,0 +1,30 @@
+#!/usr/bin/env bash
+set -euo pipefail
+
+# Usage: scripts/upload_preset.sh /path/to/preset.json
+PRESET_PATH="${1:-}"
+if [ -z "$PRESET_PATH" ] || [ ! -f "$PRESET_PATH" ]; then
+  echo "Usage: $0 /path/to/preset.json"
+  exit 1
+fi
+
+RG="${RG:-rg-aaa-demo}"
+API_APP="${API_APP:-api-aaa-demo}"
+ADMIN_EMAIL="${ADMIN_EMAIL:-va.sysoiev@audit3a.com}"
+
+API_FQDN="$(az containerapp show -g "$RG" -n "$API_APP" --query properties.configuration.ingress.fqdn -o tsv)"
+API_URL="https://${API_FQDN}"
+
+echo "==> Uploading preset to $API_URL/presets/upload"
+curl -sS -X POST "$API_URL/presets/upload" \
+  -H "X-User-Email: $ADMIN_EMAIL" \
+  -H "X-Engagement-ID: bootstrap" \
+  -F "file=@${PRESET_PATH}"
+
+echo
+echo "==> Listing presets:"
+if command -v jq >/dev/null; then
+  curl -sS "$API_URL/presets" | jq .
+else
+  curl -sS "$API_URL/presets"
+fi
diff --git a/web/.dockerignore b/web/.dockerignore
new file mode 100644
index 0000000000000000000000000000000000000000..6754f3efc4dc289fa3ee36355f60d227561fa477
--- /dev/null
+++ b/web/.dockerignore
@@ -0,0 +1,65 @@
+node_modules/
+.next/
+.git/
+.gitignore
+Dockerfile.bak
+
+# Environment files
+.env
+.env.*
+.env.local
+.env.test
+.env.production
+.envrc
+.secrets
+
+# Editor/IDE directories and configs
+.vscode/
+.idea/
+*.swp
+*.swo
+*~
+
+# OS files
+.DS_Store
+Thumbs.db
+
+# Logs
+*.log
+npm-debug.log*
+yarn-debug.log*
+yarn-error.log*
+
+# Build outputs and caches
+dist/
+build/
+coverage/
+.cache/
+.turbo/
+.parcel-cache/
+out/
+
+# Test files
+__tests__/
+*.test.js
+*.test.ts
+*.spec.js
+*.spec.ts
+
+# Package manager files (keeping lock files for reproducible builds)
+
+# TypeScript cache
+*.tsbuildinfo
+
+# Next.js specific
+.next/
+out/
+.vercel
+
+# Backup files
+*.bak
+*.backup
+
+# Temporary files
+tmp/
+temp/
diff --git a/web/Dockerfile b/web/Dockerfile
index 79c16af9aee1841c0f79c83af6dd5be09c57814e..fabbc712b8ac1c7b3c2e5939b79731170342fd5e 100644
--- a/web/Dockerfile
+++ b/web/Dockerfile
@@ -1,29 +1,38 @@
-FROM node:20-alpine AS deps
+# Build stage
+FROM node:20-alpine AS builder
 WORKDIR /app
-COPY package*.json ./
-RUN npm ci
 
-FROM node:20-alpine AS build
-WORKDIR /app
-COPY --from=deps /app/node_modules ./node_modules
-COPY . ./
-ARG NEXT_PUBLIC_API_BASE_URL
+# Install deps (prefer clean, reproducible installs)
+COPY package.json package-lock.json* pnpm-lock.yaml* yarn.lock* ./
+RUN \
+  if [ -f package-lock.json ]; then npm ci; \
+  elif [ -f pnpm-lock.yaml ]; then npm i -g pnpm && pnpm i --frozen-lockfile; \
+  elif [ -f yarn.lock ]; then yarn install --frozen-lockfile; \
+  else npm i; fi
+
+# Build arg surfaces through environment for Next.js at build time
+ARG NEXT_PUBLIC_API_BASE_URL=""
 ENV NEXT_PUBLIC_API_BASE_URL=$NEXT_PUBLIC_API_BASE_URL
+
+# Copy rest and build
+COPY . .
+# Ensure public directory exists for Next.js
+RUN mkdir -p public
 RUN npm run build
 
-FROM node:20-alpine AS run
+# Runtime stage
+FROM node:20-alpine AS runner
 WORKDIR /app
 ENV NODE_ENV=production
-COPY --from=build /app ./
-EXPOSE 3000
-CMD ["npm","start"]
-
-
-
-
-
-
-
-
+# Re-expose public env var for runtime (also embedded at build time)
+ARG NEXT_PUBLIC_API_BASE_URL=""
+ENV NEXT_PUBLIC_API_BASE_URL=$NEXT_PUBLIC_API_BASE_URL
 
+# Copy production build
+COPY --from=builder /app/package.json ./
+COPY --from=builder /app/node_modules ./node_modules
+COPY --from=builder /app/.next ./.next
+COPY --from=builder /app/public ./public
 
+EXPOSE 3000
+CMD ["npm", "run", "start"]
\ No newline at end of file
diff --git a/web/app/admin/presets/page.tsx b/web/app/admin/presets/page.tsx
new file mode 100644
index 0000000000000000000000000000000000000000..e5db39ca729b833401446fe79e11000f60a1efdb
--- /dev/null
+++ b/web/app/admin/presets/page.tsx
@@ -0,0 +1,100 @@
+"use client";
+import { useState, useEffect } from "react";
+import { API_BASE, authHeaders } from "@/lib/api";
+
+type PresetRow = { id:string; name:string; version:string; source:string; counts:{pillars:number;capabilities:number;questions:number}};
+
+export default function AdminPresets() {
+  const [items, setItems] = useState<PresetRow[]>([]);
+  const [msg, setMsg] = useState<string>("");
+
+  async function load() {
+    try {
+      const r = await fetch(`${API_BASE}/presets`, { headers: authHeaders() });
+      if (!r.ok) {
+        setMsg(`Failed to load presets: ${r.status}`);
+        return;
+      }
+      setItems(await r.json());
+    } catch (error) {
+      setMsg(`Error loading presets: ${error}`);
+    }
+  }
+
+  useEffect(()=>{ load(); },[]);
+
+  async function onUpload(e: React.FormEvent<HTMLFormElement>) {
+    e.preventDefault();
+    const fd = new FormData(e.currentTarget);
+    try {
+      const r = await fetch(`${API_BASE}/presets/upload`, {
+        method: "POST",
+        headers: { ...authHeaders() }, // do NOT set content-type here
+        body: fd
+      });
+      if (!r.ok) { 
+        const errorText = await r.text();
+        setMsg(`Upload failed: ${r.status} - ${errorText}`); 
+        return; 
+      }
+      const data = await r.json();
+      setMsg(`Uploaded: ${data.name} (${data.id})`);
+      await load();
+      e.currentTarget.reset();
+    } catch (error) {
+      setMsg(`Upload error: ${error}`);
+    }
+  }
+
+  return (
+    <div className="p-6 space-y-6">
+      <h1 className="text-2xl font-semibold">Admin · Presets</h1>
+      <form onSubmit={onUpload} className="border rounded p-4 space-y-3">
+        <div className="text-sm text-gray-600">Upload a preset JSON</div>
+        <input name="file" type="file" accept="application/json" className="border rounded p-2" required />
+        <button className="px-3 py-1 border rounded bg-blue-500 text-white hover:bg-blue-600" type="submit">Upload</button>
+        {msg && <div className="text-sm">{msg}</div>}
+      </form>
+      <div className="border rounded p-4">
+        <div className="font-medium mb-2">Available Presets</div>
+        <table className="w-full text-sm">
+          <thead><tr className="border-b">
+            <th className="text-left py-2">Name</th>
+            <th className="text-left py-2">ID</th>
+            <th className="text-left py-2">Version</th>
+            <th className="text-left py-2">Counts (P/C/Q)</th>
+            <th className="text-left py-2">Source</th>
+            <th className="text-left py-2">Actions</th>
+          </tr></thead>
+          <tbody>
+            {items.map(it=>(
+              <tr key={it.id} className="border-t">
+                <td className="py-2">{it.name}</td>
+                <td className="py-2 font-mono text-xs">{it.id}</td>
+                <td className="py-2">{it.version}</td>
+                <td className="py-2">{it.counts.pillars}/{it.counts.capabilities}/{it.counts.questions}</td>
+                <td className="py-2">
+                  <span className={`px-2 py-1 rounded text-xs ${it.source === 'bundled' ? 'bg-green-100 text-green-800' : 'bg-blue-100 text-blue-800'}`}>
+                    {it.source}
+                  </span>
+                </td>
+                <td className="py-2 space-x-2">
+                  <a className="underline text-blue-600 hover:text-blue-800" href={`${API_BASE}/presets/${it.id}`} target="_blank" rel="noopener noreferrer">Preview</a>
+                  <button 
+                    className="underline text-gray-600 hover:text-gray-800"
+                    onClick={() => navigator.clipboard.writeText(it.id)}
+                  >
+                    Copy ID
+                  </button>
+                </td>
+              </tr>
+           ))}
+          </tbody>
+        </table>
+        {items.length === 0 && (
+          <div className="text-gray-500 text-center py-4">No presets available</div>
+        )}
+      </div>
+    </div>
+  );
+}
diff --git a/web/app/demo-orchestration/page.tsx b/web/app/demo-orchestration/page.tsx
new file mode 100644
index 0000000000000000000000000000000000000000..7a35d82e74b6720c6ab4d861731066806044e55c
--- /dev/null
+++ b/web/app/demo-orchestration/page.tsx
@@ -0,0 +1,101 @@
+"use client";
+
+import { useState } from "react";
+import { createAssessment, runAnalyze, runRecommend } from "@/lib/orchestration";
+
+export default function DemoOrchestration() {
+  const [aid, setAid] = useState<string>("");
+  const [content, setContent] = useState<string>("Sample workshop notes:\n- Admins without MFA\n- No M365 DLP\n- No incident runbooks");
+  const [findings, setFindings] = useState<any[]>([]);
+  const [recs, setRecs] = useState<any[]>([]);
+  const [busy, setBusy] = useState<boolean>(false);
+  const [msg, setMsg] = useState<string>("");
+
+  async function onCreate() {
+    setBusy(true); setMsg("");
+    try {
+      const a = await createAssessment("Demo Assessment");
+      setAid(a.id);
+      setMsg(`Created assessment ${a.id}`);
+    } catch (e:any) {
+      setMsg(e.message);
+    } finally { setBusy(false); }
+  }
+
+  async function onAnalyze() {
+    if (!aid) return setMsg("Create assessment first");
+    setBusy(true); setMsg("");
+    try {
+      const r = await runAnalyze(aid, content);
+      setFindings(r.findings || []);
+      setMsg(`Analyze ok: ${r.findings?.length || 0} findings`);
+    } catch (e:any) {
+      setMsg(e.message);
+    } finally { setBusy(false); }
+  }
+
+  async function onRecommend() {
+    if (!aid) return setMsg("Create assessment first");
+    setBusy(true); setMsg("");
+    try {
+      const r = await runRecommend(aid);
+      setRecs(r.recommendations || []);
+      setMsg(`Recommend ok: ${r.recommendations?.length || 0} items`);
+    } catch (e:any) {
+      setMsg(e.message);
+    } finally { setBusy(false); }
+  }
+
+  // Check if engagement is selected
+  const hasEngagement = typeof window !== "undefined" && localStorage.getItem("engagementId");
+
+  return (
+    <div className="p-6 space-y-4">
+      <h1 className="text-2xl font-semibold">Demo Orchestration</h1>
+      
+      {!hasEngagement && (
+        <div className="bg-yellow-50 border border-yellow-200 rounded p-4">
+          <p className="text-yellow-800">
+            No engagement selected. 
+            <a href="/engagements" className="ml-2 text-yellow-900 underline font-medium">
+              Choose an engagement
+            </a>
+          </p>
+        </div>
+      )}
+      <div className="flex gap-2">
+        <button className="px-3 py-2 rounded bg-black text-white" onClick={onCreate} disabled={busy}>Create Assessment</button>
+        <button className="px-3 py-2 rounded bg-black text-white" onClick={onAnalyze} disabled={busy}>Run Analyze</button>
+        <button className="px-3 py-2 rounded bg-black text-white" onClick={onRecommend} disabled={busy}>Run Recommend</button>
+      </div>
+      {msg && <div className="text-sm text-gray-600">{msg}</div>}
+
+      <div>
+        <label className="block text-sm font-medium mb-1">Workshop / Doc Content</label>
+        <textarea value={content} onChange={e=>setContent(e.target.value)} className="w-full border rounded p-2 h-40" />
+      </div>
+
+      <div>
+        <h2 className="text-xl font-medium">Findings</h2>
+        <ul className="list-disc pl-6">
+          {(findings || []).map((f:any, index:number)=>(
+            <li key={f?.id ?? `finding-${index}`}>
+              <strong>[{f?.severity || 'medium'}] {f?.area || "General"}:</strong> {f?.title || 'Untitled finding'}
+            </li>
+          ))}
+        </ul>
+      </div>
+
+      <div>
+        <h2 className="text-xl font-medium">Recommendations</h2>
+        <ol className="list-decimal pl-6">
+          {(recs || []).map((r:any, index:number)=>(
+            <li key={r?.id ?? `result-${index}`}>
+              {r?.title || 'Untitled recommendation'} <span className="text-xs text-gray-500">({r?.priority || 'P2'}, {r?.effort || 'M'}, {r?.timeline_weeks ?? "?"}w)</span>
+            </li>
+          ))}
+        </ol>
+      </div>
+    </div>
+  );
+}
diff --git a/web/app/e/[engagementId]/dashboard/page.tsx b/web/app/e/[engagementId]/dashboard/page.tsx
new file mode 100644
index 0000000000000000000000000000000000000000..0cac3ec99007d232e5eb483bc838ab4d7b50d25e
--- /dev/null
+++ b/web/app/e/[engagementId]/dashboard/page.tsx
@@ -0,0 +1,81 @@
+"use client";
+import { useEffect, useState } from "react";
+import { useParams, useRouter } from "next/navigation";
+import Link from "next/link";
+import { getSummary, reportMdUrl, type EngagementSummary } from "@/lib/summary";
+
+export default function DashboardPage() {
+  const { engagementId } = useParams<{ engagementId: string }>();
+  const router = useRouter();
+  const [sum, setSum] = useState<EngagementSummary | null>(null);
+  const [err, setErr] = useState<string>("");
+
+  useEffect(() => {
+    if (!engagementId) return;
+    (async () => {
+      try {
+        const s = await getSummary(engagementId);
+        setSum(s);
+      } catch (e: any) {
+        setErr(e.message ?? "Failed to load");
+      }
+    })();
+  }, [engagementId]);
+
+  if (!engagementId) return <div className="p-6">No engagement selected.</div>;
+
+  return (
+    <div className="p-6 space-y-6">
+      <div className="flex items-center justify-between">
+        <h1 className="text-2xl font-semibold">Engagement Dashboard</h1>
+        <div className="flex gap-2">
+          <a className="px-3 py-1 border rounded" href={reportMdUrl(engagementId)} target="_blank">Export Markdown</a>
+          <Link className="px-3 py-1 border rounded" href={`/e/${engagementId}/demo`}>Open Demo</Link>
+          <Link className="px-3 py-1 border rounded" href={`/e/${engagementId}/demo#docs`}>Docs</Link>
+        </div>
+      </div>
+
+      {err && <div className="text-red-600 text-sm">{err}</div>}
+
+      <div className="grid grid-cols-2 md:grid-cols-5 gap-3">
+        <Card title="Assessments" value={sum?.counts.assessments ?? 0} />
+        <Card title="Documents" value={sum?.counts.documents ?? 0} />
+        <Card title="Findings" value={sum?.counts.findings ?? 0} />
+        <Card title="Recommendations" value={sum?.counts.recommendations ?? 0} />
+        <Card title="Run Logs" value={sum?.counts.runlogs ?? 0} />
+      </div>
+
+      <div className="rounded-xl border p-4">
+        <div className="font-medium mb-2">Recent Activity</div>
+        {!sum?.recent_activity?.length && <div className="text-sm text-gray-500">No activity yet.</div>}
+        <ul className="divide-y">
+          {sum?.recent_activity?.map((a, i) => (
+            <li key={i} className="py-2 text-sm flex items-center justify-between gap-3">
+              <div className="truncate">
+                <span className="inline-block min-w-28 text-gray-500">{a.type}</span>
+                <span className="font-medium">{a.title || a.id}</span>
+              </div>
+              <div className="text-gray-500">{a.ts ? new Date(a.ts).toLocaleString() : ""}</div>
+            </li>
+          ))}
+        </ul>
+      </div>
+
+      {sum?.recent_runlog_excerpt && (
+        <div className="rounded-xl border p-4">
+          <div className="font-medium mb-2">Recent Run Log</div>
+          <pre className="text-sm whitespace-pre-wrap">{sum.recent_runlog_excerpt}</pre>
+        </div>
+      )}
+    </div>
+  );
+}
+
+function Card({ title, value }: { title: string; value: number | string }) {
+  return (
+    <div className="rounded-xl border p-4">
+      <div className="text-sm text-gray-500">{title}</div>
+      <div className="text-2xl font-semibold">{value}</div>
+    </div>
+  );
+}
diff --git a/web/app/e/[engagementId]/demo/page.tsx b/web/app/e/[engagementId]/demo/page.tsx
new file mode 100644
index 0000000000000000000000000000000000000000..c60969cc8b592e031766a1a42c91df36af919304
--- /dev/null
+++ b/web/app/e/[engagementId]/demo/page.tsx
@@ -0,0 +1,261 @@
+"use client";
+
+import { useState, useEffect } from "react";
+import { useParams, useRouter } from "next/navigation";
+import { createAssessment, runAnalyze, runRecommend } from "@/lib/orchestration";
+import { requireEmail, setEngagementId } from "@/lib/auth";
+import EngagementSwitcher from "@/components/EngagementSwitcher";
+import { listDocs, uploadDocs, deleteDoc, downloadUrl, analyzeDoc, type Doc } from "@/lib/docs";
+import { authHeaders } from "@/lib/api";
+
+interface Finding {
+  id: string;
+  title: string;
+  description?: string;
+  severity: string;
+  area: string;
+  source?: string;
+  createdAt?: string;
+  updatedAt?: string;
+}
+
+interface Recommendation {
+  id: string;
+  title: string;
+  description?: string;
+  priority: string;
+  effort: string;
+  timeline_weeks: number;
+  status?: string;
+  createdAt?: string;
+  updatedAt?: string;
+}
+
+export default function EngagementDemo() {
+  const params = useParams();
+  const router = useRouter();
+  const engagementId = params.engagementId as string;
+  
+  const [aid, setAid] = useState<string>("");
+  const [content, setContent] = useState<string>("Sample workshop notes:\n- Admins without MFA\n- No M365 DLP\n- No incident runbooks");
+  const [findings, setFindings] = useState<Finding[]>([]);
+  const [recs, setRecs] = useState<Recommendation[]>([]);
+  const [busy, setBusy] = useState<boolean>(false);
+  const [msg, setMsg] = useState<string>("");
+  const [docs, setDocs] = useState<Doc[]>([]);
+  const [docMsg, setDocMsg] = useState<string>("");
+
+  useEffect(() => {
+    const email = requireEmail(router);
+    if (email && engagementId) {
+      // Set the engagement ID for API calls
+      setEngagementId(engagementId);
+      refreshDocs();
+    }
+  }, [engagementId, router]);
+
+  async function refreshDocs() {
+    if (!engagementId) return;
+    try { 
+      setDocs(await listDocs(engagementId)); 
+    } catch (e: any) { 
+      setDocMsg(e.message); 
+    }
+  }
+
+  async function onCreate() {
+    setBusy(true); setMsg("");
+    try {
+      const a = await createAssessment("Demo Assessment");
+      setAid(a.id);
+      setMsg(`Created assessment ${a.id}`);
+    } catch (e: any) {
+      setMsg(e.message);
+    } finally { setBusy(false); }
+  }
+
+  async function onAnalyze() {
+    if (!aid) return setMsg("Create assessment first");
+    setBusy(true); setMsg("");
+    try {
+      const r = await runAnalyze(aid, content);
+      setFindings(r.findings || []);
+      setMsg(`Analyze ok: ${r.findings?.length || 0} findings`);
+    } catch (e: any) {
+      setMsg(e.message);
+    } finally { setBusy(false); }
+  }
+
+  async function onRecommend() {
+    if (!aid) return setMsg("Create assessment first");
+    setBusy(true); setMsg("");
+    try {
+      const r = await runRecommend(aid);
+      setRecs(r.recommendations || []);
+      setMsg(`Recommend ok: ${r.recommendations?.length || 0} items`);
+    } catch (e: any) {
+      setMsg(e.message);
+    } finally { setBusy(false); }
+  }
+
+  async function onUpload(e: React.ChangeEvent<HTMLInputElement>) {
+    const files = Array.from(e.target.files || []);
+    if (!files.length || !engagementId) return;
+    setBusy(true);
+    try {
+      await uploadDocs(engagementId, files);
+      await refreshDocs();
+      setDocMsg(`Uploaded ${files.length} file(s)`);
+    } catch (e: any) { 
+      setDocMsg(e.message); 
+    } finally { 
+      setBusy(false); 
+      e.currentTarget.value = ""; 
+    }
+  }
+
+  async function onAnalyzeDoc(docId: string) {
+    setBusy(true);
+    try {
+      const res = await analyzeDoc(engagementId, docId);
+      setDocMsg(res?.note ? `Analyzed (note: ${res.note})` : "Analyzed");
+    } catch (e: any) { 
+      setDocMsg(e.message); 
+    } finally { 
+      setBusy(false); 
+    }
+  }
+
+  async function onDeleteDoc(docId: string) {
+    if (!confirm("Delete document?")) return;
+    setBusy(true);
+    try { 
+      await deleteDoc(engagementId, docId); 
+      await refreshDocs(); 
+    } catch(e: any) { 
+      setDocMsg(e.message); 
+    } finally { 
+      setBusy(false); 
+    }
+  }
+
+  return (
+    <div className="min-h-screen bg-gray-50">
+      <div className="bg-white shadow">
+        <div className="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8">
+          <div className="flex justify-between items-center py-4">
+            <h1 className="text-xl font-semibold">AI Maturity Assessment</h1>
+            <EngagementSwitcher />
+          </div>
+        </div>
+      </div>
+      
+      <div className="max-w-7xl mx-auto p-6 space-y-6">
+        <div className="bg-white rounded-lg shadow p-6">
+          <h2 className="text-2xl font-semibold mb-4">Demo Orchestration</h2>
+          
+          <div className="flex gap-2 mb-4">
+            <button 
+              className="px-3 py-2 rounded bg-black text-white disabled:opacity-50" 
+              onClick={onCreate} 
+              disabled={busy}
+            >
+              Create Assessment
+            </button>
+            <button 
+              className="px-3 py-2 rounded bg-black text-white disabled:opacity-50" 
+              onClick={onAnalyze} 
+              disabled={busy}
+            >
+              Run Analyze
+            </button>
+            <button 
+              className="px-3 py-2 rounded bg-black text-white disabled:opacity-50" 
+              onClick={onRecommend} 
+              disabled={busy}
+            >
+              Run Recommend
+            </button>
+          </div>
+          
+          {msg && <div className="text-sm text-gray-600 mb-4">{msg}</div>}
+
+          <div className="mb-6">
+            <label className="block text-sm font-medium mb-1">Workshop / Doc Content</label>
+            <textarea 
+              value={content} 
+              onChange={e => setContent(e.target.value)} 
+              className="w-full border rounded p-2 h-40" 
+            />
+          </div>
+
+          <div className="grid md:grid-cols-2 gap-6">
+            <div>
+              <h3 className="text-xl font-medium mb-3">Findings</h3>
+              <ul className="list-disc pl-6 space-y-2">
+                {findings.map((f, index) => (
+                  <li key={f.id ?? `finding-${index}`}>
+                    <strong>[{f.severity || 'medium'}] {f.area || "General"}:</strong> {f.title || 'Untitled finding'}
+                  </li>
+                ))}
+              </ul>
+            </div>
+
+            <div>
+              <h3 className="text-xl font-medium mb-3">Recommendations</h3>
+              <ol className="list-decimal pl-6 space-y-2">
+                {recs.map((r, index) => (
+                  <li key={r.id ?? `result-${index}`}>
+                    {r.title || 'Untitled recommendation'} 
+                    <span className="text-xs text-gray-500 ml-2">
+                      ({r.priority || 'P2'}, {r.effort || 'M'}, {r.timeline_weeks ?? "?"}w)
+                    </span>
+                  </li>
+                ))}
+              </ol>
+            </div>
+          </div>
+        </div>
+
+        <div className="mt-6 rounded-xl border p-4 space-y-3">
+          <h2 className="text-lg font-semibold">Documents</h2>
+          <input type="file" multiple onChange={onUpload} disabled={busy} />
+          <div className="text-sm text-gray-600">Max {process.env.NEXT_PUBLIC_MAX_UPLOAD_MB ?? '10'} MB each. PDF, DOCX, TXT recommended.</div>
+          <ul className="divide-y">
+            {docs.map(d => (
+              <li key={d.id} className="py-2 flex items-center justify-between gap-3">
+                <div className="min-w-0">
+                  <div className="font-medium truncate">{d.filename}</div>
+                  <div className="text-xs text-gray-500">{(d.size/1024).toFixed(1)} KB · {new Date(d.uploaded_at).toLocaleString()}</div>
+                </div>
+                <div className="flex items-center gap-3 shrink-0">
+                  <button 
+                    className="underline" 
+                    onClick={async () => {
+                      const url = downloadUrl(engagementId as string, d.id);
+                      const response = await fetch(url, { headers: authHeaders() });
+                      if (response.ok) {
+                        const blob = await response.blob();
+                        const a = document.createElement('a');
+                        a.href = URL.createObjectURL(blob);
+                        a.download = d.filename;
+                        a.click();
+                      }
+                    }} 
+                    disabled={busy}
+                  >
+                    Download
+                  </button>
+                  <button className="px-2 py-1 border rounded" onClick={()=>onAnalyzeDoc(d.id)} disabled={busy}>Analyze</button>
+                  <button className="px-2 py-1 border rounded" onClick={()=>onDeleteDoc(d.id)} disabled={busy}>Delete</button>
+                </div>
+              </li>
+            ))}
+            {!docs.length && <li className="text-sm text-gray-500">No documents yet.</li>}
+          </ul>
+          {docMsg && <div className="text-sm text-blue-700">{docMsg}</div>}
+        </div>
+      </div>
+    </div>
+  );
+}
diff --git a/web/app/engagements/page.tsx b/web/app/engagements/page.tsx
new file mode 100644
index 0000000000000000000000000000000000000000..2747aa5555d5c2562fd6e8f80c24aeb5fdaed933
--- /dev/null
+++ b/web/app/engagements/page.tsx
@@ -0,0 +1,183 @@
+"use client";
+
+import { useState, useEffect, useCallback } from "react";
+import { useRouter } from "next/navigation";
+import { requireEmail, getEmail, setEngagementId, isAdmin } from "@/lib/auth";
+import { API_BASE } from "@/lib/orchestration";
+
+interface Engagement {
+  id: string;
+  name: string;
+  client_code?: string;
+  created_by: string;
+  created_at: string;
+}
+
+export default function Engagements() {
+  const [engagements, setEngagements] = useState<Engagement[]>([]);
+  const [loading, setLoading] = useState(true);
+  const [showCreate, setShowCreate] = useState(false);
+  const [newName, setNewName] = useState("");
+  const [newClientCode, setNewClientCode] = useState("");
+  const [error, setError] = useState("");
+  const router = useRouter();
+
+  const loadEngagements = useCallback(async () => {
+    try {
+      const email = getEmail();
+      if (!email || !email.trim()) {
+        setError("Email is required");
+        setLoading(false);
+        return;
+      }
+      
+      const res = await fetch(`${API_BASE}/engagements`, {
+        headers: {
+          "X-User-Email": email,
+          "X-Engagement-ID": "bootstrap", // Required by API but not used for listing
+        },
+      });
+      if (res.ok) {
+        const data = await res.json();
+        setEngagements(data);
+      } else {
+        setError("Failed to load engagements");
+      }
+    } catch (err) {
+      setError("Error loading engagements");
+    } finally {
+      setLoading(false);
+    }
+  }, []);
+
+  useEffect(() => {
+    const email = requireEmail(router);
+    if (email) {
+      loadEngagements();
+    }
+  }, [router, loadEngagements]);
+
+  const handleCreate = async () => {
+    try {
+      const email = getEmail();
+      const res = await fetch(`${API_BASE}/engagements`, {
+        method: "POST",
+        headers: {
+          "Content-Type": "application/json",
+          "X-User-Email": email,
+          "X-Engagement-ID": "bootstrap",
+        },
+        body: JSON.stringify({ 
+          name: newName, 
+          client_code: newClientCode || undefined 
+        }),
+      });
+      if (res.ok) {
+        setNewName("");
+        setNewClientCode("");
+        setShowCreate(false);
+        loadEngagements();
+      } else {
+        const data = await res.json();
+        setError(data.detail || "Failed to create engagement");
+      }
+    } catch (err) {
+      setError("Error creating engagement");
+    }
+  };
+
+  const selectEngagement = (id: string) => {
+    setEngagementId(id);
+    router.push(`/e/${id}/demo`);
+  };
+
+  if (loading) {
+    return <div className="p-6">Loading...</div>;
+  }
+
+  return (
+    <div className="p-6 max-w-4xl mx-auto">
+      <h1 className="text-2xl font-semibold mb-6">My Engagements</h1>
+      
+      {error && (
+        <div className="bg-red-50 border border-red-200 text-red-700 px-4 py-3 rounded mb-4">
+          {error}
+        </div>
+      )}
+
+      {isAdmin() && (
+        <div className="mb-6">
+          {!showCreate ? (
+            <button
+              onClick={() => setShowCreate(true)}
+              className="px-4 py-2 bg-indigo-600 text-white rounded hover:bg-indigo-700"
+            >
+              Create New Engagement
+            </button>
+          ) : (
+            <div className="bg-gray-50 p-4 rounded">
+              <h3 className="text-lg font-medium mb-3">New Engagement</h3>
+              <div className="space-y-3">
+                <input
+                  type="text"
+                  placeholder="Engagement Name"
+                  value={newName}
+                  onChange={(e) => setNewName(e.target.value)}
+                  className="w-full px-3 py-2 border rounded"
+                />
+                <input
+                  type="text"
+                  placeholder="Client Code (optional)"
+                  value={newClientCode}
+                  onChange={(e) => setNewClientCode(e.target.value)}
+                  className="w-full px-3 py-2 border rounded"
+                />
+                <div className="flex gap-2">
+                  <button
+                    onClick={handleCreate}
+                    disabled={!newName.trim()}
+                    className="px-4 py-2 bg-indigo-600 text-white rounded hover:bg-indigo-700 disabled:opacity-50"
+                  >
+                    Create
+                  </button>
+                  <button
+                    onClick={() => {
+                      setShowCreate(false);
+                      setNewName("");
+                      setNewClientCode("");
+                    }}
+                    className="px-4 py-2 bg-gray-300 text-gray-700 rounded hover:bg-gray-400"
+                  >
+                    Cancel
+                  </button>
+                </div>
+              </div>
+            </div>
+          )}
+        </div>
+      )}
+
+      <div className="grid gap-4">
+        {engagements.length === 0 ? (
+          <p className="text-gray-500">No engagements found. {isAdmin() && "Create one to get started."}</p>
+        ) : (
+          engagements.map((eng) => (
+            <div
+              key={eng.id}
+              onClick={() => selectEngagement(eng.id)}
+              className="p-4 border rounded hover:bg-gray-50 cursor-pointer"
+            >
+              <h3 className="font-medium text-lg">{eng.name}</h3>
+              {eng.client_code && (
+                <p className="text-sm text-gray-600">Client: {eng.client_code}</p>
+              )}
+              <p className="text-sm text-gray-500">
+                Created by {eng.created_by} on {new Date(eng.created_at).toLocaleDateString()}
+              </p>
+            </div>
+          ))
+        )}
+      </div>
+    </div>
+  );
+}
diff --git a/web/app/new/page.tsx b/web/app/new/page.tsx
index 799b95f9d098fbe34573054253cd4e7b620079dc..81ad3a286bb34259eab3723e646c4c1c310d669d 100644
--- a/web/app/new/page.tsx
+++ b/web/app/new/page.tsx
@@ -1,21 +1,50 @@
 "use client";
-import { useState } from "react";
+import { useState, useEffect } from "react";
 import { useRouter } from "next/navigation";
-import { fetchPreset } from "@/lib/api";
+import { fetchPreset, API_BASE, authHeaders } from "@/lib/api";
 import { createAssessment } from "@/lib/assessments";
 
+type PresetOption = { id: string; name: string; version: string; source: string; counts: { pillars: number; capabilities: number; questions: number } };
+
 export default function NewAssessmentPage() {
   const router = useRouter();
   const [loading, setLoading] = useState(false);
   const [preset, setPreset] = useState<any>(null);
   const [error, setError] = useState<string | null>(null);
   const [creating, setCreating] = useState(false);
+  const [presets, setPresets] = useState<PresetOption[]>([]);
+  const [selectedPresetId, setSelectedPresetId] = useState<string>("");
+  
+  useEffect(() => {
+    loadPresets();
+  }, []);
+
+  async function loadPresets() {
+    try {
+      const r = await fetch(`${API_BASE}/presets`, { headers: authHeaders() });
+      if (!r.ok) {
+        throw new Error(`Failed to fetch presets: ${r.status}`);
+      }
+      const presetList = await r.json();
+      setPresets(presetList);
+      // Auto-select first preset if available
+      if (presetList.length > 0) {
+        setSelectedPresetId(presetList[0].id);
+      }
+    } catch (err) {
+      setError(err instanceof Error ? err.message : "Failed to load presets");
+    }
+  }
   
   async function load() {
+    if (!selectedPresetId) {
+      setError("Please select a preset");
+      return;
+    }
     setLoading(true);
     setError(null);
     try {
-      setPreset(await fetchPreset("cyber-for-ai"));
+      setPreset(await fetchPreset(selectedPresetId));
     } catch (err) {
       setError(err instanceof Error ? err.message : "Failed to load preset");
     } finally {
@@ -24,10 +53,14 @@ export default function NewAssessmentPage() {
   }
 
   async function handleContinue() {
+    if (!selectedPresetId) {
+      setError("Please select a preset");
+      return;
+    }
     setCreating(true);
     setError(null);
     try {
-      const assessment = await createAssessment("Demo Assessment", "cyber-for-ai");
+      const assessment = await createAssessment("Demo Assessment", selectedPresetId);
       router.push(`/assessment/${assessment.id}`);
     } catch (err) {
       setError(err instanceof Error ? err.message : "Failed to create assessment");
@@ -39,8 +72,20 @@ export default function NewAssessmentPage() {
       <h1 className="text-2xl font-semibold">New Assessment — Scope</h1>
       <div className="space-y-2">
         <label className="block text-sm font-medium">Profile</label>
-        <select className="border rounded px-3 py-2" defaultValue="cyber-for-ai">
-          <option value="cyber-for-ai">Cyber for AI</option>
+        <select 
+          className="border rounded px-3 py-2" 
+          value={selectedPresetId}
+          onChange={(e) => setSelectedPresetId(e.target.value)}
+        >
+          {presets.length === 0 ? (
+            <option value="">Loading presets...</option>
+          ) : (
+            presets.map(preset => (
+              <option key={preset.id} value={preset.id}>
+                {preset.name} v{preset.version} ({preset.counts.questions} questions)
+              </option>
+            ))
+          )}
         </select>
       </div>
       <button onClick={load} className="px-4 py-2 bg-black text-white rounded" disabled={loading}>
diff --git a/web/app/signin/page.tsx b/web/app/signin/page.tsx
new file mode 100644
index 0000000000000000000000000000000000000000..6564f2c0540f6828d25d4011407ebd8f617165ff
--- /dev/null
+++ b/web/app/signin/page.tsx
@@ -0,0 +1,69 @@
+"use client";
+
+import { useState } from "react";
+import { useRouter } from "next/navigation";
+
+export default function SignIn() {
+  const [email, setEmail] = useState("");
+  const router = useRouter();
+
+  const handleSubmit = (e: React.FormEvent) => {
+    e.preventDefault();
+    if (email.trim()) {
+      // Check localStorage availability and handle errors
+      if (typeof window !== "undefined" && window.localStorage) {
+        try {
+          localStorage.setItem("email", email.trim());
+        } catch (error) {
+          console.warn("Failed to save email to localStorage:", error);
+          // Continue anyway - the app can still work without persistence
+        }
+      }
+      router.push("/engagements");
+    }
+  };
+
+  return (
+    <div className="flex min-h-screen items-center justify-center bg-gray-50">
+      <div className="w-full max-w-md space-y-8">
+        <div>
+          <h2 className="mt-6 text-center text-3xl font-bold tracking-tight text-gray-900">
+            Sign in to AI Maturity Assessment
+          </h2>
+          <p className="mt-2 text-center text-sm text-gray-600">
+            Enter your email to continue (demo)
+          </p>
+        </div>
+        <form className="mt-8 space-y-6" onSubmit={handleSubmit}>
+          <div className="-space-y-px rounded-md shadow-sm">
+            <div>
+              <label htmlFor="email" className="sr-only">
+                Email address
+              </label>
+              <input
+                id="email"
+                name="email"
+                type="email"
+                autoComplete="email"
+                required
+                className="relative block w-full appearance-none rounded-md border border-gray-300 px-3 py-2 text-gray-900 placeholder-gray-500 focus:z-10 focus:border-indigo-500 focus:outline-none focus:ring-indigo-500 sm:text-sm"
+                placeholder="Email address"
+                value={email}
+                onChange={(e) => setEmail(e.target.value)}
+              />
+            </div>
+          </div>
+
+          <div>
+            <button
+              type="submit"
+              className="group relative flex w-full justify-center rounded-md border border-transparent bg-indigo-600 py-2 px-4 text-sm font-medium text-white hover:bg-indigo-700 focus:outline-none focus:ring-2 focus:ring-indigo-500 focus:ring-offset-2"
+            >
+              Sign in
+            </button>
+          </div>
+        </form>
+      </div>
+    </div>
+  );
+}
diff --git a/web/components/EngagementSwitcher.tsx b/web/components/EngagementSwitcher.tsx
new file mode 100644
index 0000000000000000000000000000000000000000..91e8a4e8eaad5861aed7e718094edbcfd02c785b
--- /dev/null
+++ b/web/components/EngagementSwitcher.tsx
@@ -0,0 +1,156 @@
+"use client";
+
+import { useState, useEffect } from "react";
+import { useRouter, usePathname } from "next/navigation";
+import { getEmail, getEngagementId, setEngagementId } from "@/lib/auth";
+import { API_BASE } from "@/lib/orchestration";
+
+interface Engagement {
+  id: string;
+  name: string;
+  client_code?: string;
+}
+
+export default function EngagementSwitcher() {
+  const [engagements, setEngagements] = useState<Engagement[]>([]);
+  const [currentEngagementId, setCurrentEngagementId] = useState("");
+  const [showDropdown, setShowDropdown] = useState(false);
+  const [loading, setLoading] = useState(false);
+  const [error, setError] = useState<string | null>(null);
+  const router = useRouter();
+  const pathname = usePathname();
+
+  useEffect(() => {
+    const email = getEmail();
+    const engId = getEngagementId();
+    if (email) {
+      loadEngagements();
+      setCurrentEngagementId(engId);
+    }
+  }, []);
+
+  const loadEngagements = async () => {
+    setLoading(true);
+    setError(null);
+    try {
+      const email = getEmail();
+      if (!email) {
+        setError("No email found");
+        return;
+      }
+      
+      const res = await fetch(`${API_BASE}/engagements`, {
+        headers: {
+          "X-User-Email": email,
+          "X-Engagement-ID": getEngagementId() || "bootstrap",
+        },
+      });
+      if (res.ok) {
+        const data = await res.json();
+        setEngagements(data);
+      } else {
+        try {
+          const errorData = await res.json();
+          const serverMessage = errorData.message || errorData.error || errorData.detail;
+          setError(serverMessage ? `Failed to load engagements: ${serverMessage}` : `Failed to load engagements (${res.status} ${res.statusText})`);
+        } catch {
+          try {
+            const textError = await res.text();
+            setError(textError ? `Failed to load engagements: ${textError}` : `Failed to load engagements (${res.status} ${res.statusText})`);
+          } catch {
+            setError(`Failed to load engagements (${res.status} ${res.statusText})`);
+          }
+        }
+      }
+    } catch (err) {
+      console.error("Failed to load engagements", err);
+      setError("Failed to load engagements");
+    } finally {
+      setLoading(false);
+    }
+  };
+
+  const switchEngagement = (id: string) => {
+    setEngagementId(id);
+    setCurrentEngagementId(id);
+    setShowDropdown(false);
+    
+    // Redirect to engagement-specific route if on a generic page
+    if (pathname === "/demo-orchestration") {
+      router.push(`/e/${id}/demo`);
+    } else if (pathname.startsWith("/e/") && pathname.includes("/demo")) {
+      // Replace current engagement ID in path
+      const newPath = pathname.replace(/\/e\/[^/]+\//, `/e/${id}/`);
+      router.push(newPath);
+    }
+  };
+
+  const currentEngagement = engagements.find(e => e.id === currentEngagementId);
+
+  if (!getEmail() || engagements.length === 0) {
+    return null;
+  }
+
+  return (
+    <div className="relative">
+      <button
+        onClick={() => setShowDropdown(!showDropdown)}
+        className="flex items-center gap-2 px-3 py-2 text-sm border rounded hover:bg-gray-50 disabled:opacity-50"
+        disabled={loading}
+      >
+        <span className="font-medium">
+          {loading ? "Loading..." : currentEngagement ? currentEngagement.name : "Select Engagement"}
+        </span>
+        <svg className="w-4 h-4" fill="none" stroke="currentColor" viewBox="0 0 24 24">
+          <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M19 9l-7 7-7-7" />
+        </svg>
+      </button>
+      
+      {showDropdown && (
+        <div className="absolute right-0 mt-1 w-64 bg-white border rounded-md shadow-lg z-50">
+          {error && (
+            <div className="px-4 py-2 text-sm text-red-600 bg-red-50 border-b">
+              {error}
+              <button 
+                onClick={() => {
+                  setError(null);
+                  loadEngagements();
+                }}
+                className="ml-2 text-xs underline"
+              >
+                Retry
+              </button>
+            </div>
+          )}
+          <div className="py-1">
+            {engagements.map(eng => (
+              <button
+                key={eng.id}
+                onClick={() => switchEngagement(eng.id)}
+                className={`w-full text-left px-4 py-2 text-sm hover:bg-gray-100 ${
+                  eng.id === currentEngagementId ? "bg-gray-50 font-medium" : ""
+                }`}
+              >
+                <div>{eng.name}</div>
+                {eng.client_code && (
+                  <div className="text-xs text-gray-500">Client: {eng.client_code}</div>
+                )}
+              </button>
+            ))}
+          </div>
+          <div className="border-t">
+            <button
+              onClick={() => {
+                setShowDropdown(false);
+                router.push("/engagements");
+              }}
+              className="w-full text-left px-4 py-2 text-sm text-indigo-600 hover:bg-gray-100"
+            >
+              Manage Engagements
+            </button>
+          </div>
+        </div>
+      )}
+    </div>
+  );
+}
diff --git a/web/components/TopNav.tsx b/web/components/TopNav.tsx
index e01dee4fa2ca459a2378e9603ec8c0ed58950a62..e3f88bd7cac17d452875f392ea8309960a7fb9f2 100644
--- a/web/components/TopNav.tsx
+++ b/web/components/TopNav.tsx
@@ -1,14 +1,46 @@
+"use client";
+import dynamic from "next/dynamic";
+import { usePathname } from "next/navigation";
+import { useEffect, useState } from "react";
+import Link from "next/link";
+
+// Dynamic import to avoid SSR issues with localStorage
+const EngagementSwitcher = dynamic(() => import("./EngagementSwitcher"), {
+  ssr: false,
+});
+
 export default function TopNav() {
+  const pathname = usePathname();
+  const [engagementId, setEngagementId] = useState<string | null>(null);
+
+  useEffect(() => {
+    // Extract engagement ID from pathname if we're in an engagement route
+    const match = pathname.match(/^\/e\/([^\/]+)/);
+    if (match) {
+      setEngagementId(match[1]);
+    } else {
+      setEngagementId(null);
+    }
+  }, [pathname]);
+
   return (
     <nav className="bg-white border-b px-8 py-4">
       <div className="flex items-center justify-between">
         <div className="flex items-center space-x-8">
           <h1 className="text-lg font-semibold">AI Maturity Tool</h1>
           <div className="flex space-x-6">
-            <a href="/" className="text-sm hover:text-blue-600">Dashboard</a>
+            <a href="/" className="text-sm hover:text-blue-600">Home</a>
             <a href="/new" className="text-sm hover:text-blue-600">New Assessment</a>
+            <a href="/engagements" className="text-sm hover:text-blue-600">Engagements</a>
+            {engagementId && (
+              <>
+                <Link href={`/e/${engagementId}/dashboard`} className="text-sm hover:text-blue-600">Dashboard</Link>
+                <Link href={`/e/${engagementId}/demo`} className="text-sm hover:text-blue-600">Demo</Link>
+              </>
+            )}
           </div>
         </div>
+        <EngagementSwitcher />
       </div>
     </nav>
   );
diff --git a/web/lib/api.ts b/web/lib/api.ts
index c448f8bf4da2f833c3da78cf0019c7e38c2ebae4..151e7011d631efd4406154eb110cc5dfee8e6096 100644
--- a/web/lib/api.ts
+++ b/web/lib/api.ts
@@ -1,5 +1,39 @@
+import { getEmail, getEngagementId } from "./auth";
+
 const BASE = process.env.NEXT_PUBLIC_API_BASE_URL || "http://localhost:8000";
 
+// Helper to add auth headers
+function getAuthHeaders(): Record<string, string> {
+  const email = getEmail();
+  const engagementId = getEngagementId();
+  
+  const headers: Record<string, string> = {};
+  if (email) headers["X-User-Email"] = email;
+  if (engagementId) headers["X-Engagement-ID"] = engagementId;
+  
+  return headers;
+}
+
+// Authenticated fetch wrapper
+export async function apiFetch(url: string, options: RequestInit = {}) {
+  const authHeaders = getAuthHeaders();
+  
+  const response = await fetch(`${BASE}${url}`, {
+    ...options,
+    headers: {
+      ...authHeaders,
+      ...options.headers,
+    },
+  });
+  
+  if (!response.ok) {
+    const error = await response.json().catch(() => ({ detail: "Request failed" }));
+    throw new Error(error.detail || `Request failed: ${response.status}`);
+  }
+  
+  return response.json();
+}
+
 export async function fetchPreset(id: string) {
   try {
     const res = await fetch(`${BASE}/presets/${id}`, { cache: "no-store" });
@@ -12,3 +46,13 @@ export async function fetchPreset(id: string) {
     throw error;
   }
 }
+
+// Export API_BASE and authHeaders for other modules
+export const API_BASE = BASE;
+export function authHeaders(skipContentType: boolean = false): Record<string, string> {
+  const headers = getAuthHeaders();
+  if (!skipContentType) {
+    headers["Content-Type"] = "application/json";
+  }
+  return headers;
+}
diff --git a/web/lib/auth.ts b/web/lib/auth.ts
new file mode 100644
index 0000000000000000000000000000000000000000..876e018cec34042ea0132bb555b6744f248635a4
--- /dev/null
+++ b/web/lib/auth.ts
@@ -0,0 +1,37 @@
+import { NextRouter } from "next/router";
+
+export function getEmail(): string {
+  if (typeof window !== "undefined") {
+    return localStorage.getItem("email") || "";
+  }
+  return "";
+}
+
+export function getEngagementId(): string {
+  if (typeof window !== "undefined") {
+    return localStorage.getItem("engagementId") || "";
+  }
+  return "";
+}
+
+export function setEngagementId(id: string): void {
+  if (typeof window !== "undefined") {
+    localStorage.setItem("engagementId", id);
+  }
+}
+
+export async function requireEmail(router: any): Promise<string> {
+  const email = getEmail();
+  if (!email) {
+    await router.push("/signin");
+    return "";
+  }
+  return email;
+}
+
+export function isAdmin(): boolean {
+  const email = getEmail();
+  const adminEmails = process.env.NEXT_PUBLIC_ADMIN_EMAILS || "";
+  const admins = adminEmails.split(",").map(e => e.trim().toLowerCase());
+  return admins.includes(email.toLowerCase());
+}
diff --git a/web/lib/docs.ts b/web/lib/docs.ts
new file mode 100644
index 0000000000000000000000000000000000000000..8a84599fb00d97ded58f075d94b810adf5761b30
--- /dev/null
+++ b/web/lib/docs.ts
@@ -0,0 +1,71 @@
+import { API_BASE, authHeaders } from "@/lib/api";
+
+export type Doc = {
+  id: string;
+  engagement_id: string;
+  filename: string;
+  content_type?: string;
+  size: number;
+  uploaded_by: string;
+  uploaded_at: string;
+};
+
+export async function listDocs(eid: string): Promise<Doc[]> {
+  const r = await fetch(`${API_BASE}/engagements/${eid}/docs`, { headers: authHeaders() });
+  if (!r.ok) throw new Error(`listDocs ${r.status}`);
+  return r.json();
+}
+
+export async function uploadDocs(eid: string, files: File[]): Promise<Doc[]> {
+  const fd = new FormData();
+  files.forEach(f => fd.append("files", f));
+  
+  // Construct properly typed RequestInit object
+  const init: RequestInit = {
+    method: "POST",
+    headers: authHeaders(true) as HeadersInit, // skip Content-Type for multipart
+    body: fd,
+  };
+  
+  const r = await fetch(`${API_BASE}/engagements/${eid}/docs`, init);
+  
+  if (!r.ok) {
+    // Enhanced error handling with response details
+    let errorMessage = `uploadDocs failed with status ${r.status}`;
+    try {
+      const errorBody = await r.text();
+      if (errorBody) {
+        errorMessage += `: ${errorBody}`;
+      }
+    } catch (parseError) {
+      // If we can't read the response body, just use the status
+      errorMessage += ` (unable to read error details)`;
+    }
+    throw new Error(errorMessage);
+  }
+  
+  return r.json();
+}
+
+export function downloadUrl(eid: string, docId: string) {
+  return `${API_BASE}/engagements/${eid}/docs/${docId}`;
+}
+
+export async function deleteDoc(eid: string, docId: string) {
+  const r = await fetch(`${API_BASE}/engagements/${eid}/docs/${docId}`, {
+    method: "DELETE",
+    headers: authHeaders(),
+  });
+  if (!r.ok) throw new Error(`deleteDoc ${r.status}`);
+  return r.json();
+}
+
+export async function analyzeDoc(eid: string, docId: string) {
+  const r = await fetch(`${API_BASE}/orchestrations/analyze-doc`, {
+    method: "POST",
+    headers: authHeaders(),
+    body: JSON.stringify({ doc_id: docId }),
+  });
+  if (!r.ok) throw new Error(`analyzeDoc ${r.status}`);
+  return r.json();
+}
diff --git a/web/lib/orchestration.ts b/web/lib/orchestration.ts
new file mode 100644
index 0000000000000000000000000000000000000000..f19af7bd6eb9473dcc905caa75d76fbb1e8c992e
--- /dev/null
+++ b/web/lib/orchestration.ts
@@ -0,0 +1,60 @@
+import { getEmail, getEngagementId } from "./auth";
+
+export const API_BASE = process.env.NEXT_PUBLIC_API_BASE_URL || "http://localhost:8000";
+
+function getAuthHeaders(): Record<string, string> {
+  const email = getEmail();
+  const engagementId = getEngagementId();
+  
+  return {
+    "X-User-Email": email || "",
+    "X-Engagement-ID": engagementId || "",
+  };
+}
+
+export async function createAssessment(name: string, framework: string = "NIST-CSF") {
+  // Validate input
+  const trimmedName = name.trim();
+  if (!trimmedName) {
+    throw new Error("createAssessment: name must be a non-empty string");
+  }
+  
+  const res = await fetch(`${API_BASE}/domain-assessments`, {
+    method: "POST",
+    headers: { 
+      "Content-Type": "application/json",
+      ...getAuthHeaders()
+    },
+    body: JSON.stringify({ name: trimmedName, framework })
+  });
+  if (!res.ok) throw new Error(`createAssessment failed: ${res.status}`);
+  return res.json();
+}
+
+export async function runAnalyze(assessmentId: string, content: string) {
+  const res = await fetch(`${API_BASE}/orchestrations/analyze`, {
+    method: "POST",
+    headers: { 
+      "Content-Type": "application/json",
+      ...getAuthHeaders()
+    },
+    body: JSON.stringify({ assessment_id: assessmentId, content })
+  });
+  if (!res.ok) throw new Error(`analyze failed: ${res.status}`);
+  const data = await res.json();
+  return data as { findings: Array<any> };
+}
+
+export async function runRecommend(assessmentId: string) {
+  const res = await fetch(`${API_BASE}/orchestrations/recommend`, {
+    method: "POST",
+    headers: { 
+      "Content-Type": "application/json",
+      ...getAuthHeaders()
+    },
+    body: JSON.stringify({ assessment_id: assessmentId })
+  });
+  if (!res.ok) throw new Error(`recommend failed: ${res.status}`);
+  const data = await res.json();
+  return data as { recommendations: Array<any> };
+}
diff --git a/web/lib/summary.ts b/web/lib/summary.ts
new file mode 100644
index 0000000000000000000000000000000000000000..23972c83048f0234f6204987523f5ad17891a2d8
--- /dev/null
+++ b/web/lib/summary.ts
@@ -0,0 +1,64 @@
+import { API_BASE, authHeaders } from "@/lib/api";
+
+export type CountSummary = {
+  assessments: number; documents: number; findings: number; recommendations: number; runlogs: number;
+};
+export type ActivityItem = { type: string; id: string; ts?: string; title?: string | null; extra?: any };
+export type EngagementSummary = {
+  engagement_id: string;
+  counts: CountSummary;
+  last_activity?: string | null;
+  recent_activity: ActivityItem[];
+  recent_runlog_excerpt?: string | null;
+};
+
+export async function getSummary(eid: string): Promise<EngagementSummary> {
+  try {
+    const r = await fetch(`${API_BASE}/engagements/${eid}/summary`, { headers: authHeaders() });
+    
+    if (!r.ok) {
+      let errorBody = "";
+      try {
+        errorBody = await r.text();
+      } catch {
+        errorBody = "Unable to read response body";
+      }
+      throw new Error(`getSummary failed for engagement ${eid}: HTTP ${r.status} ${r.statusText}. Response: ${errorBody}`);
+    }
+
+    let data: any;
+    try {
+      data = await r.json();
+    } catch (parseError) {
+      throw new Error(`getSummary failed to parse JSON for engagement ${eid}: ${parseError}`);
+    }
+
+    // Validate the response shape
+    if (!data || typeof data !== 'object') {
+      throw new Error(`getSummary received invalid response for engagement ${eid}: not an object`);
+    }
+    
+    if (typeof data.engagement_id !== 'string') {
+      throw new Error(`getSummary received invalid response for engagement ${eid}: missing or invalid engagement_id`);
+    }
+    
+    if (!data.counts || typeof data.counts !== 'object') {
+      throw new Error(`getSummary received invalid response for engagement ${eid}: missing or invalid counts object`);
+    }
+    
+    if (!Array.isArray(data.recent_activity)) {
+      throw new Error(`getSummary received invalid response for engagement ${eid}: recent_activity is not an array`);
+    }
+
+    return data as EngagementSummary;
+  } catch (error) {
+    if (error instanceof Error) {
+      throw error;
+    }
+    throw new Error(`getSummary unexpected error for engagement ${eid}: ${error}`);
+  }
+}
+
+export function reportMdUrl(eid: string) {
+  return `${API_BASE}/engagements/${eid}/exports/report.md`;
+}
