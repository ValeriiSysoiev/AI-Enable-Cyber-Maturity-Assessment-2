{
  "schema_version": "0.1.0",
  "id": "cyber-for-ai",
  "name": "Cyber for AI (Secure the AI)",
  "description": "Preset focused on securing models, data, pipelines, prompts and agents. Maps to NIST AI RMF, ISO/IEC 42001, and OWASP LLM Top 10.",
  "default_target_level": 4,
  "maturity_levels": {
    "1": "Ad hoc",
    "2": "Emerging controls",
    "3": "Defined & repeatable",
    "4": "Managed & risk-based",
    "5": "Optimized & continuous"
  },
  "pillars": [
    { "id": "governance",       "name": "Governance & Responsible AI",        "weight": 0.20, "examples": ["AI policy, intake workflow, risk acceptance, RACI"] },
    { "id": "model_security",   "name": "Model & Prompt Security",            "weight": 0.20, "examples": ["prompt injection defenses, output filters, key handling"] },
    { "id": "data_security",    "name": "Data Security & Privacy",            "weight": 0.20, "examples": ["training/inference data protection, DLP, retention"] },
    { "id": "supply_chain",     "name": "AI Supply Chain & Ops Security",     "weight": 0.15, "examples": ["artifact signing/verification, CI/CD hardening"] },
    { "id": "evals_monitoring", "name": "Evaluations, Guardrails & Monitoring","weight": 0.15, "examples": ["eval suites, jailbreak testing, drift & safety monitoring"] },
    { "id": "platform_access",  "name": "Platform & Access Controls",         "weight": 0.10, "examples": ["platform baseline, network controls, IAM/JIT/JEA"] }
  ],
  "scoring": {
    "method": "weighted_average",
    "gates": [
      { "pillar": "governance", "min_level": 2, "reason": "Minimum governance required to exceed overall level 3" }
    ]
  },
  "mappings": {
    "nist_ai_rmf": { "functions": ["Govern", "Map", "Measure", "Manage"] },
    "iso_42001":   { "clauses":   ["Context", "Leadership", "Planning", "Support", "Operation", "Performance evaluation", "Improvement"] },
    "nist_csf_2_0":{ "functions": ["Identify", "Protect", "Detect", "Respond", "Recover", "Govern"] },
    "owasp_llm_top10_2023": [
      "LLM01: Prompt Injection",
      "LLM02: Data Leakage",
      "LLM03: Supply Chain",
      "LLM04: Model Theft",
      "LLM05: Insecure Output Handling"
    ]
  },
  "questions": {
    "governance": [
      {
        "id": "gov-01",
        "text": "Is there an approved AI policy with roles, intake workflow, and risk approvals?",
        "evidence": ["AI policy doc", "intake process", "approval records"],
        "level_hints": { "3": "Policy approved; roles & intake defined", "4": "Risk-based approvals with periodic review and metrics" }
      },
      {
        "id": "gov-02",
        "text": "Are AI risk assessments performed per use case and tracked in a risk register?",
        "evidence": ["methodology", "risk register entries"],
        "level_hints": { "3": "Standard method applied", "4": "Thresholds drive controls and go/no-go decisions" }
      }
    ],
    "model_security": [
      {
        "id": "mod-01",
        "text": "Are prompt-injection and data-exfiltration tests executed per release with documented mitigations?",
        "evidence": ["test plans", "results", "mitigation PRs"],
        "level_hints": { "3": "Basic tests exist", "4": "Automated gates with thresholds and regression history" }
      }
    ],
    "data_security": [
      {
        "id": "data-01",
        "text": "Is training/inference data classified, access-controlled, and protected by preventive DLP where appropriate?",
        "evidence": ["data map", "classification standard", "DLP policy/config"],
        "level_hints": { "3": "Classification defined & applied", "4": "Preventive enforcement + periodic audits" }
      }
    ],
    "supply_chain": [
      {
        "id": "sc-01",
        "text": "Are model artifacts and dependencies signed and verified in CI/CD with provenance records?",
        "evidence": ["sigstore/cosign logs", "pipeline config"],
        "level_hints": { "3": "Signing present", "4": "Verification enforced; failure blocks release" }
      }
    ],
    "evals_monitoring": [
      {
        "id": "eval-01",
        "text": "Are evals for safety, security, bias, and drift run and reviewed with alerts on regressions?",
        "evidence": ["eval reports", "alert config", "review minutes"],
        "level_hints": { "3": "Periodic manual evals", "4": "Automated eval suite with SLOs & alerting" }
      }
    ],
    "platform_access": [
      {
        "id": "plat-01",
        "text": "Is least-privilege enforced for models, prompts, data, and keys with JIT/JEA and recertification?",
        "evidence": ["IAM policy", "PIM/JIT config", "access review logs"],
        "level_hints": { "3": "RBAC defined", "4": "JIT/JEA + periodic recertification + anomaly detection" }
      }
    ]
  },
  "evidence": { "allowed_types": ["pdf","docx","xlsx","csv","md","png","jpg"], "storage_container": "docs" }
}

